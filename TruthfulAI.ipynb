{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdfd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEVER Dataset Processing\n",
      "============================================================\n",
      "\n",
      "‚úì Found file: C:\\Users\\pooji\\Downloads\\train.jsonl\n",
      "  File size: 31.5 MB\n",
      "\n",
      "Reading claims (this may take a minute)...\n",
      "  Processed 10,000 lines...\n",
      "  Processed 20,000 lines...\n",
      "  Processed 30,000 lines...\n",
      "  Processed 40,000 lines...\n",
      "  Processed 50,000 lines...\n",
      "  Processed 60,000 lines...\n",
      "  Processed 70,000 lines...\n",
      "  Processed 80,000 lines...\n",
      "  Processed 90,000 lines...\n",
      "  Processed 100,000 lines...\n",
      "  Processed 110,000 lines...\n",
      "  Processed 120,000 lines...\n",
      "  Processed 130,000 lines...\n",
      "  Processed 140,000 lines...\n",
      "\n",
      "‚úì Loaded 145,449 total claims (VERIFIABLE + NOT VERIFIABLE)\n",
      "\n",
      "Label distribution in source data:\n",
      "  SUPPORTS: 80,035\n",
      "  REFUTES: 29,775\n",
      "  NOT ENOUGH INFO: 35,639\n",
      "\n",
      "‚úì Sampled 15000 balanced claims\n",
      "\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop/fever_claims_subset.csv\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop/fever_claims_full.json\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop/sample_claims.json\n",
      "\n",
      "============================================================\n",
      "Dataset Statistics\n",
      "============================================================\n",
      "\n",
      "Total claims: 15000\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "REFUTES            5000\n",
      "NOT ENOUGH INFO    5000\n",
      "SUPPORTS           5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "Sample Claims:\n",
      "============================================================\n",
      "\n",
      "1. The Wolf of Wall Street was a film of 1999.\n",
      "   Label: REFUTES\n",
      "\n",
      "2. Rope starred Bill Clinton.\n",
      "   Label: REFUTES\n",
      "\n",
      "3. Jared Leto has a former name called Toast.\n",
      "   Label: NOT ENOUGH INFO\n",
      "\n",
      "============================================================\n",
      "‚úì Processing Complete!\n",
      "============================================================\n",
      "\n",
      "üöÄ Next step: Build the RAG system!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Process FEVER train.jsonl file - SIMPLE VERSION\n",
    "Just edit the INPUT_FILE path below and run!\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "INPUT_FILE = r\"C:\\Users\\pooji\\Downloads\\train.jsonl\"  # ‚Üê CHANGE THIS TO YOUR PATH\n",
    "\n",
    "\n",
    "N_SAMPLES = 15000  # Number of claims to extract (500 each label)\n",
    "OUTPUT_DIR = r\"C:\\Users\\pooji\\Desktop\"\n",
    "\n",
    "def process_fever_data():\n",
    "    \"\"\"Process FEVER data and extract subset\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"FEVER Dataset Processing\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not Path(INPUT_FILE).exists():\n",
    "        print(f\"\\n ERROR: File not found!\")\n",
    "        print(f\"Looking for: {INPUT_FILE}\")\n",
    "        print(f\"\\n Please edit INPUT_FILE at the top of this script\")\n",
    "        print(f\"   and provide the correct path to train.jsonl\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n‚úì Found file: {INPUT_FILE}\")\n",
    "    file_size_mb = Path(INPUT_FILE).stat().st_size / (1024 * 1024)\n",
    "    print(f\"  File size: {file_size_mb:.1f} MB\")\n",
    "    \n",
    "    # Read claims\n",
    "    print(f\"\\nReading claims (this may take a minute)...\")\n",
    "    claims = []\n",
    "    \n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                print(f\"  Processed {i:,} lines...\")\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                # Include all claims (both VERIFIABLE and NOT VERIFIABLE)\n",
    "                # NOT VERIFIABLE claims have \"NOT ENOUGH INFO\" label\n",
    "                claims.append(data)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\n‚úì Loaded {len(claims):,} total claims (VERIFIABLE + NOT VERIFIABLE)\")\n",
    "    \n",
    "    # Separate by label\n",
    "    supports = [c for c in claims if c['label'] == 'SUPPORTS']\n",
    "    refutes = [c for c in claims if c['label'] == 'REFUTES']\n",
    "    not_enough = [c for c in claims if c['label'] == 'NOT ENOUGH INFO']\n",
    "    \n",
    "    print(f\"\\nLabel distribution in source data:\")\n",
    "    print(f\"  SUPPORTS: {len(supports):,}\")\n",
    "    print(f\"  REFUTES: {len(refutes):,}\")\n",
    "    print(f\"  NOT ENOUGH INFO: {len(not_enough):,}\")\n",
    "    \n",
    "    # Sample balanced subset (equal amounts of each label)\n",
    "    n_each = N_SAMPLES // 3\n",
    "    sampled = (\n",
    "        random.sample(supports, min(n_each, len(supports))) +\n",
    "        random.sample(refutes, min(n_each, len(refutes))) +\n",
    "        random.sample(not_enough, min(n_each, len(not_enough)))\n",
    "    )\n",
    "    random.shuffle(sampled)\n",
    "    \n",
    "    print(f\"\\n‚úì Sampled {len(sampled)} balanced claims\")\n",
    "    \n",
    "    # Convert to simple format\n",
    "    processed = []\n",
    "    for claim in sampled:\n",
    "        processed.append({\n",
    "            'id': claim['id'],\n",
    "            'claim': claim['claim'],\n",
    "            'label': claim['label'],\n",
    "            'evidence': claim.get('evidence', [])\n",
    "        })\n",
    "    \n",
    "    # Save data\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save CSV\n",
    "    df = pd.DataFrame(processed)\n",
    "    csv_path = f\"{OUTPUT_DIR}/fever_claims_subset.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n‚úì Saved: {csv_path}\")\n",
    "    \n",
    "    # Save JSON\n",
    "    json_path = f\"{OUTPUT_DIR}/fever_claims_full.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(processed, f, indent=2)\n",
    "    print(f\"‚úì Saved: {json_path}\")\n",
    "    \n",
    "    # Save sample\n",
    "    sample_path = f\"{OUTPUT_DIR}/sample_claims.json\"\n",
    "    with open(sample_path, 'w') as f:\n",
    "        json.dump(processed[:5], f, indent=2)\n",
    "    print(f\"‚úì Saved: {sample_path}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Dataset Statistics\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nTotal claims: {len(df)}\")\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    # Show samples\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Sample Claims:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for i in range(min(3, len(processed))):\n",
    "        print(f\"\\n{i+1}. {processed[i]['claim']}\")\n",
    "        print(f\"   Label: {processed[i]['label']}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚úì Processing Complete!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_fever_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEVER Dataset - Exploratory Data Analysis\n",
      "============================================================\n",
      "\n",
      "Output Directory: C:\\Users\\pooji\\Desktop\n",
      "\n",
      "Loading data...\n",
      "‚úì Loaded 15000 claims\n",
      "\n",
      "============================================================\n",
      "1. BASIC STATISTICS\n",
      "============================================================\n",
      "\n",
      "Dataset Shape: (15000, 4)\n",
      "Columns: ['id', 'claim', 'label', 'evidence']\n",
      "\n",
      "--- Label Distribution ---\n",
      "label\n",
      "REFUTES            5000\n",
      "NOT ENOUGH INFO    5000\n",
      "SUPPORTS           5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label Percentages:\n",
      "label\n",
      "REFUTES            33.333333\n",
      "NOT ENOUGH INFO    33.333333\n",
      "SUPPORTS           33.333333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Missing Values ---\n",
      "id          0\n",
      "claim       0\n",
      "label       0\n",
      "evidence    0\n",
      "dtype: int64\n",
      "\n",
      "--- Sample Claims ---\n",
      "\n",
      "REFUTES:\n",
      "  Claim: The Wolf of Wall Street was a film of 1999....\n",
      "\n",
      "NOT ENOUGH INFO:\n",
      "  Claim: Jared Leto has a former name called Toast....\n",
      "\n",
      "SUPPORTS:\n",
      "  Claim: Estella Warren is an actress....\n",
      "\n",
      "============================================================\n",
      "2. CLAIM LENGTH ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Character Length Statistics ---\n",
      "                  count     mean        std   min   25%   50%   75%    max\n",
      "label                                                                     \n",
      "NOT ENOUGH INFO  5000.0  48.1270  18.186936  13.0  35.0  45.0  57.0  277.0\n",
      "REFUTES          5000.0  46.9632  16.477031  15.0  35.0  45.0  56.0  241.0\n",
      "SUPPORTS         5000.0  48.4550  22.943654  13.0  35.0  44.0  58.0  614.0\n",
      "\n",
      "--- Word Count Statistics ---\n",
      "                  count    mean       std  min  25%  50%   75%   max\n",
      "label                                                               \n",
      "NOT ENOUGH INFO  5000.0  8.1256  3.098087  3.0  6.0  8.0  10.0  47.0\n",
      "REFUTES          5000.0  8.1058  2.749494  3.0  6.0  8.0  10.0  39.0\n",
      "SUPPORTS         5000.0  8.2336  3.623321  2.0  6.0  8.0  10.0  65.0\n",
      "\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop\\eda_claim_lengths.png\n",
      "\n",
      "============================================================\n",
      "3. WORD FREQUENCY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Top 20 Words in REFUTES Claims ---\n",
      "  not: 610\n",
      "  only: 464\n",
      "  film: 356\n",
      "  born: 222\n",
      "  from: 161\n",
      "  american: 158\n",
      "  did: 145\n",
      "  released: 140\n",
      "  series: 114\n",
      "  album: 98\n",
      "  ‚úì Saved: C:\\Users\\pooji\\Desktop\\eda_words_refutes.png\n",
      "\n",
      "--- Top 20 Words in NOT ENOUGH INFO Claims ---\n",
      "  film: 325\n",
      "  american: 187\n",
      "  born: 154\n",
      "  from: 140\n",
      "  stars: 131\n",
      "  won: 129\n",
      "  award: 122\n",
      "  released: 112\n",
      "  starred: 102\n",
      "  played: 94\n",
      "\n",
      "--- Top 20 Words in SUPPORTS Claims ---\n",
      "  film: 419\n",
      "  american: 242\n",
      "  from: 156\n",
      "  born: 154\n",
      "  series: 136\n",
      "  released: 122\n",
      "  award: 120\n",
      "  actor: 118\n",
      "  starred: 118\n",
      "  stars: 118\n",
      "  ‚úì Saved: C:\\Users\\pooji\\Desktop\\eda_words_supports.png\n",
      "\n",
      "============================================================\n",
      "4. NAMED ENTITY PATTERNS\n",
      "============================================================\n",
      "\n",
      "--- Person Names ---\n",
      "  REFUTES: 4642 occurrences (2272 unique)\n",
      "  NOT ENOUGH INFO: 5053 occurrences (2468 unique)\n",
      "  SUPPORTS: 5201 occurrences (2605 unique)\n",
      "\n",
      "--- Years ---\n",
      "  REFUTES: 739 occurrences (2 unique)\n",
      "  NOT ENOUGH INFO: 535 occurrences (2 unique)\n",
      "  SUPPORTS: 603 occurrences (2 unique)\n",
      "\n",
      "--- Numbers ---\n",
      "  REFUTES: 1192 occurrences (253 unique)\n",
      "  NOT ENOUGH INFO: 930 occurrences (215 unique)\n",
      "  SUPPORTS: 1005 occurrences (214 unique)\n",
      "\n",
      "--- Locations ---\n",
      "  REFUTES: 139 occurrences (6 unique)\n",
      "  NOT ENOUGH INFO: 110 occurrences (6 unique)\n",
      "  SUPPORTS: 170 occurrences (6 unique)\n",
      "\n",
      "============================================================\n",
      "5. EVIDENCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Evidence Statistics by Label ---\n",
      "                  count    mean       std  min  25%  50%  75%    max\n",
      "label                                                               \n",
      "NOT ENOUGH INFO  5000.0  1.0000  0.000000  1.0  1.0  1.0  1.0    1.0\n",
      "REFUTES          5000.0  1.9886  2.900440  1.0  1.0  1.0  2.0   60.0\n",
      "SUPPORTS         5000.0  2.0718  4.497854  1.0  1.0  1.0  2.0  156.0\n",
      "\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop\\eda_evidence_counts.png\n",
      "\n",
      "--- Claims with No Evidence ---\n",
      "Total: 0 (0.0%)\n",
      "Distribution by label:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "============================================================\n",
      "6. LABEL DISTRIBUTION VISUALIZATION\n",
      "============================================================\n",
      "\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop\\eda_label_distribution.png\n",
      "\n",
      "============================================================\n",
      "7. CLAIM COMPLEXITY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Complexity Metrics by Label ---\n",
      "\n",
      "Claim Words:\n",
      "label\n",
      "NOT ENOUGH INFO    8.1256\n",
      "REFUTES            8.1058\n",
      "SUPPORTS           8.2336\n",
      "Name: claim_words, dtype: float64\n",
      "\n",
      "Num Punctuation:\n",
      "label\n",
      "NOT ENOUGH INFO    1.1140\n",
      "REFUTES            1.1116\n",
      "SUPPORTS           1.1804\n",
      "Name: num_punctuation, dtype: float64\n",
      "\n",
      "Num Numbers:\n",
      "label\n",
      "NOT ENOUGH INFO    0.2146\n",
      "REFUTES            0.2636\n",
      "SUPPORTS           0.2320\n",
      "Name: num_numbers, dtype: float64\n",
      "\n",
      "Avg Word Length:\n",
      "label\n",
      "NOT ENOUGH INFO    5.127324\n",
      "REFUTES            4.962373\n",
      "SUPPORTS           5.066151\n",
      "Name: avg_word_length, dtype: float64\n",
      "\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop\\eda_complexity_correlation.png\n",
      "\n",
      "============================================================\n",
      "8. SUMMARY REPORT\n",
      "============================================================\n",
      "\n",
      "FEVER DATASET - EXPLORATORY DATA ANALYSIS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Dataset Overview:\n",
      "  ‚Ä¢ Total Claims: 15,000\n",
      "  ‚Ä¢ Features: 10\n",
      "  ‚Ä¢ Date: 2025-11-02\n",
      "\n",
      "Label Distribution:\n",
      "label\n",
      "REFUTES            5000\n",
      "NOT ENOUGH INFO    5000\n",
      "SUPPORTS           5000\n",
      "\n",
      "Claim Length Statistics:\n",
      "  ‚Ä¢ Min Words: 2\n",
      "  ‚Ä¢ Max Words: 65\n",
      "  ‚Ä¢ Mean Words: 8.2\n",
      "  ‚Ä¢ Median Words: 8.0\n",
      "\n",
      "Claims by Length Category:\n",
      "  ‚Ä¢ Short (‚â§10 words): 12,224 (81.5%)\n",
      "  ‚Ä¢ Medium (11-20 words): 2,708 (18.1%)\n",
      "  ‚Ä¢ Long (>20 words): 68 (0.5%)\n",
      "\n",
      "Evidence Statistics:\n",
      "  ‚Ä¢ Claims with Evidence: 15,000 (100.0%)\n",
      "  ‚Ä¢ Claims without Evidence: 0 (0.0%)\n",
      "  ‚Ä¢ Avg Evidence per Claim: 1.69\n",
      "\n",
      "============================================================\n",
      "\n",
      "Key Insights:\n",
      "1. Dataset is balanced across labels (equal SUPPORTS, REFUTES, NOT ENOUGH INFO)\n",
      "2. Most claims are medium length (10-20 words)\n",
      "3. All labels show similar complexity patterns\n",
      "4. Evidence availability varies by claim type\n",
      "\n",
      "Files Generated:\n",
      "  ‚Ä¢ eda_claim_lengths.png\n",
      "  ‚Ä¢ eda_words_supports.png\n",
      "  ‚Ä¢ eda_words_refutes.png\n",
      "  ‚Ä¢ eda_evidence_counts.png\n",
      "  ‚Ä¢ eda_label_distribution.png\n",
      "  ‚Ä¢ eda_complexity_correlation.png\n",
      "  ‚Ä¢ eda_summary_report.txt\n",
      "\n",
      "All files saved to: C:\\Users\\pooji\\Desktop\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "‚úì Saved: C:\\Users\\pooji\\Desktop\\eda_summary_report.txt\n",
      "\n",
      "============================================================\n",
      "‚úì EDA Complete!\n",
      "============================================================\n",
      "\n",
      "All files saved to: C:\\Users\\pooji\\Desktop\n",
      "\n",
      "Generated files:\n",
      "  ‚Ä¢ 6 visualization images (.png)\n",
      "  ‚Ä¢ 1 summary report (.txt)\n",
      "\n",
      "You can now:\n",
      "  1. Review the visualizations on your Desktop\n",
      "  2. Include them in your project report\n",
      "  3. Proceed with RAG system development\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exploratory Data Analysis (EDA) for FEVER Dataset\n",
    "Analyzes claims, labels, and evidence patterns\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# OUTPUT DIRECTORY - Change this to where you want files saved\n",
    "OUTPUT_DIR = r\"C:\\Users\\pooji\\Desktop\"\n",
    "\n",
    "def load_data(claims_file: str = \"fever_claims_full.json\"):\n",
    "    \"\"\"Load FEVER claims data\"\"\"\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    with open(claims_file, 'r', encoding='utf-8') as f:\n",
    "        claims = json.load(f)\n",
    "    \n",
    "    df = pd.DataFrame(claims)\n",
    "    print(f\"‚úì Loaded {len(df)} claims\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def basic_statistics(df: pd.DataFrame):\n",
    "    \"\"\"Display basic dataset statistics\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"1. BASIC STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nDataset Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    print(\"\\n--- Label Distribution ---\")\n",
    "    print(df['label'].value_counts())\n",
    "    print(f\"\\nLabel Percentages:\")\n",
    "    print(df['label'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    print(\"\\n--- Missing Values ---\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(\"\\n--- Sample Claims ---\")\n",
    "    for label in df['label'].unique():\n",
    "        sample = df[df['label'] == label].iloc[0]\n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"  Claim: {sample['claim'][:100]}...\")\n",
    "\n",
    "def claim_length_analysis(df: pd.DataFrame):\n",
    "    \"\"\"Analyze claim lengths\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"2. CLAIM LENGTH ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Calculate lengths\n",
    "    df['claim_length'] = df['claim'].apply(len)\n",
    "    df['claim_words'] = df['claim'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    print(\"\\n--- Character Length Statistics ---\")\n",
    "    print(df.groupby('label')['claim_length'].describe())\n",
    "    \n",
    "    print(\"\\n--- Word Count Statistics ---\")\n",
    "    print(df.groupby('label')['claim_words'].describe())\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Character length distribution\n",
    "    for label in df['label'].unique():\n",
    "        data = df[df['label'] == label]['claim_length']\n",
    "        axes[0].hist(data, alpha=0.6, label=label, bins=30)\n",
    "    axes[0].set_xlabel('Claim Length (characters)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Distribution of Claim Lengths by Label')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Word count distribution\n",
    "    for label in df['label'].unique():\n",
    "        data = df[df['label'] == label]['claim_words']\n",
    "        axes[1].hist(data, alpha=0.6, label=label, bins=20)\n",
    "    axes[1].set_xlabel('Word Count')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Distribution of Word Counts by Label')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(OUTPUT_DIR, 'eda_claim_lengths.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n‚úì Saved: {save_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def word_frequency_analysis(df: pd.DataFrame):\n",
    "    \"\"\"Analyze most common words in claims\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"3. WORD FREQUENCY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Common stop words to exclude\n",
    "    stop_words = {'the', 'is', 'in', 'a', 'an', 'and', 'or', 'of', 'to', 'was', 'were', \n",
    "                  'be', 'been', 'has', 'have', 'had', 'at', 'by', 'for', 'on', 'with'}\n",
    "    \n",
    "    for label in df['label'].unique():\n",
    "        print(f\"\\n--- Top 20 Words in {label} Claims ---\")\n",
    "        \n",
    "        claims_text = ' '.join(df[df['label'] == label]['claim'].values)\n",
    "        words = re.findall(r'\\b\\w+\\b', claims_text.lower())\n",
    "        words_filtered = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "        \n",
    "        word_counts = Counter(words_filtered).most_common(20)\n",
    "        \n",
    "        for word, count in word_counts[:10]:\n",
    "            print(f\"  {word}: {count}\")\n",
    "        \n",
    "        # Visualization for SUPPORTS and REFUTES\n",
    "        if label in ['SUPPORTS', 'REFUTES']:\n",
    "            words_list, counts_list = zip(*word_counts)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.barh(words_list, counts_list)\n",
    "            plt.xlabel('Frequency')\n",
    "            plt.title(f'Top 20 Words in {label} Claims')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(OUTPUT_DIR, f'eda_words_{label.lower()}.png')\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"  ‚úì Saved: {save_path}\")\n",
    "            plt.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def entity_analysis(df: pd.DataFrame):\n",
    "    \"\"\"Analyze named entities (simple version)\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"4. NAMED ENTITY PATTERNS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Simple pattern matching for common entities\n",
    "    patterns = {\n",
    "        'Person Names': r'\\b[A-Z][a-z]+ [A-Z][a-z]+\\b',\n",
    "        'Years': r'\\b(19|20)\\d{2}\\b',\n",
    "        'Numbers': r'\\b\\d+\\b',\n",
    "        'Locations': r'\\b(United States|America|Europe|Asia|Africa|Australia)\\b',\n",
    "    }\n",
    "    \n",
    "    for pattern_name, pattern in patterns.items():\n",
    "        print(f\"\\n--- {pattern_name} ---\")\n",
    "        \n",
    "        for label in df['label'].unique():\n",
    "            claims_text = ' '.join(df[df['label'] == label]['claim'].values)\n",
    "            matches = re.findall(pattern, claims_text)\n",
    "            \n",
    "            if matches:\n",
    "                unique_matches = len(set(matches))\n",
    "                total_matches = len(matches)\n",
    "                print(f\"  {label}: {total_matches} occurrences ({unique_matches} unique)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def evidence_analysis(df: pd.DataFrame):\n",
    "    \"\"\"Analyze evidence patterns\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"5. EVIDENCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Count evidence entries\n",
    "    df['evidence_count'] = df['evidence'].apply(\n",
    "        lambda x: len(x) if isinstance(x, list) else 0\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Evidence Statistics by Label ---\")\n",
    "    print(df.groupby('label')['evidence_count'].describe())\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df.boxplot(column='evidence_count', by='label', ax=plt.gca())\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Number of Evidence Sets')\n",
    "    plt.title('Evidence Count Distribution by Label')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(OUTPUT_DIR, 'eda_evidence_counts.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n‚úì Saved: {save_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Claims with no evidence\n",
    "    no_evidence = (df['evidence_count'] == 0).sum()\n",
    "    print(f\"\\n--- Claims with No Evidence ---\")\n",
    "    print(f\"Total: {no_evidence} ({no_evidence/len(df)*100:.1f}%)\")\n",
    "    print(\"Distribution by label:\")\n",
    "    print(df[df['evidence_count'] == 0]['label'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def label_balance_visualization(df: pd.DataFrame):\n",
    "    \"\"\"Visualize label distribution\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"6. LABEL DISTRIBUTION VISUALIZATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart\n",
    "    label_counts = df['label'].value_counts()\n",
    "    axes[0].bar(label_counts.index, label_counts.values, color=['#2ecc71', '#e74c3c', '#f39c12'])\n",
    "    axes[0].set_xlabel('Label')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].set_title('Label Distribution (Count)')\n",
    "    axes[0].tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, (label, count) in enumerate(label_counts.items()):\n",
    "        axes[0].text(i, count + 20, str(count), ha='center', fontweight='bold')\n",
    "    \n",
    "    # Pie chart\n",
    "    colors = ['#2ecc71', '#e74c3c', '#f39c12']\n",
    "    axes[1].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%',\n",
    "                colors=colors, startangle=90)\n",
    "    axes[1].set_title('Label Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(OUTPUT_DIR, 'eda_label_distribution.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n‚úì Saved: {save_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def claim_complexity_analysis(df: pd.DataFrame):\n",
    "    \"\"\"Analyze claim complexity\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"7. CLAIM COMPLEXITY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Various complexity metrics\n",
    "    df['num_punctuation'] = df['claim'].apply(lambda x: sum(1 for c in x if c in '.,!?;:'))\n",
    "    df['num_numbers'] = df['claim'].apply(lambda x: len(re.findall(r'\\d+', x)))\n",
    "    df['avg_word_length'] = df['claim'].apply(\n",
    "        lambda x: np.mean([len(w) for w in x.split()]) if x else 0\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Complexity Metrics by Label ---\")\n",
    "    complexity_cols = ['claim_words', 'num_punctuation', 'num_numbers', 'avg_word_length']\n",
    "    \n",
    "    for col in complexity_cols:\n",
    "        print(f\"\\n{col.replace('_', ' ').title()}:\")\n",
    "        print(df.groupby('label')[col].mean())\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    correlation_data = df[['claim_words', 'num_punctuation', 'num_numbers', 'avg_word_length']]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_data.corr(), annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=1)\n",
    "    plt.title('Correlation Between Complexity Metrics')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(OUTPUT_DIR, 'eda_complexity_correlation.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n‚úì Saved: {save_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_summary_report(df: pd.DataFrame):\n",
    "    \"\"\"Create a summary report\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"8. SUMMARY REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    if 'claim_words' not in df.columns:\n",
    "        df['claim_words'] = df['claim'].apply(lambda x: len(str(x).split()))\n",
    "    if 'evidence_count' not in df.columns:\n",
    "        df['evidence_count'] = df['evidence'].apply(\n",
    "            lambda x: len(x) if isinstance(x, list) else 0\n",
    "        )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    min_words = int(df['claim_words'].min())\n",
    "    max_words = int(df['claim_words'].max())\n",
    "    mean_words = df['claim_words'].mean()\n",
    "    median_words = df['claim_words'].median()\n",
    "    \n",
    "    short_claims = (df['claim_words'] <= 10).sum()\n",
    "    short_pct = short_claims / len(df) * 100\n",
    "    \n",
    "    medium_claims = ((df['claim_words'] > 10) & (df['claim_words'] <= 20)).sum()\n",
    "    medium_pct = medium_claims / len(df) * 100\n",
    "    \n",
    "    long_claims = (df['claim_words'] > 20).sum()\n",
    "    long_pct = long_claims / len(df) * 100\n",
    "    \n",
    "    with_evidence = (df['evidence_count'] > 0).sum()\n",
    "    with_evidence_pct = with_evidence / len(df) * 100\n",
    "    \n",
    "    without_evidence = (df['evidence_count'] == 0).sum()\n",
    "    without_evidence_pct = without_evidence / len(df) * 100\n",
    "    \n",
    "    avg_evidence = df['evidence_count'].mean()\n",
    "    \n",
    "    report = f\"\"\"\n",
    "FEVER DATASET - EXPLORATORY DATA ANALYSIS SUMMARY\n",
    "{'='*60}\n",
    "\n",
    "Dataset Overview:\n",
    "  ‚Ä¢ Total Claims: {len(df):,}\n",
    "  ‚Ä¢ Features: {len(df.columns)}\n",
    "  ‚Ä¢ Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "Label Distribution:\n",
    "{df['label'].value_counts().to_string()}\n",
    "\n",
    "Claim Length Statistics:\n",
    "  ‚Ä¢ Min Words: {min_words}\n",
    "  ‚Ä¢ Max Words: {max_words}\n",
    "  ‚Ä¢ Mean Words: {mean_words:.1f}\n",
    "  ‚Ä¢ Median Words: {median_words:.1f}\n",
    "\n",
    "Claims by Length Category:\n",
    "  ‚Ä¢ Short (‚â§10 words): {short_claims:,} ({short_pct:.1f}%)\n",
    "  ‚Ä¢ Medium (11-20 words): {medium_claims:,} ({medium_pct:.1f}%)\n",
    "  ‚Ä¢ Long (>20 words): {long_claims:,} ({long_pct:.1f}%)\n",
    "\n",
    "Evidence Statistics:\n",
    "  ‚Ä¢ Claims with Evidence: {with_evidence:,} ({with_evidence_pct:.1f}%)\n",
    "  ‚Ä¢ Claims without Evidence: {without_evidence:,} ({without_evidence_pct:.1f}%)\n",
    "  ‚Ä¢ Avg Evidence per Claim: {avg_evidence:.2f}\n",
    "\n",
    "{'='*60}\n",
    "\n",
    "Key Insights:\n",
    "1. Dataset is balanced across labels (equal SUPPORTS, REFUTES, NOT ENOUGH INFO)\n",
    "2. Most claims are medium length (10-20 words)\n",
    "3. All labels show similar complexity patterns\n",
    "4. Evidence availability varies by claim type\n",
    "\n",
    "Files Generated:\n",
    "  ‚Ä¢ eda_claim_lengths.png\n",
    "  ‚Ä¢ eda_words_supports.png\n",
    "  ‚Ä¢ eda_words_refutes.png\n",
    "  ‚Ä¢ eda_evidence_counts.png\n",
    "  ‚Ä¢ eda_label_distribution.png\n",
    "  ‚Ä¢ eda_complexity_correlation.png\n",
    "  ‚Ä¢ eda_summary_report.txt\n",
    "\n",
    "All files saved to: {OUTPUT_DIR}\n",
    "\n",
    "{'='*60}\n",
    "\"\"\"\n",
    "    \n",
    "    print(report)\n",
    "    \n",
    "    # Save report\n",
    "    save_path = os.path.join(OUTPUT_DIR, 'eda_summary_report.txt')\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"\\n‚úì Saved: {save_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main EDA execution\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"FEVER Dataset - Exploratory Data Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOutput Directory: {OUTPUT_DIR}\\n\")\n",
    "    \n",
    "    # Check if data exists\n",
    "    claims_file = r\"C:\\Users\\pooji\\Desktop\\fever_claims_full.json\"\n",
    "    if not Path(claims_file).exists():\n",
    "        print(f\"‚ùå Data file not found: {claims_file}\")\n",
    "        print(\"\\nPlease ensure fever_claims_full.json is in the correct location\")\n",
    "        return\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(claims_file)\n",
    "    \n",
    "    # Run analyses\n",
    "    basic_statistics(df)\n",
    "    df = claim_length_analysis(df)\n",
    "    df = word_frequency_analysis(df)\n",
    "    df = entity_analysis(df)\n",
    "    df = evidence_analysis(df)\n",
    "    df = label_balance_visualization(df)\n",
    "    df = claim_complexity_analysis(df)\n",
    "    create_summary_report(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úì EDA Complete!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nAll files saved to: {OUTPUT_DIR}\")\n",
    "    print(\"\\nGenerated files:\")\n",
    "    print(\"  ‚Ä¢ 6 visualization images (.png)\")\n",
    "    print(\"  ‚Ä¢ 1 summary report (.txt)\")\n",
    "    print(\"\\nYou can now:\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdaea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Wikipedia Knowledge Base Builder for FEVER\n",
      "============================================================\n",
      "\n",
      "Loading FEVER claims from: C:\\Users\\pooji\\Desktop\\fever_claims_full.json\n",
      "‚úì Loaded 15000 claims\n",
      "\n",
      "\n",
      "============================================================\n",
      "EVIDENCE STRUCTURE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Sample Evidence Entries ---\n",
      "\n",
      "Claim 1: The Wolf of Wall Street was a film of 1999....\n",
      "Label: REFUTES\n",
      "Evidence: [[[121034, 135322, 'The_Wolf_of_Wall_Street_-LRB-2013_film-RRB-', 0]], [[121034, 135323, 'The_Wolf_of_Wall_Street_-LRB-2013_film-RRB-', 1], [121034, 135323, 'The_Wolf_of_Wall_Street_-LRB-book-RRB-', 1]]]\n",
      "\n",
      "Claim 2: Rope starred Bill Clinton....\n",
      "Label: REFUTES\n",
      "Evidence: [[[41643, 50076, 'Rope_-LRB-film-RRB-', 4]]]\n",
      "\n",
      "Claim 3: Jared Leto has a former name called Toast....\n",
      "Label: NOT ENOUGH INFO\n",
      "Evidence: [[[262465, None, None, None]]]\n",
      "\n",
      "Claim 4: Linkin Park is a British rock band....\n",
      "Label: REFUTES\n",
      "Evidence: [[[150689, 165539, 'Linkin_Park', 0]], [[150696, 165546, 'Linkin_Park', 0]]]\n",
      "\n",
      "Claim 5: Celine Dion sings in Arabic....\n",
      "Label: REFUTES\n",
      "Evidence: [[[51364, 61088, 'Celine_Dion', 0]], [[51364, 61089, 'Celine_Dion', 16]]]\n",
      "\n",
      "--- Statistics ---\n",
      "Total claims: 15000\n",
      "Total evidence sets: 25302\n",
      "Unique Wikipedia articles: 4655\n",
      "Avg evidence sets per claim: 1.69\n",
      "\n",
      "============================================================\n",
      "EXTRACTING WIKIPEDIA ARTICLES\n",
      "============================================================\n",
      "Extracting Wikipedia article titles from evidence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15000/15000 [00:00<00:00, 1045526.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Found 4654 unique Wikipedia articles\n",
      "‚úì Saved article titles to: C:\\Users\\pooji\\Desktop\\wikipedia_article_titles.txt\n",
      "\n",
      "--- Sample Article Titles ---\n",
      "  1. \"Heroes\"_-LRB-David_Bowie_album-RRB-\n",
      "  2. 100_Greatest_of_All_Time\n",
      "  3. 10_-LRB-film-RRB-\n",
      "  4. 10_Cloverfield_Lane\n",
      "  5. 12-hour_clock\n",
      "  6. 12_Monkeys\n",
      "  7. 12_Play\n",
      "  8. 12_Years_a_Slave_-LRB-film-RRB-\n",
      "  9. 1956_Summer_Olympics\n",
      "  10. 1964_Football_League_Cup_Final\n",
      "  11. 1964_Summer_Olympics\n",
      "  12. 1971_FA_Charity_Shield\n",
      "  13. 1972_Cannes_Film_Festival\n",
      "  14. 1983‚Äì84_NBA_season\n",
      "  15. 1984_French_Open_‚Äì_Men's_Singles\n",
      "  16. 1991_NBA_Finals\n",
      "  17. 1992_Los_Angeles_riots\n",
      "  18. 1997_Masters_Tournament\n",
      "  19. 1998_Major_League_Baseball_All-Star_Game\n",
      "  20. 19_-LRB-Adele_album-RRB-\n",
      "  ... and 4634 more\n",
      "\n",
      "============================================================\n",
      "CREATING CORPUS FILES\n",
      "============================================================\n",
      "\n",
      "Creating corpus with 4654 articles...\n",
      "‚úì Fetching REAL Wikipedia content\n",
      "  Rate limit: 10 requests/second\n",
      "  Estimated time: 7.8 minutes\n",
      "  Checkpoints every 100 articles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:   2%|‚ñè         | 100/4654 [00:48<43:21,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 100 | Failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:   4%|‚ñç         | 200/4654 [01:37<1:03:55,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 200 | Failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:   6%|‚ñã         | 300/4654 [02:25<37:49,  1.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 300 | Failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:   9%|‚ñä         | 400/4654 [03:09<32:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 400 | Failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  11%|‚ñà         | 500/4654 [04:01<29:13,  2.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 499 | Failed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  13%|‚ñà‚ñé        | 600/4654 [04:46<35:33,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 599 | Failed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  15%|‚ñà‚ñå        | 700/4654 [05:30<30:24,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 699 | Failed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  17%|‚ñà‚ñã        | 800/4654 [06:18<57:56,  1.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 799 | Failed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  19%|‚ñà‚ñâ        | 900/4654 [07:03<33:24,  1.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 899 | Failed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  21%|‚ñà‚ñà‚ñè       | 1000/4654 [07:46<36:34,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 997 | Failed: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  24%|‚ñà‚ñà‚ñé       | 1100/4654 [08:28<26:36,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1096 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  26%|‚ñà‚ñà‚ñå       | 1200/4654 [09:08<21:06,  2.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1196 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  28%|‚ñà‚ñà‚ñä       | 1300/4654 [09:50<25:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1296 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  30%|‚ñà‚ñà‚ñà       | 1400/4654 [10:30<32:40,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1396 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  32%|‚ñà‚ñà‚ñà‚ñè      | 1500/4654 [11:11<21:40,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1496 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  34%|‚ñà‚ñà‚ñà‚ñç      | 1600/4654 [11:52<30:40,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1596 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  37%|‚ñà‚ñà‚ñà‚ñã      | 1700/4654 [12:33<26:21,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1696 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  39%|‚ñà‚ñà‚ñà‚ñä      | 1800/4654 [13:09<30:22,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1796 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  41%|‚ñà‚ñà‚ñà‚ñà      | 1900/4654 [13:45<32:12,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1896 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2000/4654 [14:28<30:53,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 1996 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2100/4654 [15:05<23:36,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2096 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2200/4654 [15:51<26:22,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2196 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2300/4654 [16:30<26:34,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2296 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2400/4654 [17:11<18:01,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2396 | Failed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2500/4654 [17:50<19:47,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2495 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2600/4654 [18:28<14:27,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2595 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2700/4654 [19:06<15:43,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2695 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2800/4654 [19:47<19:25,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2795 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2900/4654 [20:31<15:29,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2895 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3000/4654 [21:13<12:23,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 2995 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3100/4654 [21:53<10:48,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3095 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3200/4654 [22:36<12:57,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3195 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3300/4654 [23:18<13:07,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3295 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3400/4654 [24:00<14:12,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3395 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3500/4654 [24:41<09:37,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3495 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3600/4654 [25:21<10:38,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3595 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3700/4654 [26:04<08:27,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3695 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3800/4654 [26:44<06:23,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3795 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3900/4654 [27:26<06:20,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3895 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4000/4654 [28:11<05:35,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 3995 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4100/4654 [28:52<05:26,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 4095 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4200/4654 [29:29<03:25,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 4195 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4300/4654 [30:09<03:41,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 4295 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 4400/4654 [30:51<02:56,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 4395 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 4500/4654 [31:36<01:14,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 4495 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 4600/4654 [32:17<00:32,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint saved | Success: 4595 | Failed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4654/4654 [32:39<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Saved corpus to: C:\\Users\\pooji\\Desktop\\wikipedia_corpus_full.json\n",
      "\n",
      "Statistics:\n",
      "  Total: 4654\n",
      "  Success: 4649 (99.9%)\n",
      "  Failed: 5 (0.1%)\n",
      "  Total chars: 135,045,689\n",
      "  Avg length: 29,048 chars/article\n",
      "‚úì Saved sample corpus to: C:\\Users\\pooji\\Desktop\\wikipedia_corpus_sample.json\n",
      "\n",
      "============================================================\n",
      "‚úì KNOWLEDGE BASE BUILT SUCCESSFULLY!\n",
      "============================================================\n",
      "\n",
      "Files created in: C:\\Users\\pooji\\Desktop\n",
      "  1. wikipedia_article_titles.txt (4654 titles)\n",
      "  2. wikipedia_corpus_full.json (4654 articles with placeholder text)\n",
      "  3. wikipedia_corpus_sample.json (5 articles with real content)\n",
      "\n",
      "============================================================\n",
      "IMPORTANT NOTES:\n",
      "============================================================\n",
      "\n",
      "‚úì REAL Wikipedia content has been fetched!\n",
      "  \n",
      "Your corpus now contains actual Wikipedia article text.\n",
      "\n",
      "Next steps:\n",
      "- Build FAISS + BM25 indexes with real content\n",
      "- Run predictions on your 3000 claims\n",
      "- Measure accuracy improvement with RAG\n",
      "        \n",
      "\n",
      "üöÄ Next: Build RAG system with FAISS + BM25!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build Wikipedia Knowledge Base from FEVER Evidence\n",
    "Extracts unique Wikipedia articles referenced in FEVER claims\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Wikipedia API (optional - only if fetching real content)\n",
    "try:\n",
    "    import wikipediaapi\n",
    "    WIKIPEDIA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIKIPEDIA_AVAILABLE = False\n",
    "    print(\"‚ö† wikipediaapi not installed. Install with: pip install wikipedia-api\")\n",
    "\n",
    "# SET YOUR PATHS HERE\n",
    "INPUT_FILE = r\"C:\\Users\\pooji\\Desktop\\fever_claims_full.json\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\pooji\\Desktop\"\n",
    "\n",
    "# Wikipedia API settings\n",
    "FETCH_REAL_CONTENT = True  # Set to True to fetch real Wikipedia content\n",
    "DELAY_BETWEEN_REQUESTS = 0.1  # seconds (10 requests/second)\n",
    "CHECKPOINT_INTERVAL = 100  # Save progress every 100 articles\n",
    "\n",
    "def extract_wiki_articles_from_evidence(claims_data):\n",
    "    \"\"\"\n",
    "    Extract unique Wikipedia article titles from FEVER evidence\n",
    "    \n",
    "    FEVER evidence format: [[[doc_id, sent_id, article_title, line_num], ...]]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting Wikipedia article titles from evidence...\")\n",
    "    article_titles = set()\n",
    "    \n",
    "    for claim in tqdm(claims_data, desc=\"Processing claims\"):\n",
    "        evidence_list = claim.get('evidence', [])\n",
    "        \n",
    "        # Navigate FEVER's nested evidence structure\n",
    "        if evidence_list:\n",
    "            for evidence_set in evidence_list:\n",
    "                if evidence_set:  # Check if not empty\n",
    "                    for evidence_item in evidence_set:\n",
    "                        if len(evidence_item) >= 3:\n",
    "                            # Extract article title (3rd element, index 2)\n",
    "                            article_title = evidence_item[2]\n",
    "                            if article_title and article_title != \"\" and article_title is not None:\n",
    "                                article_titles.add(article_title)\n",
    "    \n",
    "    return sorted(list(article_titles))\n",
    "\n",
    "def clean_article_title(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean FEVER article title for Wikipedia API\n",
    "    \n",
    "    FEVER format examples:\n",
    "    - \"Barack_Obama\" -> \"Barack Obama\"\n",
    "    - \"2001-COLON-_A_Space_Odyssey_-LRB-film-RRB-\" -> \"2001: A Space Odyssey (film)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace underscores with spaces\n",
    "    title = title.replace('_', ' ')\n",
    "    \n",
    "    # Replace FEVER special tokens\n",
    "    replacements = {\n",
    "        '-LRB-': '(',\n",
    "        '-RRB-': ')',\n",
    "        '-LSB-': '[',\n",
    "        '-RSB-': ']',\n",
    "        '-COLON-': ':',\n",
    "        '-COMMA-': ',',\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        title = title.replace(old, new)\n",
    "    \n",
    "    return title.strip()\n",
    "\n",
    "def fetch_wikipedia_article(wiki, article_id: str) -> dict:\n",
    "    \"\"\"Fetch real Wikipedia content for an article\"\"\"\n",
    "    \n",
    "    clean_title = clean_article_title(article_id)\n",
    "    \n",
    "    try:\n",
    "        page = wiki.page(clean_title)\n",
    "        \n",
    "        if page.exists():\n",
    "            return {\n",
    "                'id': article_id,\n",
    "                'title': clean_title,\n",
    "                'text': page.text,\n",
    "                'url': page.fullurl,\n",
    "                'exists': True,\n",
    "                'length': len(page.text)\n",
    "            }\n",
    "        else:\n",
    "            # Article not found\n",
    "            return {\n",
    "                'id': article_id,\n",
    "                'title': clean_title,\n",
    "                'text': f\"Wikipedia article not found: {clean_title}. This may be a redirect or deleted article.\",\n",
    "                'url': '',\n",
    "                'exists': False,\n",
    "                'length': 0\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'id': article_id,\n",
    "            'title': clean_title,\n",
    "            'text': f\"Error fetching article: {str(e)}\",\n",
    "            'url': '',\n",
    "            'exists': False,\n",
    "            'length': 0\n",
    "        }\n",
    "\n",
    "def create_wikipedia_corpus(article_titles, output_path):\n",
    "    \"\"\"\n",
    "    Create Wikipedia corpus - with REAL content if enabled\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nCreating corpus with {len(article_titles)} articles...\")\n",
    "    \n",
    "    corpus = []\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Check if we should fetch real content\n",
    "    if FETCH_REAL_CONTENT and WIKIPEDIA_AVAILABLE:\n",
    "        print(\"‚úì Fetching REAL Wikipedia content\")\n",
    "        print(f\"  Rate limit: {1/DELAY_BETWEEN_REQUESTS:.0f} requests/second\")\n",
    "        print(f\"  Estimated time: {len(article_titles) * DELAY_BETWEEN_REQUESTS / 60:.1f} minutes\")\n",
    "        print(f\"  Checkpoints every {CHECKPOINT_INTERVAL} articles\\n\")\n",
    "        \n",
    "        # Initialize Wikipedia API\n",
    "        wiki = wikipediaapi.Wikipedia(\n",
    "            language='en',\n",
    "            user_agent='FEVERFactChecker/1.0 (Educational Project)'\n",
    "        )\n",
    "        \n",
    "        # Load checkpoint if exists\n",
    "        checkpoint_file = Path(output_path).parent / 'wikipedia_checkpoint.json'\n",
    "        if checkpoint_file.exists():\n",
    "            print(f\"Found checkpoint, loading...\")\n",
    "            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n",
    "                checkpoint_data = json.load(f)\n",
    "                corpus = checkpoint_data['corpus']\n",
    "                processed = set(checkpoint_data['processed'])\n",
    "                successful = len([c for c in corpus if c['exists']])\n",
    "                failed = len(corpus) - successful\n",
    "                article_titles = [a for a in article_titles if a not in processed]\n",
    "                print(f\"‚úì Resuming from {len(corpus)} articles\\n\")\n",
    "        \n",
    "        # Fetch articles\n",
    "        for i, article_id in enumerate(tqdm(article_titles, desc=\"Fetching articles\")):\n",
    "            # Fetch content\n",
    "            article_data = fetch_wikipedia_article(wiki, article_id)\n",
    "            corpus.append(article_data)\n",
    "            \n",
    "            if article_data['exists']:\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if (i + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "                checkpoint_data = {\n",
    "                    'corpus': corpus,\n",
    "                    'processed': [c['id'] for c in corpus]\n",
    "                }\n",
    "                with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(checkpoint_data, f)\n",
    "                tqdm.write(f\"  Checkpoint saved | Success: {successful} | Failed: {failed}\")\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "        \n",
    "        # Remove checkpoint after completion\n",
    "        if checkpoint_file.exists():\n",
    "            checkpoint_file.unlink()\n",
    "        \n",
    "    else:\n",
    "        # Create placeholder corpus\n",
    "        if not WIKIPEDIA_AVAILABLE:\n",
    "            print(\"‚ö† Creating PLACEHOLDER corpus (install wikipedia-api for real content)\")\n",
    "        else:\n",
    "            print(\"Creating PLACEHOLDER corpus (set FETCH_REAL_CONTENT=True for real content)\")\n",
    "        \n",
    "        for title in tqdm(article_titles, desc=\"Building corpus\"):\n",
    "            clean_title = title.replace('_', ' ')\n",
    "            doc = {\n",
    "                'id': title,\n",
    "                'title': clean_title,\n",
    "                'text': f\"{clean_title}. \" * 10 + \n",
    "                        f\"This is a Wikipedia article about {clean_title}. \" * 5 +\n",
    "                        \"In a production system, this would contain actual Wikipedia content.\",\n",
    "                'url': '',\n",
    "                'exists': False,\n",
    "                'length': 0\n",
    "            }\n",
    "            corpus.append(doc)\n",
    "    \n",
    "    # Save corpus\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(corpus, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n‚úì Saved corpus to: {output_path}\")\n",
    "    \n",
    "    if FETCH_REAL_CONTENT and WIKIPEDIA_AVAILABLE:\n",
    "        print(f\"\\nStatistics:\")\n",
    "        print(f\"  Total: {len(corpus)}\")\n",
    "        print(f\"  Success: {successful} ({successful/len(corpus)*100:.1f}%)\")\n",
    "        print(f\"  Failed: {failed} ({failed/len(corpus)*100:.1f}%)\")\n",
    "        \n",
    "        total_chars = sum(c['length'] for c in corpus if c['exists'])\n",
    "        avg_length = total_chars / successful if successful > 0 else 0\n",
    "        print(f\"  Total chars: {total_chars:,}\")\n",
    "        print(f\"  Avg length: {avg_length:,.0f} chars/article\")\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "def create_sample_corpus_with_real_content(output_path):\n",
    "    \"\"\"\n",
    "    Create a small sample with real Wikipedia-style content for testing\n",
    "    \"\"\"\n",
    "    \n",
    "    sample_articles = [\n",
    "        {\n",
    "            'id': 'Barack_Obama',\n",
    "            'title': 'Barack Obama',\n",
    "            'text': 'Barack Hussein Obama II (born August 4, 1961) is an American politician and attorney who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party, Obama was the first African-American president of the United States. He previously served as a U.S. senator representing Illinois from 2005 to 2008, and as an Illinois state senator from 1997 to 2004. Obama was born in Honolulu, Hawaii.'\n",
    "        },\n",
    "        {\n",
    "            'id': 'United_States',\n",
    "            'title': 'United States',\n",
    "            'text': 'The United States of America (USA), commonly known as the United States (U.S.) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major unincorporated territories, nine Minor Outlying Islands, and 326 Indian reservations. The United States is the world\\'s third-largest country by both land and total area.'\n",
    "        },\n",
    "        {\n",
    "            'id': 'Donald_Trump',\n",
    "            'title': 'Donald Trump',\n",
    "            'text': 'Donald John Trump (born June 14, 1946) is an American politician, media personality, and businessman who served as the 45th president of the United States from 2017 to 2021. Trump received a Bachelor of Science in economics from the University of Pennsylvania in 1968. He became president of his father Fred Trump\\'s real estate business in 1971, renamed it The Trump Organization.'\n",
    "        },\n",
    "        {\n",
    "            'id': 'Fox_Broadcasting_Company',\n",
    "            'title': 'Fox Broadcasting Company',\n",
    "            'text': 'The Fox Broadcasting Company (FOX) is an American commercial broadcast television network owned by Fox Corporation. Headquartered in New York City, the network\\'s programming is distributed via broadcast television stations. Fox is a major television network in the United States.'\n",
    "        },\n",
    "        {\n",
    "            'id': 'Beauty_and_the_Beast',\n",
    "            'title': 'Beauty and the Beast',\n",
    "            'text': 'Beauty and the Beast is a musical with music by Alan Menken, lyrics by Howard Ashman and Tim Rice, and a book by Linda Woolverton. Adapted from Walt Disney Pictures\\' Academy Award-winning 1991 animated musical film of the same name. The stage musical premiered on Broadway in 1994.'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(sample_articles, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úì Saved sample corpus to: {output_path}\")\n",
    "    \n",
    "    return sample_articles\n",
    "\n",
    "def analyze_evidence_structure(claims_data):\n",
    "    \"\"\"\n",
    "    Analyze the evidence structure to help understand the data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVIDENCE STRUCTURE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Sample evidence examples\n",
    "    print(\"\\n--- Sample Evidence Entries ---\")\n",
    "    for i, claim in enumerate(claims_data[:5]):\n",
    "        print(f\"\\nClaim {i+1}: {claim['claim'][:60]}...\")\n",
    "        print(f\"Label: {claim['label']}\")\n",
    "        print(f\"Evidence: {claim['evidence'][:2]}\")  # Show first 2 evidence sets\n",
    "    \n",
    "    # Count statistics\n",
    "    total_evidence_sets = 0\n",
    "    total_articles = set()\n",
    "    \n",
    "    for claim in claims_data:\n",
    "        evidence_list = claim.get('evidence', [])\n",
    "        total_evidence_sets += len(evidence_list)\n",
    "        \n",
    "        for evidence_set in evidence_list:\n",
    "            if evidence_set:\n",
    "                for evidence_item in evidence_set:\n",
    "                    if len(evidence_item) >= 3:\n",
    "                        total_articles.add(evidence_item[2])\n",
    "    \n",
    "    print(f\"\\n--- Statistics ---\")\n",
    "    print(f\"Total claims: {len(claims_data)}\")\n",
    "    print(f\"Total evidence sets: {total_evidence_sets}\")\n",
    "    print(f\"Unique Wikipedia articles: {len(total_articles)}\")\n",
    "    print(f\"Avg evidence sets per claim: {total_evidence_sets/len(claims_data):.2f}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Wikipedia Knowledge Base Builder for FEVER\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not Path(INPUT_FILE).exists():\n",
    "        print(f\"Input file not found: {INPUT_FILE}\")\n",
    "        print(\"\\nPlease update INPUT_FILE path at the top of this script.\")\n",
    "        return\n",
    "    \n",
    "    # Load FEVER claims\n",
    "    print(f\"Loading FEVER claims from: {INPUT_FILE}\")\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        claims_data = json.load(f)\n",
    "    print(f\"‚úì Loaded {len(claims_data)} claims\\n\")\n",
    "    \n",
    "    # Analyze evidence structure\n",
    "    analyze_evidence_structure(claims_data)\n",
    "    \n",
    "    # Extract Wikipedia article titles\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXTRACTING WIKIPEDIA ARTICLES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    article_titles = extract_wiki_articles_from_evidence(claims_data)\n",
    "    print(f\"\\n‚úì Found {len(article_titles)} unique Wikipedia articles\")\n",
    "    \n",
    "    # Save article titles list\n",
    "    titles_file = Path(OUTPUT_DIR) / \"wikipedia_article_titles.txt\"\n",
    "    with open(titles_file, 'w', encoding='utf-8') as f:\n",
    "        for title in article_titles:\n",
    "            f.write(f\"{title}\\n\")\n",
    "    print(f\"‚úì Saved article titles to: {titles_file}\")\n",
    "    \n",
    "    # Show sample titles\n",
    "    print(\"\\n--- Sample Article Titles ---\")\n",
    "    for i, title in enumerate(article_titles[:20]):\n",
    "        print(f\"  {i+1}. {title}\")\n",
    "    if len(article_titles) > 20:\n",
    "        print(f\"  ... and {len(article_titles) - 20} more\")\n",
    "    \n",
    "    # Create corpus files\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING CORPUS FILES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Full corpus with placeholders\n",
    "    corpus_file = Path(OUTPUT_DIR) / \"wikipedia_corpus_full.json\"\n",
    "    corpus = create_wikipedia_corpus(article_titles, corpus_file)\n",
    "    \n",
    "    # Sample corpus with real content\n",
    "    sample_file = Path(OUTPUT_DIR) / \"wikipedia_corpus_sample.json\"\n",
    "    sample_corpus = create_sample_corpus_with_real_content(sample_file)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úì KNOWLEDGE BASE BUILT SUCCESSFULLY!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nFiles created in: {OUTPUT_DIR}\")\n",
    "    print(f\"  1. wikipedia_article_titles.txt ({len(article_titles)} titles)\")\n",
    "    print(f\"  2. wikipedia_corpus_full.json ({len(corpus)} articles with placeholder text)\")\n",
    "    print(f\"  3. wikipedia_corpus_sample.json ({len(sample_corpus)} articles with real content)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"IMPORTANT NOTES:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if FETCH_REAL_CONTENT and WIKIPEDIA_AVAILABLE:\n",
    "        print(\"\"\"\n",
    "‚úì REAL Wikipedia content has been fetched!\n",
    "  \n",
    "\n",
    "        \"\"\")\n",
    "    else:\n",
    "        print(\"\"\"\n",
    "1. The full corpus contains PLACEHOLDER text\n",
    "   - To get REAL content, install: pip install wikipedia-api\n",
    "   - Then set FETCH_REAL_CONTENT = True at the top of this script\n",
    "   - Run again to fetch actual Wikipedia content\n",
    "\n",
    "2. The sample corpus has REAL content for 5 articles\n",
    "   - Use this to test your RAG system first\n",
    "\n",
    "3. Next steps:\n",
    "   - Install wikipedia-api and re-run to get real content\n",
    "   - Or continue with sample corpus for testing\n",
    "        \"\"\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0aab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Deleted old BM25 index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Delete old index\n",
    "os.remove(r\"C:\\Users\\pooji\\Desktop\\bm25_index.pkl\")\n",
    "print(\"‚úì Deleted old BM25 index\")\n",
    "\n",
    "# Now re-run your main() function\n",
    "# It will rebuild in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fcafa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAG SYSTEM WITH HYBRID RETRIEVAL (FAISS + BM25)\n",
      "============================================================\n",
      "\n",
      "Loading corpus from: C:\\Users\\pooji\\Desktop\\wikipedia_corpus_full.json\n",
      "‚úì Loaded 4649 articles with real content\n",
      "\n",
      "Loading claims from: C:\\Users\\pooji\\Desktop\\fever_claims_full.json\n",
      "‚úì Loaded 15000 claims\n",
      "\n",
      "============================================================\n",
      "BUILDING INDEXES\n",
      "============================================================\n",
      "\n",
      "Initializing Dense Retriever...\n",
      "  Model: sentence-transformers/all-MiniLM-L6-v2\n",
      "‚úì Dense retriever initialized\n",
      "\n",
      "Building FAISS index...\n",
      "  Found existing index, loading...\n",
      "‚úì Loaded FAISS index (1811 vectors)\n",
      "\n",
      "Initializing Sparse Retriever (BM25)...\n",
      "‚úì Sparse retriever initialized\n",
      "\n",
      "Building BM25 index...\n",
      "  Tokenizing 4649 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4649/4649 [00:02<00:00, 1715.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building BM25 index...\n",
      "‚úì BM25 index built\n",
      "\n",
      "  Saving index to: C:\\Users\\pooji\\Desktop\\bm25_index.pkl\n",
      "‚úì Index saved\n",
      "\n",
      "Hybrid Retriever initialized (Œ±=0.5)\n",
      "  Œ±=0.5: Dense weight\n",
      "  1-Œ±=0.5: Sparse weight\n",
      "\n",
      "RAG Generator initialized\n",
      "  Model: gpt-4o-mini\n",
      "\n",
      "============================================================\n",
      "RUNNING PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Testing on 15000 claims...\n",
      "Using top-5 retrieved documents per claim\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15000/15000 [3:11:16<00:00,  1.31it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Accuracy: 62.75%\n",
      "Correct: 9413/15000\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "Actual               SUPPORTS        REFUTES         NOT ENOUGH INFO\n",
      "-----------------------------------------------------------------\n",
      "SUPPORTS             3564            232             1204           \n",
      "REFUTES              349             3628            1023           \n",
      "NOT ENOUGH INFO      1011            1768            2221           \n",
      "\n",
      "‚úì Results saved to: C:\\Users\\pooji\\Desktop\\rag_results_15000_claims.json\n",
      "\n",
      "--- Sample Results ---\n",
      "\n",
      "1. ‚úì Claim: The Wolf of Wall Street was a film of 1999....\n",
      "   Actual: REFUTES | Predicted: REFUTES\n",
      "   Retrieved: Grand Palais, The Wolf of Wall Street (2013 film), Leonardo DiCaprio\n",
      "\n",
      "2. ‚úì Claim: Rope starred Bill Clinton....\n",
      "   Actual: REFUTES | Predicted: REFUTES\n",
      "   Retrieved: Eragon (film), Cape Fear (1991 film), Rope (film)\n",
      "\n",
      "3. ‚úó Claim: Jared Leto has a former name called Toast....\n",
      "   Actual: NOT ENOUGH INFO | Predicted: REFUTES\n",
      "   Retrieved: Carmarthenshire, 30 Seconds to Mars (album), Jared Leto\n",
      "\n",
      "4. ‚úì Claim: Linkin Park is a British rock band....\n",
      "   Actual: REFUTES | Predicted: REFUTES\n",
      "   Retrieved: Dog, Linkin Park, Hybrid Theory\n",
      "\n",
      "5. ‚úó Claim: Celine Dion sings in Arabic....\n",
      "   Actual: REFUTES | Predicted: NOT ENOUGH INFO\n",
      "   Retrieved: Andorra, Celine Dion, Emmy Rossum\n",
      "\n",
      "============================================================\n",
      "‚úì RAG SYSTEM EVALUATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "1. Review results in: C:\\Users\\pooji\\Desktop\\rag_results_15000_claims.json\n",
      "2. Increase NUM_TEST_CLAIMS to test on more data\n",
      "3. Experiment with ALPHA (hybrid weight)\n",
      "4. Add self-consistency and fact verification\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RAG System with Hybrid Retrieval (FAISS + BM25)\n",
    "Complete implementation for FEVER fact-checking with GPT-4o Mini\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Vector search and embeddings\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BM25 for sparse retrieval\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# OpenAI for GPT-4o Mini\n",
    "from openai import OpenAI\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Paths\n",
    "CORPUS_FILE = r\"C:\\Users\\pooji\\Desktop\\wikipedia_corpus_full.json\"\n",
    "CLAIMS_FILE = r\"C:\\Users\\pooji\\Desktop\\fever_claims_full.json\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\pooji\\Desktop\"\n",
    "\n",
    "# Index files (will be created)\n",
    "FAISS_INDEX_FILE = os.path.join(OUTPUT_DIR, \"faiss_index.bin\")\n",
    "BM25_INDEX_FILE = os.path.join(OUTPUT_DIR, \"bm25_index.pkl\")\n",
    "EMBEDDINGS_FILE = os.path.join(OUTPUT_DIR, \"doc_embeddings.npy\")\n",
    "\n",
    "# Retrieval parameters\n",
    "TOP_K = 5  # Number of documents to retrieve\n",
    "ALPHA = 0.5  # Hybrid weight (0.5 = equal weight for dense and sparse)\n",
    "\n",
    "# Model names\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # Fast, good quality\n",
    "GPT_MODEL = \"gpt-4o-mini\"  # GPT-4o Mini for generation\n",
    "\n",
    "# OpenAI API key - SET THIS!\n",
    "OPENAI_API_KEY = \"\"  # Set via: set OPENAI_API_KEY=sk-...\n",
    "\n",
    "# Testing parameters\n",
    "NUM_TEST_CLAIMS = 15000  \n",
    "\n",
    "# ============================================\n",
    "# CORPUS LOADING\n",
    "# ============================================\n",
    "\n",
    "def load_corpus(corpus_file: str) -> List[Dict]:\n",
    "    \"\"\"Load Wikipedia corpus\"\"\"\n",
    "    \n",
    "    print(f\"Loading corpus from: {corpus_file}\")\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as f:\n",
    "        corpus = json.load(f)\n",
    "    \n",
    "    # Filter only successful articles\n",
    "    corpus = [doc for doc in corpus if doc.get('exists', False)]\n",
    "    \n",
    "    print(f\"‚úì Loaded {len(corpus)} articles with real content\\n\")\n",
    "    return corpus\n",
    "\n",
    "def load_claims(claims_file: str, num_claims: int = None) -> List[Dict]:\n",
    "    \"\"\"Load FEVER claims\"\"\"\n",
    "    \n",
    "    print(f\"Loading claims from: {claims_file}\")\n",
    "    with open(claims_file, 'r', encoding='utf-8') as f:\n",
    "        claims = json.load(f)\n",
    "    \n",
    "    if num_claims:\n",
    "        claims = claims[:num_claims]\n",
    "    \n",
    "    print(f\"‚úì Loaded {len(claims)} claims\\n\")\n",
    "    return claims\n",
    "\n",
    "# ============================================\n",
    "# DENSE RETRIEVAL (FAISS)\n",
    "# ============================================\n",
    "\n",
    "class DenseRetriever:\n",
    "    \"\"\"Dense retrieval using sentence embeddings and FAISS\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = EMBEDDING_MODEL):\n",
    "        print(f\"Initializing Dense Retriever...\")\n",
    "        print(f\"  Model: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.corpus = None\n",
    "        print(\"‚úì Dense retriever initialized\\n\")\n",
    "    \n",
    "    def build_index(self, corpus: List[Dict], save_path: str = None):\n",
    "        \"\"\"Build FAISS index from corpus\"\"\"\n",
    "        \n",
    "        print(\"Building FAISS index...\")\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        # Check if index already exists\n",
    "        if save_path and Path(save_path).exists() and Path(save_path.replace('.bin', '_embeddings.npy')).exists():\n",
    "            print(\"  Found existing index, loading...\")\n",
    "            self.load_index(save_path)\n",
    "            return\n",
    "        \n",
    "        # Extract texts\n",
    "        texts = [doc['text'] for doc in corpus]\n",
    "        \n",
    "        # Generate embeddings\n",
    "        print(f\"  Generating embeddings for {len(texts)} documents...\")\n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            show_progress_bar=True,\n",
    "            batch_size=32,\n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        \n",
    "        # Build FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        print(f\"  Building FAISS index (dimension: {dimension})...\")\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner product = cosine similarity after normalization\n",
    "        self.index.add(embeddings.astype('float32'))\n",
    "        \n",
    "        print(f\"‚úì FAISS index built ({self.index.ntotal} vectors)\\n\")\n",
    "        \n",
    "        # Save index\n",
    "        if save_path:\n",
    "            print(f\"  Saving index to: {save_path}\")\n",
    "            faiss.write_index(self.index, save_path)\n",
    "            np.save(save_path.replace('.bin', '_embeddings.npy'), embeddings)\n",
    "            print(\"‚úì Index saved\\n\")\n",
    "    \n",
    "    def load_index(self, index_path: str):\n",
    "        \"\"\"Load pre-built FAISS index\"\"\"\n",
    "        \n",
    "        self.index = faiss.read_index(index_path)\n",
    "        print(f\"‚úì Loaded FAISS index ({self.index.ntotal} vectors)\\n\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = TOP_K) -> Tuple[List[int], List[float]]:\n",
    "        \"\"\"Search for similar documents\"\"\"\n",
    "        \n",
    "        # Encode query\n",
    "        query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # Search\n",
    "        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
    "        \n",
    "        return indices[0].tolist(), scores[0].tolist()\n",
    "\n",
    "# ============================================\n",
    "# SPARSE RETRIEVAL (BM25)\n",
    "# ============================================\n",
    "\n",
    "class SparseRetriever:\n",
    "    \"\"\"Sparse retrieval using BM25\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Initializing Sparse Retriever (BM25)...\")\n",
    "        self.bm25 = None\n",
    "        self.corpus = None\n",
    "        self.tokenized_corpus = None\n",
    "        print(\"‚úì Sparse retriever initialized\\n\")\n",
    "    \n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Simple tokenization\"\"\"\n",
    "        return text.lower().split()\n",
    "    \n",
    "    def build_index(self, corpus: List[Dict], save_path: str = None):\n",
    "        \"\"\"Build BM25 index\"\"\"\n",
    "        \n",
    "        print(\"Building BM25 index...\")\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        # Check if index already exists\n",
    "        if save_path and Path(save_path).exists():\n",
    "            print(\"  Found existing index, loading...\")\n",
    "            self.load_index(save_path)\n",
    "            return\n",
    "        \n",
    "        # Tokenize corpus\n",
    "        texts = [doc['text'] for doc in corpus]\n",
    "        print(f\"  Tokenizing {len(texts)} documents...\")\n",
    "        self.tokenized_corpus = [self.tokenize(text) for text in tqdm(texts, desc=\"Tokenizing\")]\n",
    "        \n",
    "        # Build BM25 index\n",
    "        print(\"  Building BM25 index...\")\n",
    "        self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "        \n",
    "        print(f\"‚úì BM25 index built\\n\")\n",
    "        \n",
    "        # Save index\n",
    "        if save_path:\n",
    "            print(f\"  Saving index to: {save_path}\")\n",
    "            with open(save_path, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'bm25': self.bm25,\n",
    "                    'tokenized_corpus': self.tokenized_corpus\n",
    "                }, f)\n",
    "            print(\"‚úì Index saved\\n\")\n",
    "    \n",
    "    def load_index(self, index_path: str):\n",
    "        \"\"\"Load pre-built BM25 index\"\"\"\n",
    "        \n",
    "        with open(index_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.bm25 = data['bm25']\n",
    "            self.tokenized_corpus = data['tokenized_corpus']\n",
    "        \n",
    "        print(f\"‚úì Loaded BM25 index\\n\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = TOP_K) -> Tuple[List[int], List[float]]:\n",
    "        \"\"\"Search for relevant documents\"\"\"\n",
    "        \n",
    "        # Tokenize query\n",
    "        tokenized_query = self.tokenize(query)\n",
    "        \n",
    "        # Get scores for all documents\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        # Get top-k indices\n",
    "        top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "        top_scores = scores[top_indices]\n",
    "        \n",
    "        return top_indices.tolist(), top_scores.tolist()\n",
    "\n",
    "# ============================================\n",
    "# HYBRID RETRIEVAL\n",
    "# ============================================\n",
    "\n",
    "class HybridRetriever:\n",
    "    \"\"\"Hybrid retrieval combining dense (FAISS) and sparse (BM25)\"\"\"\n",
    "    \n",
    "    def __init__(self, dense_retriever: DenseRetriever, sparse_retriever: SparseRetriever, alpha: float = ALPHA):\n",
    "        self.dense = dense_retriever\n",
    "        self.sparse = sparse_retriever\n",
    "        self.alpha = alpha\n",
    "        print(f\"Hybrid Retriever initialized (Œ±={alpha})\")\n",
    "        print(f\"  Œ±={alpha}: Dense weight\")\n",
    "        print(f\"  1-Œ±={1-alpha}: Sparse weight\\n\")\n",
    "    \n",
    "    def normalize_scores(self, scores: List[float]) -> List[float]:\n",
    "        \"\"\"Normalize scores to [0, 1]\"\"\"\n",
    "        scores = np.array(scores)\n",
    "        if len(scores) == 0 or scores.max() == scores.min():\n",
    "            return scores.tolist()\n",
    "        return ((scores - scores.min()) / (scores.max() - scores.min())).tolist()\n",
    "    \n",
    "    def search(self, query: str, top_k: int = TOP_K) -> List[Dict]:\n",
    "        \"\"\"Hybrid search combining dense and sparse retrieval\"\"\"\n",
    "        \n",
    "        # Dense search\n",
    "        dense_indices, dense_scores = self.dense.search(query, top_k=top_k*2)\n",
    "        dense_scores = self.normalize_scores(dense_scores)\n",
    "        \n",
    "        # Sparse search\n",
    "        sparse_indices, sparse_scores = self.sparse.search(query, top_k=top_k*2)\n",
    "        sparse_scores = self.normalize_scores(sparse_scores)\n",
    "        \n",
    "        # Combine scores\n",
    "        combined_scores = {}\n",
    "        \n",
    "        for idx, score in zip(dense_indices, dense_scores):\n",
    "            combined_scores[idx] = self.alpha * score\n",
    "        \n",
    "        for idx, score in zip(sparse_indices, sparse_scores):\n",
    "            if idx in combined_scores:\n",
    "                combined_scores[idx] += (1 - self.alpha) * score\n",
    "            else:\n",
    "                combined_scores[idx] = (1 - self.alpha) * score\n",
    "        \n",
    "        # Sort by combined score\n",
    "        sorted_items = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        # Get documents\n",
    "        results = []\n",
    "        for idx, score in sorted_items:\n",
    "            doc = self.dense.corpus[idx]  # Both retrievers share same corpus\n",
    "            results.append({\n",
    "                'doc_id': idx,\n",
    "                'article_id': doc['id'],\n",
    "                'title': doc['title'],\n",
    "                'text': doc['text'][:500],  # First 500 chars for display\n",
    "                'full_text': doc['text'],\n",
    "                'score': score\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# GPT-4o MINI GENERATION\n",
    "# ============================================\n",
    "\n",
    "class RAGGenerator:\n",
    "    \"\"\"Generate answers using GPT-4o Mini with retrieved context\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model: str = GPT_MODEL):\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key not set! Set via: set OPENAI_API_KEY=sk-...\")\n",
    "        \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "        print(f\"RAG Generator initialized\")\n",
    "        print(f\"  Model: {model}\\n\")\n",
    "    \n",
    "    def create_prompt(self, claim: str, retrieved_docs: List[Dict]) -> str:\n",
    "        \"\"\"Create prompt with claim and retrieved evidence\"\"\"\n",
    "        \n",
    "        evidence_text = \"\\n\\n\".join([\n",
    "            f\"Article {i+1}: {doc['title']}\\n{doc['full_text'][:1000]}\"\n",
    "            for i, doc in enumerate(retrieved_docs)\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"You are a fact-checking system. Based on the Wikipedia articles provided, determine if the claim is SUPPORTED, REFUTED, or if there is NOT ENOUGH INFO.\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Wikipedia Evidence:\n",
    "{evidence_text}\n",
    "\n",
    "Instructions:\n",
    "1. Carefully read the claim and the evidence\n",
    "2. Determine if the evidence SUPPORTS, REFUTES, or provides NOT ENOUGH INFO for the claim\n",
    "3. Respond with ONLY ONE of these three labels: SUPPORTS, REFUTES, or NOT ENOUGH INFO\n",
    "4. Do not provide explanation, just the label\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def generate(self, claim: str, retrieved_docs: List[Dict]) -> str:\n",
    "        \"\"\"Generate prediction using GPT-4o Mini\"\"\"\n",
    "        \n",
    "        prompt = self.create_prompt(claim, retrieved_docs)\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a precise fact-checking assistant that only responds with one of: SUPPORTS, REFUTES, or NOT ENOUGH INFO.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.0,  # Deterministic\n",
    "                max_tokens=10  # Short response\n",
    "            )\n",
    "            \n",
    "            prediction = response.choices[0].message.content.strip().upper()\n",
    "            \n",
    "            # Normalize response\n",
    "            if \"SUPPORT\" in prediction:\n",
    "                return \"SUPPORTS\"\n",
    "            elif \"REFUTE\" in prediction:\n",
    "                return \"REFUTES\"\n",
    "            elif \"NOT ENOUGH\" in prediction or \"NEI\" in prediction:\n",
    "                return \"NOT ENOUGH INFO\"\n",
    "            else:\n",
    "                return prediction  # Return as-is if unclear\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating prediction: {e}\")\n",
    "            return \"ERROR\"\n",
    "\n",
    "# ============================================\n",
    "# EVALUATION\n",
    "# ============================================\n",
    "\n",
    "def evaluate_predictions(claims: List[Dict], predictions: List[str]) -> Dict:\n",
    "    \"\"\"Calculate accuracy and metrics\"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = len(claims)\n",
    "    \n",
    "    confusion = {\n",
    "        'SUPPORTS': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0},\n",
    "        'REFUTES': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0},\n",
    "        'NOT ENOUGH INFO': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0}\n",
    "    }\n",
    "    \n",
    "    for claim, pred in zip(claims, predictions):\n",
    "        actual = claim['label']\n",
    "        if pred == actual:\n",
    "            correct += 1\n",
    "        \n",
    "        if actual in confusion and pred in confusion[actual]:\n",
    "            confusion[actual][pred] += 1\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'correct': correct,\n",
    "        'total': total,\n",
    "        'confusion_matrix': confusion\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main RAG pipeline execution\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"RAG SYSTEM WITH HYBRID RETRIEVAL (FAISS + BM25)\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    # Check OpenAI API key\n",
    "    if not OPENAI_API_KEY:\n",
    "        print(\"OpenAI API key not set!\")\n",
    "        print(\"\\nPlease set your API key:\")\n",
    "        print(\"  Windows: set OPENAI_API_KEY=sk-your-key-here\")\n",
    "        print(\"  Mac/Linux: export OPENAI_API_KEY=sk-your-key-here\")\n",
    "        print(\"\\nOr edit the OPENAI_API_KEY variable in this script.\")\n",
    "        return\n",
    "    \n",
    "    # Load corpus and claims\n",
    "    corpus = load_corpus(CORPUS_FILE)\n",
    "    claims = load_claims(CLAIMS_FILE, NUM_TEST_CLAIMS)\n",
    "    \n",
    "    # Build/load retrievers\n",
    "    print(\"=\"*60)\n",
    "    print(\"BUILDING INDEXES\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    # Dense retriever (FAISS)\n",
    "    dense_retriever = DenseRetriever()\n",
    "    dense_retriever.build_index(corpus, FAISS_INDEX_FILE)\n",
    "    \n",
    "    # Sparse retriever (BM25)\n",
    "    sparse_retriever = SparseRetriever()\n",
    "    sparse_retriever.build_index(corpus, BM25_INDEX_FILE)\n",
    "    \n",
    "    # Hybrid retriever\n",
    "    hybrid_retriever = HybridRetriever(dense_retriever, sparse_retriever, alpha=ALPHA)\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = RAGGenerator(OPENAI_API_KEY)\n",
    "    \n",
    "    # Run predictions\n",
    "    print(\"=\"*60)\n",
    "    print(\"RUNNING PREDICTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTesting on {len(claims)} claims...\")\n",
    "    print(f\"Using top-{TOP_K} retrieved documents per claim\\n\")\n",
    "    \n",
    "    predictions = []\n",
    "    results = []\n",
    "    \n",
    "    for i, claim_data in enumerate(tqdm(claims, desc=\"Processing claims\")):\n",
    "        claim = claim_data['claim']\n",
    "        actual_label = claim_data['label']\n",
    "        \n",
    "        # Retrieve documents\n",
    "        retrieved_docs = hybrid_retriever.search(claim, top_k=TOP_K)\n",
    "        \n",
    "        # Generate prediction\n",
    "        prediction = generator.generate(claim, retrieved_docs)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        results.append({\n",
    "            'claim_id': claim_data['id'],\n",
    "            'claim': claim,\n",
    "            'actual': actual_label,\n",
    "            'predicted': prediction,\n",
    "            'correct': prediction == actual_label,\n",
    "            'retrieved_articles': [doc['title'] for doc in retrieved_docs]\n",
    "        })\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(0.1)  # Small delay to avoid rate limits\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    metrics = evaluate_predictions(claims, predictions)\n",
    "    \n",
    "    print(f\"Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "    print(f\"Correct: {metrics['correct']}/{metrics['total']}\")\n",
    "    \n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    print(f\"{'Actual':<20} {'SUPPORTS':<15} {'REFUTES':<15} {'NOT ENOUGH INFO':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "    for actual, preds in metrics['confusion_matrix'].items():\n",
    "        print(f\"{actual:<20} {preds['SUPPORTS']:<15} {preds['REFUTES']:<15} {preds['NOT ENOUGH INFO']:<15}\")\n",
    "    \n",
    "    # Save results\n",
    "    output_file = os.path.join(OUTPUT_DIR, f\"rag_results_{NUM_TEST_CLAIMS}_claims.json\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'metrics': metrics,\n",
    "            'results': results,\n",
    "            'config': {\n",
    "                'top_k': TOP_K,\n",
    "                'alpha': ALPHA,\n",
    "                'model': GPT_MODEL,\n",
    "                'num_claims': NUM_TEST_CLAIMS\n",
    "            }\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úì Results saved to: {output_file}\")\n",
    "    \n",
    "    # Sample results\n",
    "    print(\"\\n--- Sample Results ---\")\n",
    "    for i, result in enumerate(results[:5]):\n",
    "        status = \"‚úì\" if result['correct'] else \"‚úó\"\n",
    "        print(f\"\\n{i+1}. {status} Claim: {result['claim'][:80]}...\")\n",
    "        print(f\"   Actual: {result['actual']} | Predicted: {result['predicted']}\")\n",
    "        print(f\"   Retrieved: {', '.join(result['retrieved_articles'][:3])}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úì RAG SYSTEM EVALUATION COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"1. Review results in: {output_file}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2876af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE SYSTEM (GPT-4o Mini WITHOUT RAG)\n",
      "============================================================\n",
      "\n",
      "Loading claims from: C:\\Users\\pooji\\Desktop\\fever_claims_full.json\n",
      "‚úì Loaded 15000 claims\n",
      "\n",
      "Baseline Generator initialized\n",
      "  Model: gpt-4o-mini\n",
      "  Mode: NO RETRIEVAL (pure GPT-4o Mini)\n",
      "\n",
      "============================================================\n",
      "RUNNING BASELINE PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Testing on 15000 claims...\n",
      "Using GPT-4o Mini ONLY (no Wikipedia retrieval)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 13659/15000 [2:52:51<5:34:14, 14.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 13682/15000 [2:54:00<6:07:59, 16.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 13683/15000 [2:54:13<5:45:31, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 13684/15000 [2:54:15<4:10:59, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 13685/15000 [2:54:16<3:05:39,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15000/15000 [3:13:16<00:00,  1.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Baseline Accuracy: 59.05%\n",
      "Correct: 8857/15000\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "Actual               SUPPORTS        REFUTES         NOT ENOUGH INFO\n",
      "-----------------------------------------------------------------\n",
      "SUPPORTS             3867            820             311            \n",
      "REFUTES              527             4109            362            \n",
      "NOT ENOUGH INFO      1405            2713            881            \n",
      "\n",
      "‚úì Results saved to: C:\\Users\\pooji\\Desktop\\baseline_results_15000_claims.json\n",
      "\n",
      "--- Sample Results ---\n",
      "\n",
      "1. ‚úì Claim: The Wolf of Wall Street was a film of 1999....\n",
      "   Actual: REFUTES | Predicted: REFUTES\n",
      "\n",
      "2. ‚úì Claim: Rope starred Bill Clinton....\n",
      "   Actual: REFUTES | Predicted: REFUTES\n",
      "\n",
      "3. ‚úó Claim: Jared Leto has a former name called Toast....\n",
      "   Actual: NOT ENOUGH INFO | Predicted: REFUTES\n",
      "\n",
      "4. ‚úì Claim: Linkin Park is a British rock band....\n",
      "   Actual: REFUTES | Predicted: REFUTES\n",
      "\n",
      "5. ‚úì Claim: Celine Dion sings in Arabic....\n",
      "   Actual: REFUTES | Predicted: REFUTES\n",
      "\n",
      "============================================================\n",
      "‚úì BASELINE EVALUATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "1. Run RAG system: python 04_rag_system_hybrid.py\n",
      "2. Compare results:\n",
      "   - Baseline: C:\\Users\\pooji\\Desktop\\baseline_results_15000_claims.json\n",
      "   - RAG: rag_results_15000_claims.json\n",
      "3. Calculate improvement: RAG accuracy - Baseline accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Baseline System - GPT-4o Mini WITHOUT RAG\n",
    "For comparison with RAG system\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "CLAIMS_FILE = r\"C:\\Users\\pooji\\Desktop\\fever_claims_full.json\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\pooji\\Desktop\"\n",
    "\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "NUM_TEST_CLAIMS = 15000  # Same as RAG system for fair comparison\n",
    "\n",
    "# ============================================\n",
    "# BASELINE GENERATOR\n",
    "# ============================================\n",
    "\n",
    "class BaselineGenerator:\n",
    "    \"\"\"Generate predictions using GPT-4o Mini WITHOUT any retrieval\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model: str = GPT_MODEL):\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key not set!\")\n",
    "        \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "        print(f\"Baseline Generator initialized\")\n",
    "        print(f\"  Model: {model}\")\n",
    "        print(f\"  Mode: NO RETRIEVAL (pure GPT-4o Mini)\\n\")\n",
    "    \n",
    "    def create_prompt(self, claim: str) -> str:\n",
    "        \"\"\"Create prompt WITHOUT any Wikipedia evidence\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"You are a fact-checking system. Determine if the following claim is true, false, or if you don't have enough information.\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Instructions:\n",
    "1. Based on your knowledge, determine if the claim is:\n",
    "   - SUPPORTS: The claim is true\n",
    "   - REFUTES: The claim is false\n",
    "   - NOT ENOUGH INFO: You cannot determine from your knowledge\n",
    "2. Respond with ONLY ONE of these three labels\n",
    "3. Do not provide explanation, just the label\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def generate(self, claim: str) -> str:\n",
    "        \"\"\"Generate prediction using GPT-4o Mini alone\"\"\"\n",
    "        \n",
    "        prompt = self.create_prompt(claim)\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a precise fact-checking assistant that only responds with one of: SUPPORTS, REFUTES, or NOT ENOUGH INFO.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=10\n",
    "            )\n",
    "            \n",
    "            prediction = response.choices[0].message.content.strip().upper()\n",
    "            \n",
    "            # Normalize response\n",
    "            if \"SUPPORT\" in prediction:\n",
    "                return \"SUPPORTS\"\n",
    "            elif \"REFUTE\" in prediction:\n",
    "                return \"REFUTES\"\n",
    "            elif \"NOT ENOUGH\" in prediction or \"NEI\" in prediction:\n",
    "                return \"NOT ENOUGH INFO\"\n",
    "            else:\n",
    "                return prediction\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return \"ERROR\"\n",
    "\n",
    "# ============================================\n",
    "# EVALUATION\n",
    "# ============================================\n",
    "\n",
    "def evaluate_predictions(claims, predictions):\n",
    "    \"\"\"Calculate accuracy and metrics\"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = len(claims)\n",
    "    \n",
    "    confusion = {\n",
    "        'SUPPORTS': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0},\n",
    "        'REFUTES': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0},\n",
    "        'NOT ENOUGH INFO': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0}\n",
    "    }\n",
    "    \n",
    "    for claim, pred in zip(claims, predictions):\n",
    "        actual = claim['label']\n",
    "        if pred == actual:\n",
    "            correct += 1\n",
    "        \n",
    "        if actual in confusion and pred in confusion[actual]:\n",
    "            confusion[actual][pred] += 1\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'correct': correct,\n",
    "        'total': total,\n",
    "        'confusion_matrix': confusion\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# MAIN\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Run baseline evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"BASELINE SYSTEM (GPT-4o Mini WITHOUT RAG)\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    # Check API key\n",
    "    if not OPENAI_API_KEY:\n",
    "        print(\"OpenAI API key not set!\")\n",
    "        print(\"\\nSet via: set OPENAI_API_KEY=sk-your-key\")\n",
    "        return\n",
    "    \n",
    "    # Load claims\n",
    "    print(f\"Loading claims from: {CLAIMS_FILE}\")\n",
    "    with open(CLAIMS_FILE, 'r', encoding='utf-8') as f:\n",
    "        claims = json.load(f)\n",
    "    \n",
    "    claims = claims[:NUM_TEST_CLAIMS]\n",
    "    print(f\"‚úì Loaded {len(claims)} claims\\n\")\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = BaselineGenerator(OPENAI_API_KEY)\n",
    "    \n",
    "    # Run predictions\n",
    "    print(\"=\"*60)\n",
    "    print(\"RUNNING BASELINE PREDICTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTesting on {len(claims)} claims...\")\n",
    "    print(\"Using GPT-4o Mini ONLY (no Wikipedia retrieval)\\n\")\n",
    "    \n",
    "    predictions = []\n",
    "    results = []\n",
    "    \n",
    "    for claim_data in tqdm(claims, desc=\"Processing claims\"):\n",
    "        claim = claim_data['claim']\n",
    "        actual_label = claim_data['label']\n",
    "        \n",
    "        # Generate prediction WITHOUT retrieval\n",
    "        prediction = generator.generate(claim)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        results.append({\n",
    "            'claim_id': claim_data['id'],\n",
    "            'claim': claim,\n",
    "            'actual': actual_label,\n",
    "            'predicted': prediction,\n",
    "            'correct': prediction == actual_label\n",
    "        })\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BASELINE EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    metrics = evaluate_predictions(claims, predictions)\n",
    "    \n",
    "    print(f\"Baseline Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "    print(f\"Correct: {metrics['correct']}/{metrics['total']}\")\n",
    "    \n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    print(f\"{'Actual':<20} {'SUPPORTS':<15} {'REFUTES':<15} {'NOT ENOUGH INFO':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "    for actual, preds in metrics['confusion_matrix'].items():\n",
    "        print(f\"{actual:<20} {preds['SUPPORTS']:<15} {preds['REFUTES']:<15} {preds['NOT ENOUGH INFO']:<15}\")\n",
    "    \n",
    "    # Save results\n",
    "    output_file = os.path.join(OUTPUT_DIR, f\"baseline_results_{NUM_TEST_CLAIMS}_claims.json\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'system': 'baseline',\n",
    "            'description': 'GPT-4o Mini without RAG (no retrieval)',\n",
    "            'metrics': metrics,\n",
    "            'results': results,\n",
    "            'config': {\n",
    "                'model': GPT_MODEL,\n",
    "                'num_claims': NUM_TEST_CLAIMS,\n",
    "                'retrieval': False\n",
    "            }\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úì Results saved to: {output_file}\")\n",
    "    \n",
    "    # Sample results\n",
    "    print(\"\\n--- Sample Results ---\")\n",
    "    for i, result in enumerate(results[:5]):\n",
    "        status = \"‚úì\" if result['correct'] else \"‚úó\"\n",
    "        print(f\"\\n{i+1}. {status} Claim: {result['claim'][:80]}...\")\n",
    "        print(f\"   Actual: {result['actual']} | Predicted: {result['predicted']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úì BASELINE EVALUATION COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84906f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üß™ TESTING NLI MODEL (Specialized for Fact-Checking)\n",
      "======================================================================\n",
      "\n",
      "üì• Loading model: cross-encoder/nli-deberta-v3-base\n",
      "   This model is trained specifically for Natural Language Inference\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0f4a2548114b73b7ab06d629853c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pooji\\.cache\\huggingface\\hub\\models--cross-encoder--nli-deberta-v3-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f9c69495284dae947c55303dcdedcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15770ee2b64d4d2facf2d2e49e688ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c467a14c5464253bd86cd07e957f47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cc35e252a64ff3ad8100e712dba804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f36405d81ce442d8a290328bc21bda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734cf1e444cd48088a4baa4aa9ec99cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded successfully\n",
      "\n",
      "üß™ Test Cases:\n",
      "======================================================================\n",
      "\n",
      "üìù Test 1:\n",
      "   Premise: Barack Obama was the 44th president of the United States from 2009 to 2017.\n",
      "   Hypothesis: Barack Obama served as president.\n",
      "\n",
      "   Result:\n",
      "   ‚Ä¢ Predicted Label: ENTAILMENT\n",
      "   ‚Ä¢ Entailment Score: 99.82%\n",
      "   ‚Ä¢ All Probabilities:\n",
      "     - Contradiction: 0.01%\n",
      "     - Neutral: 0.17%\n",
      "     - Entailment: 99.82%\n",
      "   ‚Ä¢ Expected: ENTAILMENT\n",
      "   ‚Ä¢ Status: ‚úì CORRECT\n",
      "   ------------------------------------------------------------------\n",
      "\n",
      "üìù Test 2:\n",
      "   Premise: The Eiffel Tower is located in Paris, France.\n",
      "   Hypothesis: The Eiffel Tower is in London.\n",
      "\n",
      "   Result:\n",
      "   ‚Ä¢ Predicted Label: CONTRADICTION\n",
      "   ‚Ä¢ Entailment Score: 0.01%\n",
      "   ‚Ä¢ All Probabilities:\n",
      "     - Contradiction: 99.98%\n",
      "     - Neutral: 0.01%\n",
      "     - Entailment: 0.01%\n",
      "   ‚Ä¢ Expected: CONTRADICTION\n",
      "   ‚Ä¢ Status: ‚úì CORRECT\n",
      "   ------------------------------------------------------------------\n",
      "\n",
      "üìù Test 3:\n",
      "   Premise: Python is a high-level programming language.\n",
      "   Hypothesis: The weather is sunny today.\n",
      "\n",
      "   Result:\n",
      "   ‚Ä¢ Predicted Label: NEUTRAL\n",
      "   ‚Ä¢ Entailment Score: 0.02%\n",
      "   ‚Ä¢ All Probabilities:\n",
      "     - Contradiction: 0.32%\n",
      "     - Neutral: 99.66%\n",
      "     - Entailment: 0.02%\n",
      "   ‚Ä¢ Expected: NEUTRAL\n",
      "   ‚Ä¢ Status: ‚úì CORRECT\n",
      "   ------------------------------------------------------------------\n",
      "\n",
      "üìù Test 4:\n",
      "   Premise: UMBC is located in Baltimore County, Maryland.\n",
      "   Hypothesis: UMBC is a university in Maryland.\n",
      "\n",
      "   Result:\n",
      "   ‚Ä¢ Predicted Label: ENTAILMENT\n",
      "   ‚Ä¢ Entailment Score: 93.42%\n",
      "   ‚Ä¢ All Probabilities:\n",
      "     - Contradiction: 0.00%\n",
      "     - Neutral: 6.58%\n",
      "     - Entailment: 93.42%\n",
      "   ‚Ä¢ Expected: ENTAILMENT\n",
      "   ‚Ä¢ Status: ‚úì CORRECT\n",
      "   ------------------------------------------------------------------\n",
      "\n",
      "üìù Test 5:\n",
      "   Premise: The Pacific Ocean is the largest ocean on Earth.\n",
      "   Hypothesis: The Atlantic Ocean is the largest ocean.\n",
      "\n",
      "   Result:\n",
      "   ‚Ä¢ Predicted Label: CONTRADICTION\n",
      "   ‚Ä¢ Entailment Score: 0.01%\n",
      "   ‚Ä¢ All Probabilities:\n",
      "     - Contradiction: 99.93%\n",
      "     - Neutral: 0.06%\n",
      "     - Entailment: 0.01%\n",
      "   ‚Ä¢ Expected: CONTRADICTION\n",
      "   ‚Ä¢ Status: ‚úì CORRECT\n",
      "   ------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "‚úÖ NLI MODEL TEST COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üìä Summary:\n",
      "   ‚Ä¢ Model is specifically trained for NLI\n",
      "   ‚Ä¢ Outputs: CONTRADICTION, NEUTRAL, ENTAILMENT\n",
      "   ‚Ä¢ Ready for hallucination detection integration\n",
      "\n",
      "üöÄ Next Step: Integrate into ensemble system\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Script: Using Pre-trained NLI Model\n",
    "Best for fact-checking and hallucination detection\n",
    "\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üß™ TESTING NLI MODEL (Specialized for Fact-Checking)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# This model is specifically trained for NLI tasks\n",
    "model_name = \"cross-encoder/nli-deberta-v3-base\"\n",
    "\n",
    "# Load model\n",
    "print(f\"\\nüì• Loading model: {model_name}\")\n",
    "print(\"   This model is trained specifically for Natural Language Inference\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "print(\"‚úì Model loaded successfully\\n\")\n",
    "\n",
    "def get_entailment_score(premise, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculate entailment score between premise and hypothesis\n",
    "    \n",
    "    Returns:\n",
    "        - entailment_score (0-1): probability of entailment\n",
    "        - label: CONTRADICTION, NEUTRAL, or ENTAILMENT\n",
    "        - all_probs: [contradiction, neutral, entailment]\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", \n",
    "                      truncation=True, max_length=512)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "    \n",
    "    # This model outputs: [contradiction, entailment, neutral]\n",
    "    # Re-order to standard: [contradiction, neutral, entailment]\n",
    "    reordered_probs = torch.tensor([probs[0][0], probs[0][2], probs[0][1]])\n",
    "    \n",
    "    labels = [\"CONTRADICTION\", \"NEUTRAL\", \"ENTAILMENT\"]\n",
    "    pred_idx = torch.argmax(reordered_probs).item()\n",
    "    pred_label = labels[pred_idx]\n",
    "    entailment_score = reordered_probs[2].item()\n",
    "    \n",
    "    return entailment_score, pred_label, reordered_probs.tolist()\n",
    "\n",
    "# Test cases\n",
    "print(\"üß™ Test Cases:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"premise\": \"Barack Obama was the 44th president of the United States from 2009 to 2017.\",\n",
    "        \"hypothesis\": \"Barack Obama served as president.\",\n",
    "        \"expected\": \"ENTAILMENT\"\n",
    "    },\n",
    "    {\n",
    "        \"premise\": \"The Eiffel Tower is located in Paris, France.\",\n",
    "        \"hypothesis\": \"The Eiffel Tower is in London.\",\n",
    "        \"expected\": \"CONTRADICTION\"\n",
    "    },\n",
    "    {\n",
    "        \"premise\": \"Python is a high-level programming language.\",\n",
    "        \"hypothesis\": \"The weather is sunny today.\",\n",
    "        \"expected\": \"NEUTRAL\"\n",
    "    },\n",
    "    {\n",
    "        \"premise\": \"UMBC is located in Baltimore County, Maryland.\",\n",
    "        \"hypothesis\": \"UMBC is a university in Maryland.\",\n",
    "        \"expected\": \"ENTAILMENT\"\n",
    "    },\n",
    "    {\n",
    "        \"premise\": \"The Pacific Ocean is the largest ocean on Earth.\",\n",
    "        \"hypothesis\": \"The Atlantic Ocean is the largest ocean.\",\n",
    "        \"expected\": \"CONTRADICTION\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüìù Test {i}:\")\n",
    "    print(f\"   Premise: {test['premise']}\")\n",
    "    print(f\"   Hypothesis: {test['hypothesis']}\")\n",
    "    \n",
    "    score, label, probs = get_entailment_score(test['premise'], test['hypothesis'])\n",
    "    \n",
    "    print(f\"\\n   Result:\")\n",
    "    print(f\"   ‚Ä¢ Predicted Label: {label}\")\n",
    "    print(f\"   ‚Ä¢ Entailment Score: {score:.2%}\")\n",
    "    print(f\"   ‚Ä¢ All Probabilities:\")\n",
    "    print(f\"     - Contradiction: {probs[0]:.2%}\")\n",
    "    print(f\"     - Neutral: {probs[1]:.2%}\")\n",
    "    print(f\"     - Entailment: {probs[2]:.2%}\")\n",
    "    print(f\"   ‚Ä¢ Expected: {test['expected']}\")\n",
    "    print(f\"   ‚Ä¢ Status: {'‚úì CORRECT' if label == test['expected'] else '‚ö† MISMATCH'}\")\n",
    "    print(\"   \" + \"-\" * 66)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ NLI MODEL TEST COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìä Summary:\")\n",
    "print(\"   ‚Ä¢ Model is specifically trained for NLI\")\n",
    "print(\"   ‚Ä¢ Outputs: CONTRADICTION, NEUTRAL, ENTAILMENT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419e2aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üß™ TESTING ENTROPY CALCULATOR\n",
      "======================================================================\n",
      "üßÆ Entropy Calculator initialized\n",
      "\n",
      "üìù Test 1: Perfect Consistency\n",
      "   Answers: ['Paris', 'Paris', 'Paris', 'Paris', 'Paris']\n",
      "   Entropy: -0.000\n",
      "   Normalized Entropy: 0.000\n",
      "   Interpretation: Should be 0 (perfect certainty)\n",
      "   Status: ‚úì CORRECT\n",
      "\n",
      "üìù Test 2: Maximum Uncertainty\n",
      "   Answers: ['Paris', 'London', 'Berlin', 'Madrid', 'Rome']\n",
      "   Entropy: 2.322\n",
      "   Normalized Entropy: 1.000\n",
      "   Interpretation: Should be ~1.0 (maximum uncertainty)\n",
      "   Status: ‚úì CORRECT\n",
      "\n",
      "üìù Test 3: Moderate Uncertainty\n",
      "   Answers: ['Paris', 'Paris', 'Paris', 'London', 'London']\n",
      "   Entropy: 0.971\n",
      "   Normalized Entropy: 0.971\n",
      "   Distribution: {'Paris': 3, 'London': 2}\n",
      "   Interpretation: Should be moderate (~0.5-0.7)\n",
      "\n",
      "üìù Test 4: Semantic Entropy (Answer Groups)\n",
      "   Group 1 (size 3): ['Paris', 'Paris, France', 'Paris in France']\n",
      "   Group 2 (size 2): ['London', 'London, UK']\n",
      "   Semantic Entropy: 0.971\n",
      "   Normalized: 0.971\n",
      "   Group Probabilities: [0.6, 0.4]\n",
      "\n",
      "üìù Test 5: NLI Entropy\n",
      "   NLI Scores: [[0.01, 0.02, 0.97], [0.02, 0.01, 0.97], [0.01, 0.03, 0.96]]\n",
      "   Avg Probabilities: [0.013333333333333334, 0.02, 0.9666666666666667]\n",
      "   NLI Entropy: 0.243\n",
      "   Normalized: 0.153\n",
      "   Interpretation: Very certain (low entropy)\n",
      "\n",
      "üìù Test 6: Combined Confidence Score\n",
      "   Inputs:\n",
      "     - Semantic Entropy: 0.2 (low)\n",
      "     - NLI Entropy: 0.15 (low)\n",
      "     - Consistency: 80%\n",
      "   Output:\n",
      "     - Combined Confidence: 81.0%\n",
      "     - Risk Level: LOW ‚úÖ\n",
      "     - Components: {'self_consistency': 80, 'semantic_certainty': 80.0, 'nli_certainty': 85.0}\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ENTROPY CALCULATOR TEST COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üöÄ Ready to integrate into hallucination detection system!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Entropy-Based Uncertainty Quantification\n",
    "Measures confidence in answer distributions\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "class EntropyCalculator:\n",
    "    \"\"\"Calculate entropy and uncertainty metrics for answer distributions\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"üßÆ Entropy Calculator initialized\")\n",
    "    \n",
    "    def calculate_shannon_entropy(self, probabilities):\n",
    "        \"\"\"\n",
    "        Calculate Shannon entropy from probability distribution\n",
    "        \n",
    "        Args:\n",
    "            probabilities: List of probabilities (should sum to 1.0)\n",
    "        \n",
    "        Returns:\n",
    "            entropy_score: 0 (certain) to log2(n) (maximum uncertainty)\n",
    "            normalized_entropy: 0 (certain) to 1.0 (maximum uncertainty)\n",
    "        \"\"\"\n",
    "        probs = np.array(probabilities)\n",
    "        \n",
    "        # Remove zeros to avoid log(0)\n",
    "        probs = probs[probs > 0]\n",
    "        \n",
    "        if len(probs) == 0:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        # Calculate Shannon entropy\n",
    "        h = -np.sum(probs * np.log2(probs))\n",
    "        \n",
    "        # Normalize by max possible entropy (uniform distribution)\n",
    "        max_entropy = np.log2(len(probabilities))\n",
    "        normalized_h = h / max_entropy if max_entropy > 0 else 0.0\n",
    "        \n",
    "        return h, normalized_h\n",
    "    \n",
    "    def calculate_answer_distribution_entropy(self, answers):\n",
    "        \"\"\"\n",
    "        Calculate entropy from a list of answers\n",
    "        \n",
    "        Args:\n",
    "            answers: List of answer strings\n",
    "        \n",
    "        Returns:\n",
    "            dict with entropy metrics and distribution\n",
    "        \"\"\"\n",
    "        if not answers:\n",
    "            return {\n",
    "                'entropy': 0.0,\n",
    "                'normalized_entropy': 0.0,\n",
    "                'num_unique': 0,\n",
    "                'distribution': {}\n",
    "            }\n",
    "        \n",
    "        # Count answer frequencies\n",
    "        answer_counts = Counter(answers)\n",
    "        total = len(answers)\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        probabilities = [count / total for count in answer_counts.values()]\n",
    "        \n",
    "        # Calculate entropy\n",
    "        h, normalized_h = self.calculate_shannon_entropy(probabilities)\n",
    "        \n",
    "        return {\n",
    "            'entropy': h,\n",
    "            'normalized_entropy': normalized_h,\n",
    "            'num_unique': len(answer_counts),\n",
    "            'distribution': dict(answer_counts),\n",
    "            'probabilities': {ans: count/total for ans, count in answer_counts.items()}\n",
    "        }\n",
    "    \n",
    "    def calculate_semantic_entropy(self, answer_groups):\n",
    "        \"\"\"\n",
    "        Calculate entropy from semantically grouped answers\n",
    "        \n",
    "        Args:\n",
    "            answer_groups: List of lists, where each inner list contains similar answers\n",
    "        \n",
    "        Returns:\n",
    "            dict with entropy metrics\n",
    "        \"\"\"\n",
    "        if not answer_groups:\n",
    "            return {\n",
    "                'entropy': 0.0,\n",
    "                'normalized_entropy': 0.0,\n",
    "                'num_groups': 0\n",
    "            }\n",
    "        \n",
    "        total_answers = sum(len(group) for group in answer_groups)\n",
    "        \n",
    "        # Calculate probability of each group\n",
    "        group_probs = [len(group) / total_answers for group in answer_groups]\n",
    "        \n",
    "        # Calculate entropy\n",
    "        h, normalized_h = self.calculate_shannon_entropy(group_probs)\n",
    "        \n",
    "        return {\n",
    "            'entropy': h,\n",
    "            'normalized_entropy': normalized_h,\n",
    "            'num_groups': len(answer_groups),\n",
    "            'group_sizes': [len(g) for g in answer_groups],\n",
    "            'group_probabilities': group_probs\n",
    "        }\n",
    "    \n",
    "    def calculate_nli_entropy(self, nli_scores):\n",
    "        \"\"\"\n",
    "        Calculate entropy from NLI probability distributions\n",
    "        \n",
    "        Args:\n",
    "            nli_scores: List of [contradiction, neutral, entailment] probabilities\n",
    "        \n",
    "        Returns:\n",
    "            dict with entropy metrics\n",
    "        \"\"\"\n",
    "        if not nli_scores:\n",
    "            return {'entropy': 0.0, 'normalized_entropy': 0.0}\n",
    "        \n",
    "        # Average probabilities across multiple predictions\n",
    "        avg_probs = np.mean(nli_scores, axis=0)\n",
    "        \n",
    "        # Calculate entropy\n",
    "        h, normalized_h = self.calculate_shannon_entropy(avg_probs)\n",
    "        \n",
    "        return {\n",
    "            'entropy': h,\n",
    "            'normalized_entropy': normalized_h,\n",
    "            'avg_probabilities': avg_probs.tolist(),\n",
    "            'interpretation': self._interpret_entropy(normalized_h)\n",
    "        }\n",
    "    \n",
    "    def calculate_combined_confidence(self, semantic_entropy, nli_entropy, \n",
    "                                     consistency_score):\n",
    "        \"\"\"\n",
    "        Combine multiple entropy measures into overall confidence\n",
    "        \n",
    "        Args:\n",
    "            semantic_entropy: Normalized entropy from answer clustering (0-1)\n",
    "            nli_entropy: Normalized entropy from NLI predictions (0-1)\n",
    "            consistency_score: Percentage of consistent answers (0-100)\n",
    "        \n",
    "        Returns:\n",
    "            dict with combined confidence score and risk level\n",
    "        \"\"\"\n",
    "        # Convert consistency to 0-1 scale\n",
    "        consistency_normalized = consistency_score / 100.0\n",
    "        \n",
    "        # Calculate certainty (inverse of entropy)\n",
    "        semantic_certainty = 1.0 - semantic_entropy\n",
    "        nli_certainty = 1.0 - nli_entropy\n",
    "        \n",
    "        # Weighted combination\n",
    "        # Higher weight on semantic certainty (self-consistency most important)\n",
    "        combined_certainty = (\n",
    "            0.50 * consistency_normalized +  # Self-consistency\n",
    "            0.30 * semantic_certainty +       # Semantic clustering\n",
    "            0.20 * nli_certainty              # NLI confidence\n",
    "        )\n",
    "        \n",
    "        # Convert to confidence percentage\n",
    "        confidence = combined_certainty * 100\n",
    "        \n",
    "        # Determine risk level\n",
    "        if confidence >= 85:\n",
    "            risk_level = \"VERY LOW\"\n",
    "            risk_color = \"‚úÖ‚úÖ\"\n",
    "        elif confidence >= 70:\n",
    "            risk_level = \"LOW\"\n",
    "            risk_color = \"‚úÖ\"\n",
    "        elif confidence >= 50:\n",
    "            risk_level = \"MEDIUM\"\n",
    "            risk_color = \"‚ö†Ô∏è\"\n",
    "        else:\n",
    "            risk_level = \"HIGH\"\n",
    "            risk_color = \"‚ö†Ô∏è‚ö†Ô∏è\"\n",
    "        \n",
    "        return {\n",
    "            'confidence_score': confidence,\n",
    "            'risk_level': risk_level,\n",
    "            'risk_color': risk_color,\n",
    "            'components': {\n",
    "                'self_consistency': consistency_score,\n",
    "                'semantic_certainty': semantic_certainty * 100,\n",
    "                'nli_certainty': nli_certainty * 100\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _interpret_entropy(self, normalized_entropy):\n",
    "        \"\"\"Interpret normalized entropy value\"\"\"\n",
    "        if normalized_entropy < 0.3:\n",
    "            return \"Very certain (low entropy)\"\n",
    "        elif normalized_entropy < 0.6:\n",
    "            return \"Moderately certain\"\n",
    "        else:\n",
    "            return \"Uncertain (high entropy)\"\n",
    "\n",
    "# ============================================\n",
    "# TEST THE ENTROPY CALCULATOR\n",
    "# ============================================\n",
    "\n",
    "def test_entropy_calculator():\n",
    "    \"\"\"Test entropy calculations with examples\"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üß™ TESTING ENTROPY CALCULATOR\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    calc = EntropyCalculator()\n",
    "    \n",
    "    # Test 1: Perfect consistency (5 identical answers)\n",
    "    print(\"\\nüìù Test 1: Perfect Consistency\")\n",
    "    answers1 = [\"Paris\"] * 5\n",
    "    result1 = calc.calculate_answer_distribution_entropy(answers1)\n",
    "    print(f\"   Answers: {answers1}\")\n",
    "    print(f\"   Entropy: {result1['entropy']:.3f}\")\n",
    "    print(f\"   Normalized Entropy: {result1['normalized_entropy']:.3f}\")\n",
    "    print(f\"   Interpretation: Should be 0 (perfect certainty)\")\n",
    "    print(f\"   Status: {'‚úì CORRECT' if result1['normalized_entropy'] < 0.1 else '‚úó WRONG'}\")\n",
    "    \n",
    "    # Test 2: Maximum uncertainty (5 different answers)\n",
    "    print(\"\\nüìù Test 2: Maximum Uncertainty\")\n",
    "    answers2 = [\"Paris\", \"London\", \"Berlin\", \"Madrid\", \"Rome\"]\n",
    "    result2 = calc.calculate_answer_distribution_entropy(answers2)\n",
    "    print(f\"   Answers: {answers2}\")\n",
    "    print(f\"   Entropy: {result2['entropy']:.3f}\")\n",
    "    print(f\"   Normalized Entropy: {result2['normalized_entropy']:.3f}\")\n",
    "    print(f\"   Interpretation: Should be ~1.0 (maximum uncertainty)\")\n",
    "    print(f\"   Status: {'‚úì CORRECT' if result2['normalized_entropy'] > 0.9 else '‚úó WRONG'}\")\n",
    "    \n",
    "    # Test 3: Moderate uncertainty (3 Paris, 2 London)\n",
    "    print(\"\\nüìù Test 3: Moderate Uncertainty\")\n",
    "    answers3 = [\"Paris\", \"Paris\", \"Paris\", \"London\", \"London\"]\n",
    "    result3 = calc.calculate_answer_distribution_entropy(answers3)\n",
    "    print(f\"   Answers: {answers3}\")\n",
    "    print(f\"   Entropy: {result3['entropy']:.3f}\")\n",
    "    print(f\"   Normalized Entropy: {result3['normalized_entropy']:.3f}\")\n",
    "    print(f\"   Distribution: {result3['distribution']}\")\n",
    "    print(f\"   Interpretation: Should be moderate (~0.5-0.7)\")\n",
    "    \n",
    "    # Test 4: Semantic grouping\n",
    "    print(\"\\nüìù Test 4: Semantic Entropy (Answer Groups)\")\n",
    "    groups = [\n",
    "        [\"Paris\", \"Paris, France\", \"Paris in France\"],  # 3 similar\n",
    "        [\"London\", \"London, UK\"]  # 2 similar\n",
    "    ]\n",
    "    result4 = calc.calculate_semantic_entropy(groups)\n",
    "    print(f\"   Group 1 (size {len(groups[0])}): {groups[0]}\")\n",
    "    print(f\"   Group 2 (size {len(groups[1])}): {groups[1]}\")\n",
    "    print(f\"   Semantic Entropy: {result4['entropy']:.3f}\")\n",
    "    print(f\"   Normalized: {result4['normalized_entropy']:.3f}\")\n",
    "    print(f\"   Group Probabilities: {result4['group_probabilities']}\")\n",
    "    \n",
    "    # Test 5: NLI entropy\n",
    "    print(\"\\nüìù Test 5: NLI Entropy\")\n",
    "    # NLI scores: [contradiction, neutral, entailment]\n",
    "    nli_scores = [\n",
    "        [0.01, 0.02, 0.97],  # Very confident entailment\n",
    "        [0.02, 0.01, 0.97],  # Very confident entailment\n",
    "        [0.01, 0.03, 0.96]   # Very confident entailment\n",
    "    ]\n",
    "    result5 = calc.calculate_nli_entropy(nli_scores)\n",
    "    print(f\"   NLI Scores: {nli_scores}\")\n",
    "    print(f\"   Avg Probabilities: {result5['avg_probabilities']}\")\n",
    "    print(f\"   NLI Entropy: {result5['entropy']:.3f}\")\n",
    "    print(f\"   Normalized: {result5['normalized_entropy']:.3f}\")\n",
    "    print(f\"   Interpretation: {result5['interpretation']}\")\n",
    "    \n",
    "    # Test 6: Combined confidence\n",
    "    print(\"\\nüìù Test 6: Combined Confidence Score\")\n",
    "    combined = calc.calculate_combined_confidence(\n",
    "        semantic_entropy=0.2,      # Low entropy (good)\n",
    "        nli_entropy=0.15,          # Low entropy (good)\n",
    "        consistency_score=80       # 80% consistency\n",
    "    )\n",
    "    print(f\"   Inputs:\")\n",
    "    print(f\"     - Semantic Entropy: 0.2 (low)\")\n",
    "    print(f\"     - NLI Entropy: 0.15 (low)\")\n",
    "    print(f\"     - Consistency: 80%\")\n",
    "    print(f\"   Output:\")\n",
    "    print(f\"     - Combined Confidence: {combined['confidence_score']:.1f}%\")\n",
    "    print(f\"     - Risk Level: {combined['risk_level']} {combined['risk_color']}\")\n",
    "    print(f\"     - Components: {combined['components']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ ENTROPY CALCULATOR TEST COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nüöÄ Ready to integrate into hallucination detection system!\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_entropy_calculator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa935362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì EntropyCalculator class defined!\n"
     ]
    }
   ],
   "source": [
    "# EntropyCalculator class (inline version for Jupyter)\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class EntropyCalculator:\n",
    "    \"\"\"Calculate entropy and uncertainty metrics for answer distributions\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def calculate_shannon_entropy(self, probabilities):\n",
    "        \"\"\"Calculate Shannon entropy from probability distribution\"\"\"\n",
    "        probs = np.array(probabilities)\n",
    "        probs = probs[probs > 0]\n",
    "        \n",
    "        if len(probs) == 0:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        h = -np.sum(probs * np.log2(probs))\n",
    "        max_entropy = np.log2(len(probabilities))\n",
    "        normalized_h = h / max_entropy if max_entropy > 0 else 0.0\n",
    "        \n",
    "        return h, normalized_h\n",
    "    \n",
    "    def calculate_semantic_entropy(self, answer_groups):\n",
    "        \"\"\"Calculate entropy from semantically grouped answers\"\"\"\n",
    "        if not answer_groups:\n",
    "            return {\n",
    "                'entropy': 0.0,\n",
    "                'normalized_entropy': 0.0,\n",
    "                'num_groups': 0\n",
    "            }\n",
    "        \n",
    "        total_answers = sum(len(group) for group in answer_groups)\n",
    "        group_probs = [len(group) / total_answers for group in answer_groups]\n",
    "        h, normalized_h = self.calculate_shannon_entropy(group_probs)\n",
    "        \n",
    "        return {\n",
    "            'entropy': h,\n",
    "            'normalized_entropy': normalized_h,\n",
    "            'num_groups': len(answer_groups),\n",
    "            'group_sizes': [len(g) for g in answer_groups],\n",
    "            'group_probabilities': group_probs\n",
    "        }\n",
    "    \n",
    "    def calculate_nli_entropy(self, nli_scores):\n",
    "        \"\"\"Calculate entropy from NLI probability distributions\"\"\"\n",
    "        if not nli_scores:\n",
    "            return {'entropy': 0.0, 'normalized_entropy': 0.0}\n",
    "        \n",
    "        avg_probs = np.mean(nli_scores, axis=0)\n",
    "        h, normalized_h = self.calculate_shannon_entropy(avg_probs)\n",
    "        \n",
    "        return {\n",
    "            'entropy': h,\n",
    "            'normalized_entropy': normalized_h,\n",
    "            'avg_probabilities': avg_probs.tolist(),\n",
    "            'interpretation': self._interpret_entropy(normalized_h)\n",
    "        }\n",
    "    \n",
    "    def calculate_combined_confidence(self, semantic_entropy, nli_entropy, consistency_score):\n",
    "        \"\"\"Combine multiple entropy measures into overall confidence\"\"\"\n",
    "        consistency_normalized = consistency_score / 100.0\n",
    "        semantic_certainty = 1.0 - semantic_entropy\n",
    "        nli_certainty = 1.0 - nli_entropy\n",
    "        \n",
    "        combined_certainty = (\n",
    "            0.50 * consistency_normalized +\n",
    "            0.30 * semantic_certainty +\n",
    "            0.20 * nli_certainty\n",
    "        )\n",
    "        \n",
    "        confidence = combined_certainty * 100\n",
    "        \n",
    "        if confidence >= 85:\n",
    "            risk_level, risk_color = \"VERY LOW\", \"‚úÖ‚úÖ\"\n",
    "        elif confidence >= 70:\n",
    "            risk_level, risk_color = \"LOW\", \"‚úÖ\"\n",
    "        elif confidence >= 50:\n",
    "            risk_level, risk_color = \"MEDIUM\", \"‚ö†Ô∏è\"\n",
    "        else:\n",
    "            risk_level, risk_color = \"HIGH\", \"‚ö†Ô∏è‚ö†Ô∏è\"\n",
    "        \n",
    "        return {\n",
    "            'confidence_score': confidence,\n",
    "            'risk_level': risk_level,\n",
    "            'risk_color': risk_color,\n",
    "            'components': {\n",
    "                'self_consistency': consistency_score,\n",
    "                'semantic_certainty': semantic_certainty * 100,\n",
    "                'nli_certainty': nli_certainty * 100\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _interpret_entropy(self, normalized_entropy):\n",
    "        \"\"\"Interpret normalized entropy value\"\"\"\n",
    "        if normalized_entropy < 0.3:\n",
    "            return \"Very certain (low entropy)\"\n",
    "        elif normalized_entropy < 0.6:\n",
    "            return \"Moderately certain\"\n",
    "        else:\n",
    "            return \"Uncertain (high entropy)\"\n",
    "\n",
    "print(\"‚úì EntropyCalculator class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc1a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéì Enhanced Hallucination Detection System v3.2\n",
      "   Complete 8-Layer Verification with Claim Support\n",
      "======================================================================\n",
      "\n",
      "üî¨ All 8 Verification Layers:\n",
      "   1. Wikipedia Search (FAISS + BM25)\n",
      "   2. Cross-Encoder Re-ranking\n",
      "   3. Self-Consistency Detection (5 attempts)\n",
      "   4. Semantic Clustering\n",
      "   5. Neural NLI Verification\n",
      "   6. Entropy-Based Uncertainty\n",
      "   7. Web Search Verification\n",
      "   8. Claim Verification (FEVER) üÜï\n",
      "\n",
      "Initializing all components...\n",
      "\n",
      "======================================================================\n",
      "Initializing Enhanced Hallucination Detection System v3.2...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:15:47,768 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-11-11 01:15:50,918 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-11-11 01:15:52,521 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì All systems operational!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úÖ System Ready!\n",
      "======================================================================\n",
      "\n",
      "üåê Launching interface...\n",
      "\n",
      "* Running on local URL:  http://0.0.0.0:7889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:15:54,949 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:15:56,762 - httpx - INFO - HTTP Request: GET http://localhost:7889/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:15:59,023 - httpx - INFO - HTTP Request: HEAD http://localhost:7889/ \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:15:59,928 - httpx - INFO - HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://c6b86f645b462823de.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:16:02,255 - httpx - INFO - HTTP Request: HEAD https://c6b86f645b462823de.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c6b86f645b462823de.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\gradio\\routes.py:1341: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "  return await queue_join_helper(body, request, username)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5474e31482334a08a46a4b97f6bb8df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b871d505f34b4bae876882e06b5aa329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:16:28,974 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:16:31,643 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:16:33,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:16:35,817 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:16:38,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645789bde83449ce91f6672ad7eb122d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a79508a451f46ed8d2b0ae9126cbafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b172a5f2134c31986d8a0168cf345f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd99a38d2f934722b43c353a25523156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:16:41,606 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=What%20is%20UMBC%3F 200\n",
      "2025-11-11 01:16:41,954 - primp - INFO - response: https://search.yahoo.com/search;_ylt=tUxK9bV6NShcIHTQP0JjT9TV;_ylu=AWmnB-QXdRAP3d-0fvU8eoHKzwiXW6R9evJV3k0sQNbISPM?p=What+is+UMBC%3F 200\n",
      "2025-11-11 01:16:42,190 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts&titles=What%20If%20I%20Stumble%3F&explaintext=0&exintro=0&redirects=1 200\n",
      "2025-11-11 01:16:46,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Hallucination Detection System v3.2\n",
    "Complete 8-Layer System with Claim Verification for FEVER\n",
    "\"\"\"\n",
    "\n",
    "import gradio as gr\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ddgs import DDGS\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "OPENAI_API_KEY = \"\"  # SET YOUR KEY HERE\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "CORPUS_FILE = r\"C:\\Users\\pooji\\Desktop\\wikipedia_corpus_full.json\"\n",
    "FAISS_INDEX_FILE = r\"C:\\Users\\pooji\\Desktop\\faiss_index.bin\"\n",
    "BM25_INDEX_FILE = r\"C:\\Users\\pooji\\Desktop\\bm25_index.pkl\"\n",
    "\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "NLI_MODEL = \"cross-encoder/nli-deberta-v3-base\"\n",
    "RERANK_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "NUM_CONSISTENCY_CHECKS = 5\n",
    "TEMPERATURE = 0.3\n",
    "SIMILARITY_THRESHOLD = 0.85\n",
    "WEB_SEARCH_RESULTS = 5\n",
    "\n",
    "# ============================================\n",
    "# ENTROPY CALCULATOR\n",
    "# ============================================\n",
    "\n",
    "class EntropyCalculator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def calculate_shannon_entropy(self, probabilities):\n",
    "        probs = np.array(probabilities)\n",
    "        probs = probs[probs > 0]\n",
    "        if len(probs) == 0:\n",
    "            return 0.0, 0.0\n",
    "        h = -np.sum(probs * np.log2(probs))\n",
    "        max_entropy = np.log2(len(probabilities))\n",
    "        normalized_h = h / max_entropy if max_entropy > 0 else 0.0\n",
    "        return h, normalized_h\n",
    "    \n",
    "    def calculate_semantic_entropy(self, answer_groups):\n",
    "        if not answer_groups:\n",
    "            return {'entropy': 0.0, 'normalized_entropy': 0.0, 'num_groups': 0}\n",
    "        total_answers = sum(len(group) for group in answer_groups)\n",
    "        group_probs = [len(group) / total_answers for group in answer_groups]\n",
    "        h, normalized_h = self.calculate_shannon_entropy(group_probs)\n",
    "        return {\n",
    "            'entropy': h,\n",
    "            'normalized_entropy': normalized_h,\n",
    "            'num_groups': len(answer_groups),\n",
    "            'group_sizes': [len(g) for g in answer_groups],\n",
    "            'group_probabilities': group_probs\n",
    "        }\n",
    "    \n",
    "    def calculate_nli_entropy(self, nli_scores):\n",
    "        if not nli_scores:\n",
    "            return {'entropy': 0.0, 'normalized_entropy': 0.0}\n",
    "        avg_probs = np.mean(nli_scores, axis=0)\n",
    "        h, normalized_h = self.calculate_shannon_entropy(avg_probs)\n",
    "        return {\n",
    "            'entropy': h,\n",
    "            'normalized_entropy': normalized_h,\n",
    "            'avg_probabilities': avg_probs.tolist()\n",
    "        }\n",
    "    \n",
    "    def calculate_combined_confidence(self, semantic_entropy, nli_entropy, consistency_score, web_match=None):\n",
    "        consistency_normalized = consistency_score / 100.0\n",
    "        semantic_certainty = 1.0 - semantic_entropy\n",
    "        nli_certainty = 1.0 - nli_entropy\n",
    "        \n",
    "        if web_match is not None:\n",
    "            web_normalized = web_match / 100.0\n",
    "            combined_certainty = (\n",
    "                0.35 * consistency_normalized +\n",
    "                0.25 * semantic_certainty +\n",
    "                0.15 * nli_certainty +\n",
    "                0.25 * web_normalized\n",
    "            )\n",
    "        else:\n",
    "            combined_certainty = (\n",
    "                0.50 * consistency_normalized +\n",
    "                0.30 * semantic_certainty +\n",
    "                0.20 * nli_certainty\n",
    "            )\n",
    "        \n",
    "        confidence = combined_certainty * 100\n",
    "        \n",
    "        has_web_contradiction = False\n",
    "        if web_match is not None and web_match < 30 and consistency_score > 80:\n",
    "            confidence = max(confidence, 55)\n",
    "            confidence = min(confidence, 65)\n",
    "            has_web_contradiction = True\n",
    "        \n",
    "        if confidence >= 85:\n",
    "            risk_level, risk_color = \"VERY LOW\", \"#10b981\"\n",
    "        elif confidence >= 70:\n",
    "            risk_level, risk_color = \"LOW\", \"#3b82f6\"\n",
    "        elif confidence >= 50:\n",
    "            risk_level, risk_color = \"MEDIUM\", \"#f59e0b\"\n",
    "        else:\n",
    "            risk_level, risk_color = \"HIGH\", \"#ef4444\"\n",
    "        \n",
    "        return {\n",
    "            'confidence_score': confidence,\n",
    "            'risk_level': risk_level,\n",
    "            'risk_color': risk_color,\n",
    "            'has_web_contradiction': has_web_contradiction,\n",
    "            'components': {\n",
    "                'self_consistency': consistency_score,\n",
    "                'semantic_certainty': semantic_certainty * 100,\n",
    "                'nli_certainty': nli_certainty * 100,\n",
    "                'web_match': web_match if web_match is not None else 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "# ============================================\n",
    "# üÜï CLAIM VERIFIER (Layer 8)\n",
    "# ============================================\n",
    "\n",
    "class ClaimVerifier:\n",
    "    \"\"\"\n",
    "    Layer 8: Verify if a claim is supported by the generated answer\n",
    "    Uses NLI to classify: SUPPORTS, REFUTES, or NOT ENOUGH INFO\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nli_model, nli_tokenizer):\n",
    "        \"\"\"Initialize with existing NLI model\"\"\"\n",
    "        self.nli_model = nli_model\n",
    "        self.nli_tokenizer = nli_tokenizer\n",
    "    \n",
    "    def verify_claim(self, claim: str, answer: str) -> dict:\n",
    "        \"\"\"\n",
    "        Check if the answer supports, refutes, or is neutral to the claim\n",
    "        \n",
    "        Args:\n",
    "            claim: The claim to verify\n",
    "            answer: The generated answer from the system\n",
    "        \n",
    "        Returns:\n",
    "            dict with label, scores, and confidence\n",
    "        \"\"\"\n",
    "        \n",
    "        # Tokenize: answer is premise, claim is hypothesis\n",
    "        inputs = self.nli_tokenizer(\n",
    "            answer,  # premise\n",
    "            claim,   # hypothesis\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        # Get NLI predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.nli_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Reorder: [contradiction, entailment, neutral] ‚Üí [contradiction, neutral, entailment]\n",
    "        reordered_probs = torch.tensor([probs[0][0], probs[0][2], probs[0][1]])\n",
    "        \n",
    "        contradiction_score = reordered_probs[0].item()\n",
    "        neutral_score = reordered_probs[1].item()\n",
    "        entailment_score = reordered_probs[2].item()\n",
    "        \n",
    "        # Decision logic\n",
    "        if entailment_score > 0.7:\n",
    "            label = 'SUPPORTS'\n",
    "        elif contradiction_score > 0.6:\n",
    "            label = 'REFUTES'\n",
    "        else:\n",
    "            label = 'NOT ENOUGH INFO'\n",
    "        \n",
    "        return {\n",
    "            'label': label,\n",
    "            'entailment_score': entailment_score,\n",
    "            'contradiction_score': contradiction_score,\n",
    "            'neutral_score': neutral_score,\n",
    "            'confidence': max(entailment_score, contradiction_score, neutral_score),\n",
    "            'all_scores': {\n",
    "                'SUPPORTS': entailment_score,\n",
    "                'REFUTES': contradiction_score,\n",
    "                'NOT ENOUGH INFO': neutral_score\n",
    "            }\n",
    "        }\n",
    "\n",
    "# ============================================\n",
    "# HALLUCINATION DETECTOR\n",
    "# ============================================\n",
    "\n",
    "class HallucinationDetector:\n",
    "    def __init__(self, progress=None):\n",
    "        self.progress = progress\n",
    "        self.update_progress(\"Loading Wikipedia corpus...\", 0.05)\n",
    "        self.articles = self.load_wikipedia()\n",
    "        \n",
    "        self.update_progress(\"Loading FAISS index...\", 0.15)\n",
    "        self.faiss_index = faiss.read_index(FAISS_INDEX_FILE) if os.path.exists(FAISS_INDEX_FILE) else None\n",
    "        \n",
    "        self.update_progress(\"Loading BM25 index...\", 0.25)\n",
    "        self.bm25 = self.load_bm25()\n",
    "        \n",
    "        self.update_progress(\"Loading embedding model...\", 0.35)\n",
    "        self.embedding_model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "        \n",
    "        self.update_progress(\"Loading cross-encoder re-ranker...\", 0.50)\n",
    "        self.cross_encoder = CrossEncoder(RERANK_MODEL)\n",
    "        \n",
    "        self.update_progress(\"Loading NLI model...\", 0.65)\n",
    "        self.nli_tokenizer = AutoTokenizer.from_pretrained(NLI_MODEL)\n",
    "        self.nli_model = AutoModelForSequenceClassification.from_pretrained(NLI_MODEL)\n",
    "        \n",
    "        self.update_progress(\"Initializing entropy calculator...\", 0.85)\n",
    "        self.entropy_calc = EntropyCalculator()\n",
    "        \n",
    "        # üÜï NEW: Initialize claim verifier\n",
    "        self.update_progress(\"Initializing claim verifier...\", 0.92)\n",
    "        self.claim_verifier = ClaimVerifier(self.nli_model, self.nli_tokenizer)\n",
    "        \n",
    "        self.update_progress(\"System ready!\", 1.0)\n",
    "    \n",
    "    def update_progress(self, message, progress):\n",
    "        if self.progress:\n",
    "            self.progress(progress, desc=message)\n",
    "    \n",
    "    def load_wikipedia(self):\n",
    "        articles = []\n",
    "        try:\n",
    "            with open(CORPUS_FILE, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        if isinstance(item, dict):\n",
    "                            text = item.get('text', item.get('content', ''))\n",
    "                        else:\n",
    "                            text = str(item)\n",
    "                        if text and len(str(text).strip()) > 50:\n",
    "                            articles.append(str(text))\n",
    "        except:\n",
    "            pass\n",
    "        return articles\n",
    "    \n",
    "    def load_bm25(self):\n",
    "        if os.path.exists(BM25_INDEX_FILE):\n",
    "            try:\n",
    "                with open(BM25_INDEX_FILE, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    if isinstance(data, dict):\n",
    "                        return data['bm25']\n",
    "                    elif isinstance(data, BM25Okapi):\n",
    "                        return data\n",
    "            except:\n",
    "                pass\n",
    "        return self.create_bm25()\n",
    "    \n",
    "    def create_bm25(self):\n",
    "        tokenized_corpus = [doc.lower().split() for doc in self.articles]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        with open(BM25_INDEX_FILE, 'wb') as f:\n",
    "            pickle.dump({'bm25': bm25, 'tokenized_corpus': tokenized_corpus}, f)\n",
    "        return bm25\n",
    "    \n",
    "    def search_wikipedia(self, query, top_k=5):\n",
    "        if not self.faiss_index or not self.articles:\n",
    "            return []\n",
    "        \n",
    "        query_embedding = self.embedding_model.encode([query])\n",
    "        faiss_distances, faiss_indices = self.faiss_index.search(query_embedding.astype('float32'), top_k)\n",
    "        faiss_scores = 1 / (1 + faiss_distances[0])\n",
    "        \n",
    "        tokenized_query = query.lower().split()\n",
    "        bm25_scores = self.bm25.get_scores(tokenized_query)\n",
    "        bm25_indices = np.argsort(bm25_scores)[-top_k:][::-1]\n",
    "        \n",
    "        combined_indices = list(set(list(faiss_indices[0]) + list(bm25_indices)))\n",
    "        \n",
    "        results = []\n",
    "        for idx in combined_indices[:top_k*2]:\n",
    "            if idx < len(self.articles):\n",
    "                faiss_score = faiss_scores[list(faiss_indices[0]).index(idx)] if idx in faiss_indices[0] else 0\n",
    "                bm25_score = bm25_scores[idx] if idx < len(bm25_scores) else 0\n",
    "                normalized_faiss = float(faiss_score)\n",
    "                normalized_bm25 = float(bm25_score) / (max(bm25_scores) + 0.001)\n",
    "                combined_score = (normalized_faiss + normalized_bm25) / 2\n",
    "                \n",
    "                article_text = str(self.articles[idx])\n",
    "                title = article_text.split('\\n')[0][:100] if '\\n' in article_text else article_text[:100]\n",
    "                \n",
    "                results.append({\n",
    "                    'text': article_text,\n",
    "                    'title': title,\n",
    "                    'score': combined_score\n",
    "                })\n",
    "        \n",
    "        results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        return results\n",
    "    \n",
    "    def rerank_documents(self, query, documents, top_k=3):\n",
    "        if not documents:\n",
    "            return []\n",
    "        \n",
    "        pairs = [(query, doc['text'][:512]) for doc in documents]\n",
    "        rerank_scores = self.cross_encoder.predict(pairs)\n",
    "        \n",
    "        for i, doc in enumerate(documents):\n",
    "            doc['rerank_score'] = float(rerank_scores[i])\n",
    "            doc['final_score'] = 0.6 * doc['rerank_score'] + 0.4 * doc['score']\n",
    "        \n",
    "        documents.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "        return documents[:top_k]\n",
    "    \n",
    "    def generate_answer_rag(self, query, context):\n",
    "        prompt = f\"\"\"Based on the following context, answer the question. If the context doesn't contain enough information, say \"I don't have enough information in these sources.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=GPT_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=TEMPERATURE,\n",
    "                max_tokens=200\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except:\n",
    "            return \"Error generating answer\"\n",
    "    \n",
    "    def generate_answer_pretrained(self, query):\n",
    "        prompt = f\"\"\"Answer the following question using your knowledge. Be concise and factual.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=GPT_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=TEMPERATURE,\n",
    "                max_tokens=200\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except:\n",
    "            return \"Error generating answer\"\n",
    "    \n",
    "    def is_dont_know_answer(self, answer):\n",
    "        dont_know_phrases = [\n",
    "            \"don't have enough information\", \"cannot provide\", \"unable to answer\",\n",
    "            \"don't know\", \"no information\", \"not enough information\"\n",
    "        ]\n",
    "        return any(phrase in answer.lower() for phrase in dont_know_phrases)\n",
    "    \n",
    "    def semantic_similarity(self, text1, text2):\n",
    "        try:\n",
    "            embeddings = self.embedding_model.encode([text1, text2])\n",
    "            return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def group_similar_answers(self, answers):\n",
    "        if not answers:\n",
    "            return []\n",
    "        groups = []\n",
    "        for answer in answers:\n",
    "            placed = False\n",
    "            for group in groups:\n",
    "                if self.semantic_similarity(answer, group[0]) >= SIMILARITY_THRESHOLD:\n",
    "                    group.append(answer)\n",
    "                    placed = True\n",
    "                    break\n",
    "            if not placed:\n",
    "                groups.append([answer])\n",
    "        groups.sort(key=len, reverse=True)\n",
    "        return groups\n",
    "    \n",
    "    def verify_with_nli(self, claim, evidence):\n",
    "        inputs = self.nli_tokenizer(evidence, claim, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.nli_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "        reordered_probs = torch.tensor([probs[0][0], probs[0][2], probs[0][1]])\n",
    "        labels = [\"CONTRADICTION\", \"NEUTRAL\", \"ENTAILMENT\"]\n",
    "        pred_idx = torch.argmax(reordered_probs).item()\n",
    "        return {\n",
    "            'label': labels[pred_idx],\n",
    "            'entailment_score': reordered_probs[2].item(),\n",
    "            'probabilities': reordered_probs.tolist()\n",
    "        }\n",
    "    \n",
    "    def web_search(self, query):\n",
    "        results = []\n",
    "        try:\n",
    "            ddgs = DDGS()\n",
    "            search_results = ddgs.text(query, max_results=WEB_SEARCH_RESULTS)\n",
    "            for result in search_results:\n",
    "                results.append({\n",
    "                    'title': result.get('title', 'No title'),\n",
    "                    'url': result.get('href', 'No URL'),\n",
    "                    'snippet': result.get('body', 'No snippet')\n",
    "                })\n",
    "        except:\n",
    "            pass\n",
    "        return results\n",
    "    \n",
    "    def verify_with_web(self, answer, query):\n",
    "        try:\n",
    "            web_results = self.web_search(query)\n",
    "            if not web_results:\n",
    "                return None\n",
    "            \n",
    "            web_context = \"\\n\\n\".join([f\"Source {i+1}: {r['title']}\\n{r['snippet']}\" for i, r in enumerate(web_results)])\n",
    "            \n",
    "            verification_prompt = f\"\"\"Compare the following answer with web search results and determine if they match.\n",
    "\n",
    "Answer to verify: {answer}\n",
    "\n",
    "Web search results:\n",
    "{web_context}\n",
    "\n",
    "Rate the match from 0-100% and explain briefly. Format: \"MATCH: X% - explanation\"\n",
    "\"\"\"\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=GPT_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": verification_prompt}],\n",
    "                temperature=0.1,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            \n",
    "            verification = response.choices[0].message.content.strip()\n",
    "            match_percent = 0\n",
    "            match = re.search(r'(\\d+)%', verification)\n",
    "            if match:\n",
    "                match_percent = int(match.group(1))\n",
    "            \n",
    "            return {\n",
    "                'web_results': web_results,\n",
    "                'verification': verification,\n",
    "                'match_percent': match_percent\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def is_claim_input(self, text):\n",
    "        \"\"\"Detect if input is a claim (vs a question)\"\"\"\n",
    "        # Has question mark?\n",
    "        if '?' in text:\n",
    "            return False\n",
    "        \n",
    "        # Starts with question word?\n",
    "        question_words = ['who', 'what', 'when', 'where', 'why', 'how', 'which', 'tell', 'explain', 'describe']\n",
    "        first_word = text.strip().lower().split()[0] if text.strip() else ''\n",
    "        if first_word in question_words:\n",
    "            return False\n",
    "        \n",
    "        # Otherwise it's likely a claim\n",
    "        return True\n",
    "    \n",
    "    def explain_confidence(self, results):\n",
    "        explanations = []\n",
    "        \n",
    "        if results['consistency_score'] >= 80:\n",
    "            explanations.append((\"‚úÖ\", \"High agreement across all 5 verification attempts\"))\n",
    "        elif results['consistency_score'] >= 60:\n",
    "            explanations.append((\"‚ö†Ô∏è\", \"Moderate variation detected in answer consistency\"))\n",
    "        else:\n",
    "            explanations.append((\"‚ùå\", \"Significant disagreement between verification attempts\"))\n",
    "        \n",
    "        if results['semantic_entropy'] < 0.3:\n",
    "            explanations.append((\"‚úÖ\", \"Answers are semantically very similar\"))\n",
    "        elif results['semantic_entropy'] < 0.6:\n",
    "            explanations.append((\"‚ö†Ô∏è\", \"Some semantic variation in answers\"))\n",
    "        else:\n",
    "            explanations.append((\"‚ùå\", \"High semantic uncertainty detected\"))\n",
    "        \n",
    "        if results['nli_results']:\n",
    "            entailment_count = sum(1 for r in results['nli_results'] if r['label'] == 'ENTAILMENT')\n",
    "            contradiction_count = sum(1 for r in results['nli_results'] if r['label'] == 'CONTRADICTION')\n",
    "            \n",
    "            if entailment_count >= 2:\n",
    "                explanations.append((\"‚úÖ\", f\"Strong evidence support: {entailment_count}/3 sources entail the answer\"))\n",
    "            elif contradiction_count >= 2:\n",
    "                explanations.append((\"‚ùå\", f\"Evidence contradicts answer: {contradiction_count}/3 sources\"))\n",
    "            else:\n",
    "                explanations.append((\"‚ö†Ô∏è\", \"Limited or neutral evidence from sources\"))\n",
    "        \n",
    "        if results['web_match'] >= 70:\n",
    "            explanations.append((\"‚úÖ\", f\"Strong web verification: {results['web_match']}% match\"))\n",
    "        elif results['web_match'] >= 40:\n",
    "            explanations.append((\"‚ö†Ô∏è\", f\"Partial web agreement: {results['web_match']}% match\"))\n",
    "        elif results['web_match'] > 0:\n",
    "            explanations.append((\"‚ùå\", f\"Web sources disagree: {results['web_match']}% match\"))\n",
    "        \n",
    "        if results.get('used_reranking'):\n",
    "            explanations.append((\"üéØ\", \"Cross-encoder re-ranking improved retrieval quality\"))\n",
    "        \n",
    "        if results.get('claim_verification'):\n",
    "            cv = results['claim_verification']\n",
    "            explanations.append((\"üéØ\", f\"Claim verification: {cv['label']} ({cv['confidence']*100:.0f}% confidence)\"))\n",
    "        \n",
    "        return explanations\n",
    "    \n",
    "    def detect(self, query, progress=None):\n",
    "        \"\"\"Main detection method with all 8 layers\"\"\"\n",
    "        \n",
    "        if progress is None:\n",
    "            progress = lambda x, desc='': None\n",
    "        \n",
    "        results = {\n",
    "            'query': query,\n",
    "            'answer': '',\n",
    "            'mode': 'Unknown',\n",
    "            'mode_reason': '',\n",
    "            'wiki_articles': [],\n",
    "            'wiki_score': 0,\n",
    "            'consistency_score': 0,\n",
    "            'semantic_entropy': 0,\n",
    "            'nli_results': [],\n",
    "            'nli_entropy': 0,\n",
    "            'combined_confidence': 0,\n",
    "            'risk_level': '',\n",
    "            'risk_color': '',\n",
    "            'has_web_contradiction': False,\n",
    "            'web_results': [],\n",
    "            'web_match': 0,\n",
    "            'all_answers': [],\n",
    "            'used_reranking': False,\n",
    "            'used_fallback': False,\n",
    "            'num_answer_groups': 0,\n",
    "            'explanations': [],\n",
    "            'verification_log': [],\n",
    "            'claim_verification': None,\n",
    "            'fever_label': None\n",
    "        }\n",
    "        \n",
    "        # Wikipedia search\n",
    "        progress(0.1, desc=\"üîç Layer 1: Wikipedia Search...\")\n",
    "        wiki_results = self.search_wikipedia(query, top_k=10)\n",
    "        results['verification_log'].append((\"üîç\", \"Wikipedia Search\", f\"Found {len(wiki_results)} initial articles\"))\n",
    "        \n",
    "        # Cross-encoder re-ranking\n",
    "        if wiki_results:\n",
    "            progress(0.15, desc=\"üéØ Layer 2: Cross-Encoder Re-ranking...\")\n",
    "            wiki_results = self.rerank_documents(query, wiki_results, top_k=3)\n",
    "            results['used_reranking'] = True\n",
    "            results['wiki_articles'] = [r['title'] for r in wiki_results]\n",
    "            results['wiki_score'] = wiki_results[0]['final_score'] if wiki_results else 0\n",
    "            results['verification_log'].append((\"üéØ\", \"Cross-Encoder Re-ranking\", f\"Re-ranked to top 3 articles (score: {results['wiki_score']:.2f})\"))\n",
    "        \n",
    "        # Determine mode\n",
    "        best_score = wiki_results[0]['final_score'] if wiki_results else 0\n",
    "        use_rag = best_score > 0.3 and len(wiki_results) > 0\n",
    "        \n",
    "        if use_rag:\n",
    "            results['mode'] = \"RAG\"\n",
    "            results['mode_reason'] = f\"Wikipedia relevance score: {best_score:.0%} (>30% threshold)\"\n",
    "            results['verification_log'].append((\"‚úÖ\", \"Mode Selection\", f\"RAG mode activated (relevance: {best_score:.0%})\"))\n",
    "        else:\n",
    "            results['mode'] = \"Pretrained\"\n",
    "            results['mode_reason'] = f\"Wikipedia relevance too low: {best_score:.0%} (<30% threshold)\"\n",
    "            results['verification_log'].append((\"‚ö†Ô∏è\", \"Mode Selection\", \"Pretrained mode - insufficient Wikipedia relevance\"))\n",
    "        \n",
    "        # Self-consistency\n",
    "        progress(0.3, desc=f\"üîÑ Layer 3: Self-Consistency ({NUM_CONSISTENCY_CHECKS} attempts)...\")\n",
    "        answers = []\n",
    "        for i in range(NUM_CONSISTENCY_CHECKS):\n",
    "            if use_rag:\n",
    "                context = \"\\n\\n\".join([r['text'][:500] for r in wiki_results])\n",
    "                answer = self.generate_answer_rag(query, context)\n",
    "            else:\n",
    "                answer = self.generate_answer_pretrained(query)\n",
    "            answers.append(answer)\n",
    "            time.sleep(0.3)\n",
    "        \n",
    "        results['verification_log'].append((\"üîÑ\", \"Self-Consistency\", f\"Generated {NUM_CONSISTENCY_CHECKS} independent answers\"))\n",
    "        \n",
    "        # Smart fallback\n",
    "        all_dont_know = all(self.is_dont_know_answer(a) for a in answers)\n",
    "        if use_rag and all_dont_know:\n",
    "            progress(0.45, desc=\"üîÑ Smart Fallback Activated...\")\n",
    "            answers = [self.generate_answer_pretrained(query) for _ in range(NUM_CONSISTENCY_CHECKS)]\n",
    "            results['mode'] = \"Pretrained (Fallback)\"\n",
    "            results['mode_reason'] = \"RAG gave insufficient answers, switched to pretrained knowledge\"\n",
    "            results['used_fallback'] = True\n",
    "            results['verification_log'].append((\"üîÑ\", \"Smart Fallback\", \"RAG insufficient ‚Üí switched to pretrained\"))\n",
    "        \n",
    "        results['all_answers'] = answers\n",
    "        \n",
    "        # Semantic clustering\n",
    "        progress(0.5, desc=\"üß¨ Layer 4: Semantic Clustering...\")\n",
    "        answer_groups = self.group_similar_answers(answers)\n",
    "        largest_group = answer_groups[0] if answer_groups else []\n",
    "        consensus_answer = largest_group[0] if largest_group else answers[0]\n",
    "        consistency_score = len(largest_group) / len(answers) * 100\n",
    "        \n",
    "        results['answer'] = consensus_answer\n",
    "        results['consistency_score'] = consistency_score\n",
    "        results['num_answer_groups'] = len(answer_groups)\n",
    "        results['verification_log'].append((\"üß¨\", \"Semantic Clustering\", f\"Formed {len(answer_groups)} distinct groups (largest: {len(largest_group)}/{len(answers)})\"))\n",
    "        \n",
    "        # NLI verification\n",
    "        progress(0.60, desc=\"üß† Layer 5: NLI Verification...\")\n",
    "        nli_results = []\n",
    "        if use_rag and wiki_results:\n",
    "            for wiki_doc in wiki_results:\n",
    "                nli_result = self.verify_with_nli(consensus_answer, wiki_doc['text'][:500])\n",
    "                nli_results.append(nli_result)\n",
    "        results['nli_results'] = nli_results\n",
    "        \n",
    "        if nli_results:\n",
    "            entail_count = sum(1 for r in nli_results if r['label'] == 'ENTAILMENT')\n",
    "            results['verification_log'].append((\"üß†\", \"NLI Verification\", f\"Verified against {len(nli_results)} sources ({entail_count} entailments)\"))\n",
    "        \n",
    "        # Entropy calculation\n",
    "        progress(0.70, desc=\"üìä Layer 6: Entropy Calculation...\")\n",
    "        semantic_entropy_result = self.entropy_calc.calculate_semantic_entropy(answer_groups)\n",
    "        results['semantic_entropy'] = semantic_entropy_result['normalized_entropy']\n",
    "        \n",
    "        nli_entropy_result = {'normalized_entropy': 0.0}\n",
    "        if nli_results:\n",
    "            nli_probs = [r['probabilities'] for r in nli_results]\n",
    "            nli_entropy_result = self.entropy_calc.calculate_nli_entropy(nli_probs)\n",
    "        results['nli_entropy'] = nli_entropy_result['normalized_entropy']\n",
    "        results['verification_log'].append((\"üìä\", \"Entropy Analysis\", f\"Semantic: {results['semantic_entropy']:.3f}, NLI: {results['nli_entropy']:.3f}\"))\n",
    "        \n",
    "        # Web verification\n",
    "        progress(0.80, desc=\"üåê Layer 7: Web Verification...\")\n",
    "        web_verification = self.verify_with_web(consensus_answer, query)\n",
    "        if web_verification:\n",
    "            results['web_results'] = web_verification['web_results']\n",
    "            results['web_match'] = web_verification['match_percent']\n",
    "            results['verification_log'].append((\"üåê\", \"Web Verification\", f\"Matched {results['web_match']}% with {len(results['web_results'])} web sources\"))\n",
    "        \n",
    "        # Final confidence calculation (before claim verification)\n",
    "        combined_confidence = self.entropy_calc.calculate_combined_confidence(\n",
    "            semantic_entropy=results['semantic_entropy'],\n",
    "            nli_entropy=results['nli_entropy'],\n",
    "            consistency_score=consistency_score,\n",
    "            web_match=results['web_match']\n",
    "        )\n",
    "        results['combined_confidence'] = combined_confidence['confidence_score']\n",
    "        results['risk_level'] = combined_confidence['risk_level']\n",
    "        results['risk_color'] = combined_confidence['risk_color']\n",
    "        results['has_web_contradiction'] = combined_confidence['has_web_contradiction']\n",
    "        \n",
    "        # üÜï Layer 8: Claim Verification\n",
    "        is_claim = self.is_claim_input(query)\n",
    "        \n",
    "        if is_claim:\n",
    "            progress(0.95, desc=\"üéØ Layer 8: Claim Verification...\")\n",
    "            \n",
    "            claim_verification = self.claim_verifier.verify_claim(\n",
    "                claim=query,\n",
    "                answer=consensus_answer\n",
    "            )\n",
    "            \n",
    "            results['claim_verification'] = claim_verification\n",
    "            results['fever_label'] = claim_verification['label']\n",
    "            \n",
    "            results['verification_log'].append((\n",
    "                \"üéØ\", \n",
    "                \"Claim Verification\", \n",
    "                f\"Classified as: {claim_verification['label']} ({claim_verification['confidence']*100:.0f}% confidence)\"\n",
    "            ))\n",
    "            \n",
    "            # Adjust confidence if uncertain\n",
    "            if claim_verification['label'] == 'NOT ENOUGH INFO':\n",
    "                results['combined_confidence'] *= 0.85\n",
    "                results['verification_log'].append((\n",
    "                    \"‚ö†Ô∏è\",\n",
    "                    \"Confidence Adjustment\",\n",
    "                    \"Reduced confidence - claim verification uncertain\"\n",
    "                ))\n",
    "        else:\n",
    "            results['verification_log'].append((\n",
    "                \"‚ÑπÔ∏è\",\n",
    "                \"Input Type\",\n",
    "                \"Detected as question (not claim) - skipping claim verification\"\n",
    "            ))\n",
    "        \n",
    "        # Generate explanations\n",
    "        progress(0.98, desc=\"üìù Generating Explanations...\")\n",
    "        results['explanations'] = self.explain_confidence(results)\n",
    "        \n",
    "        results['verification_log'].append((\"üìä\", \"Final Confidence\", f\"{results['combined_confidence']:.1f}% ({results['risk_level']} risk)\"))\n",
    "        \n",
    "        progress(1.0, desc=\"‚úÖ Complete!\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# VISUALIZATION\n",
    "# ============================================\n",
    "\n",
    "def create_confidence_chart(results):\n",
    "    categories = ['Self-Consistency', 'Semantic<br>Certainty', 'NLI<br>Certainty', 'Web Match']\n",
    "    values = [\n",
    "        results['consistency_score'],\n",
    "        (1 - results['semantic_entropy']) * 100,\n",
    "        (1 - results['nli_entropy']) * 100,\n",
    "        results['web_match']\n",
    "    ]\n",
    "    \n",
    "    colors = ['#10b981', '#3b82f6', '#8b5cf6', '#f59e0b']\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=categories,\n",
    "            y=values,\n",
    "            marker_color=colors,\n",
    "            text=[f\"{v:.1f}%\" for v in values],\n",
    "            textposition='outside',\n",
    "            textfont=dict(size=14, color='#1f2937'),\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': \"Confidence Component Breakdown\",\n",
    "            'font': {'size': 18, 'color': '#1f2937', 'family': 'Inter'}\n",
    "        },\n",
    "        yaxis_title=\"Score (%)\",\n",
    "        yaxis=dict(range=[0, 110]),\n",
    "        height=350,\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        margin=dict(t=60, b=40, l=60, r=20),\n",
    "        font=dict(family='Inter', color='#6b7280')\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='#f3f4f6')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ============================================\n",
    "# GRADIO INTERFACE\n",
    "# ============================================\n",
    "\n",
    "def create_interface():\n",
    "    print(\"=\"*70)\n",
    "    print(\"Initializing Enhanced Hallucination Detection System v3.2...\")\n",
    "    print(\"=\"*70)\n",
    "    detector = HallucinationDetector()\n",
    "    print(\"\\n‚úì All systems operational!\\n\")\n",
    "    \n",
    "    def process_query(query, progress=gr.Progress()):\n",
    "        if not query or not query.strip():\n",
    "            return (\n",
    "                \"<div style='padding: 20px; text-align: center; color: #ef4444;'>‚ö†Ô∏è Please enter a question or claim</div>\",\n",
    "                \"\", \"\", \"\", None\n",
    "            )\n",
    "        \n",
    "        results = detector.detect(query, progress)\n",
    "        \n",
    "        # Warning banner\n",
    "        warning_banner = \"\"\n",
    "        if results['has_web_contradiction']:\n",
    "            warning_banner = \"\"\"\n",
    "            <div style=\"background: #fef2f2; border: 2px solid #ef4444; border-radius: 12px; padding: 20px; margin-bottom: 20px;\">\n",
    "                <div style=\"display: flex; align-items: center; gap: 12px;\">\n",
    "                    <div style=\"font-size: 28px;\">‚ö†Ô∏è</div>\n",
    "                    <div>\n",
    "                        <div style=\"font-weight: 700; color: #991b1b; margin-bottom: 5px; font-size: 16px;\">Web Source Contradiction Detected</div>\n",
    "                        <div style=\"color: #7f1d1d; font-size: 14px;\">High internal consistency but web sources disagree significantly.</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        # Answer card\n",
    "        answer_html = f\"\"\"\n",
    "        {warning_banner}\n",
    "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.2);\">\n",
    "            <div style=\"color: rgba(255,255,255,0.9); font-size: 13px; font-weight: 600; margin-bottom: 15px; text-transform: uppercase; letter-spacing: 1.2px;\">Answer</div>\n",
    "            <div style=\"color: white; font-size: 18px; line-height: 1.8; font-weight: 400;\">{results['answer']}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Confidence explanations\n",
    "        explanations_html = \"\".join([\n",
    "            f'<div style=\"display: flex; align-items: start; gap: 10px; margin-bottom: 12px;\">'\n",
    "            f'<span style=\"font-size: 18px; flex-shrink: 0;\">{emoji}</span>'\n",
    "            f'<span style=\"color: #374151; font-size: 14px; line-height: 1.6;\">{text}</span>'\n",
    "            f'</div>'\n",
    "            for emoji, text in results['explanations']\n",
    "        ])\n",
    "        \n",
    "        # Confidence dashboard\n",
    "        confidence_html = f\"\"\"\n",
    "        <div style=\"background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.1);\">\n",
    "            <div style=\"text-align: center; margin-bottom: 25px;\">\n",
    "                <div style=\"font-size: 54px; font-weight: 800; color: {results['risk_color']}; margin-bottom: 12px; letter-spacing: -2px;\">\n",
    "                    {results['combined_confidence']:.1f}%\n",
    "                </div>\n",
    "                <div style=\"display: inline-block; padding: 10px 24px; background: {results['risk_color']}; color: white; border-radius: 25px; font-weight: 700; font-size: 15px; letter-spacing: 0.5px;\">\n",
    "                    {results['risk_level']} RISK\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"background: #f8f9fa; height: 22px; border-radius: 11px; overflow: hidden; margin-bottom: 30px;\">\n",
    "                <div style=\"background: linear-gradient(90deg, {results['risk_color']}, {results['risk_color']}cc); height: 100%; width: {results['combined_confidence']}%; transition: width 0.6s cubic-bezier(0.4, 0, 0.2, 1);\"></div>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(140px, 1fr)); gap: 12px; margin-bottom: 25px;\">\n",
    "                <div style=\"text-align: center; padding: 18px; background: #f8f9fa; border-radius: 10px;\">\n",
    "                    <div style=\"font-size: 10px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.8px; margin-bottom: 8px;\">Self-Consistency</div>\n",
    "                    <div style=\"font-size: 26px; font-weight: 800; color: #1f2937;\">{results['consistency_score']:.0f}%</div>\n",
    "                </div>\n",
    "                <div style=\"text-align: center; padding: 18px; background: #f8f9fa; border-radius: 10px;\">\n",
    "                    <div style=\"font-size: 10px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.8px; margin-bottom: 8px;\">Semantic Entropy</div>\n",
    "                    <div style=\"font-size: 26px; font-weight: 800; color: #1f2937;\">{results['semantic_entropy']:.3f}</div>\n",
    "                </div>\n",
    "                <div style=\"text-align: center; padding: 18px; background: #f8f9fa; border-radius: 10px;\">\n",
    "                    <div style=\"font-size: 10px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.8px; margin-bottom: 8px;\">NLI Entropy</div>\n",
    "                    <div style=\"font-size: 26px; font-weight: 800; color: #1f2937;\">{results['nli_entropy']:.3f}</div>\n",
    "                </div>\n",
    "                <div style=\"text-align: center; padding: 18px; background: {'#fef2f2' if results['web_match'] < 30 else '#f8f9fa'}; border-radius: 10px; border: {'2px solid #ef4444' if results['web_match'] < 30 else 'none'};\">\n",
    "                    <div style=\"font-size: 10px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.8px; margin-bottom: 8px;\">Web Match</div>\n",
    "                    <div style=\"font-size: 26px; font-weight: 800; color: {'#ef4444' if results['web_match'] < 30 else '#1f2937'};\">{results['web_match']}%</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"padding: 20px; background: #f0f9ff; border-radius: 10px; border-left: 4px solid #3b82f6;\">\n",
    "                <div style=\"font-size: 13px; color: #1e40af; font-weight: 700; margin-bottom: 15px; text-transform: uppercase; letter-spacing: 0.5px;\">Confidence Breakdown</div>\n",
    "                {explanations_html}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Claim verification display\n",
    "        claim_verification_html = \"\"\n",
    "        if results.get('claim_verification'):\n",
    "            cv = results['claim_verification']\n",
    "            label_color = \"#10b981\" if cv['label'] == \"SUPPORTS\" else \"#ef4444\" if cv['label'] == \"REFUTES\" else \"#6b7280\"\n",
    "            \n",
    "            claim_verification_html = f\"\"\"\n",
    "            <div style=\"margin-bottom: 25px; padding: 20px; background: #f0f9ff; border-radius: 12px; border-left: 4px solid #3b82f6;\">\n",
    "                <div style=\"font-size: 12px; color: #1e40af; font-weight: 700; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 12px;\">üéØ Claim Verification (Layer 8)</div>\n",
    "                <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 12px;\">\n",
    "                    <span style=\"color: #374151; font-weight: 600;\">FEVER Classification:</span>\n",
    "                    <span style=\"padding: 6px 16px; background: {label_color}; color: white; border-radius: 20px; font-weight: 700; font-size: 13px;\">\n",
    "                        {cv['label']}\n",
    "                    </span>\n",
    "                </div>\n",
    "                <div style=\"font-size: 13px; color: #6b7280; margin-top: 10px;\">\n",
    "                    <div>Entailment: {cv['entailment_score']*100:.1f}% | Contradiction: {cv['contradiction_score']*100:.1f}% | Neutral: {cv['neutral_score']*100:.1f}%</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        # Mode badge\n",
    "        mode_badge_color = \"#10b981\" if results['mode'] == \"RAG\" else \"#f59e0b\" if results['used_fallback'] else \"#6b7280\"\n",
    "        \n",
    "        # NLI items\n",
    "        nli_items = \"\"\n",
    "        if results['nli_results']:\n",
    "            for i, nli in enumerate(results['nli_results'], 1):\n",
    "                color = \"#10b981\" if nli['label'] == \"ENTAILMENT\" else \"#ef4444\" if nli['label'] == \"CONTRADICTION\" else \"#6b7280\"\n",
    "                nli_items += f\"\"\"\n",
    "                <div style=\"display: flex; justify-content: space-between; align-items: center; padding: 14px; background: #f8f9fa; border-radius: 8px; margin-bottom: 8px;\">\n",
    "                    <span style=\"font-weight: 600; color: #374151; font-size: 14px;\">Evidence {i}</span>\n",
    "                    <span style=\"color: {color}; font-weight: 700; font-size: 13px;\">{nli['label']} ({nli['entailment_score']*100:.0f}%)</span>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "        else:\n",
    "            nli_items = \"<div style='color: #9ca3af; text-align: center; padding: 15px; font-style: italic; font-size: 14px;'>Not applicable for this mode</div>\"\n",
    "        \n",
    "        # Verification log\n",
    "        verification_log_html = \"\".join([\n",
    "            f'<div style=\"display: flex; gap: 12px; align-items: start; padding: 12px; background: #f8f9fa; border-radius: 8px; margin-bottom: 8px;\">'\n",
    "            f'<span style=\"font-size: 18px; flex-shrink: 0;\">{emoji}</span>'\n",
    "            f'<div style=\"flex: 1;\">'\n",
    "            f'<div style=\"font-weight: 700; color: #1f2937; font-size: 13px; margin-bottom: 3px;\">{layer}</div>'\n",
    "            f'<div style=\"color: #6b7280; font-size: 13px;\">{description}</div>'\n",
    "            f'</div>'\n",
    "            f'</div>'\n",
    "            for emoji, layer, description in results['verification_log']\n",
    "        ])\n",
    "        \n",
    "        verification_html = f\"\"\"\n",
    "        <div style=\"background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.1);\">\n",
    "            <div style=\"font-size: 20px; font-weight: 800; color: #1f2937; margin-bottom: 25px;\">üî¨ Complete Verification Details</div>\n",
    "            \n",
    "            {claim_verification_html}\n",
    "            \n",
    "            <div style=\"margin-bottom: 25px;\">\n",
    "                <div style=\"font-size: 12px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 12px;\">System Mode</div>\n",
    "                <div style=\"display: inline-block; padding: 8px 18px; background: {mode_badge_color}; color: white; border-radius: 20px; font-weight: 700; font-size: 13px; margin-bottom: 8px;\">\n",
    "                    {results['mode']}\n",
    "                </div>\n",
    "                <div style=\"color: #6b7280; font-size: 13px; font-style: italic;\">{results['mode_reason']}</div>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"margin-bottom: 25px;\">\n",
    "                <div style=\"font-size: 12px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 12px;\">8-Layer Verification Process</div>\n",
    "                {verification_log_html}\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"margin-bottom: 25px;\">\n",
    "                <div style=\"font-size: 12px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 12px;\">Wikipedia Sources Used</div>\n",
    "                <div style=\"font-size: 13px; color: #4b5563;\">\n",
    "                    {'<br>‚Ä¢ '.join(['‚Ä¢ ' + art[:80] + '...' for art in results['wiki_articles']]) if results['wiki_articles'] else '<span style=\"font-style: italic; color: #9ca3af;\">No Wikipedia sources (pretrained mode)</span>'}\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"margin-bottom: 0;\">\n",
    "                <div style=\"font-size: 12px; color: #6b7280; font-weight: 700; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 12px;\">NLI Verification Results</div>\n",
    "                {nli_items}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Web sources\n",
    "        web_html = \"\"\n",
    "        if results['web_results']:\n",
    "            sources_html = \"\"\n",
    "            for i, r in enumerate(results['web_results'][:3], 1):\n",
    "                sources_html += f\"\"\"\n",
    "                <div style=\"padding: 20px; background: #f8f9fa; border-radius: 10px; margin-bottom: 12px;\">\n",
    "                    <div style=\"font-weight: 700; color: #1f2937; margin-bottom: 8px; font-size: 15px;\">{i}. {r['title']}</div>\n",
    "                    <a href=\"{r['url']}\" target=\"_blank\" style=\"color: #667eea; text-decoration: none; font-size: 12px; display: block; margin-bottom: 10px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap; font-weight: 500;\">{r['url']}</a>\n",
    "                    <div style=\"color: #6b7280; font-size: 13px; line-height: 1.7;\">{r['snippet'][:250]}...</div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            \n",
    "            web_html = f\"\"\"\n",
    "            <div style=\"background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.1);\">\n",
    "                <div style=\"font-size: 20px; font-weight: 800; color: #1f2937; margin-bottom: 20px;\">üåê Web Verification Sources</div>\n",
    "                {sources_html}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        chart = create_confidence_chart(results)\n",
    "        \n",
    "        return answer_html, confidence_html, verification_html, web_html, chart\n",
    "    \n",
    "    custom_css = \"\"\"\n",
    "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');\n",
    "    \n",
    "    .gradio-container {\n",
    "        max-width: 1400px !important;\n",
    "        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif !important;\n",
    "    }\n",
    "    .gr-button-primary {\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;\n",
    "        border: none !important;\n",
    "        font-weight: 700 !important;\n",
    "        font-size: 16px !important;\n",
    "        padding: 14px 36px !important;\n",
    "        border-radius: 12px !important;\n",
    "        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4) !important;\n",
    "        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;\n",
    "    }\n",
    "    .gr-button-primary:hover {\n",
    "        transform: translateY(-2px) !important;\n",
    "        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.5) !important;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(theme=gr.themes.Soft(), css=custom_css, title=\"Hallucination Detection v3.2\") as demo:\n",
    "        gr.HTML(\"\"\"\n",
    "        <div style=\"text-align: center; padding: 50px 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 20px; margin-bottom: 35px; box-shadow: 0 15px 50px rgba(0,0,0,0.2);\">\n",
    "            <h1 style=\"color: white; font-size: 46px; font-weight: 900; margin: 0 0 12px 0; letter-spacing: -1.5px;\">\n",
    "                Enhanced Hallucination Detection\n",
    "            </h1>\n",
    "            <div style=\"color: rgba(255,255,255,0.95); font-size: 20px; margin: 0 0 20px 0; font-weight: 500;\">\n",
    "                v3.2 - Complete 8-Layer Verification System\n",
    "            </div>\n",
    "            <div style=\"padding: 10px 20px; background: rgba(255,255,255,0.2); backdrop-filter: blur(10px); border-radius: 20px; display: inline-block;\">\n",
    "                <span style=\"color: white; font-size: 14px; font-weight: 600;\">üî¨ Wikipedia ‚Üí Re-rank ‚Üí Self-Consistency ‚Üí Clustering ‚Üí NLI ‚Üí Entropy ‚Üí Web ‚Üí Claim Verification</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                query_input = gr.Textbox(\n",
    "                    label=\"\",\n",
    "                    placeholder=\"Enter your question or claim... (Try 'Who was the 44th president?' or 'Barack Obama was the 44th president')\",\n",
    "                    lines=3,\n",
    "                    show_label=False\n",
    "                )\n",
    "                submit_btn = gr.Button(\"üîç Analyze\", variant=\"primary\", size=\"lg\")\n",
    "                \n",
    "                gr.Markdown(\"### üí° Example Inputs\")\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        [\"Who was the 44th president of America?\"],\n",
    "                        [\"Barack Obama was the 44th president\"],\n",
    "                        [\"What is UMBC?\"],\n",
    "                        [\"UMBC is located in Maryland\"],\n",
    "                        [\"Where is Baltimore?\"]\n",
    "                    ],\n",
    "                    inputs=query_input,\n",
    "                    label=\"\"\n",
    "                )\n",
    "        \n",
    "        gr.HTML(\"<div style='margin: 35px 0;'></div>\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            answer_output = gr.HTML()\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                confidence_output = gr.HTML()\n",
    "            with gr.Column(scale=1):\n",
    "                verification_output = gr.HTML()\n",
    "        \n",
    "        with gr.Row():\n",
    "            chart_output = gr.Plot(label=\"Confidence Metrics Visualization\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            web_output = gr.HTML()\n",
    "        \n",
    "        submit_btn.click(\n",
    "            fn=process_query,\n",
    "            inputs=[query_input],\n",
    "            outputs=[answer_output, confidence_output, verification_output, web_output, chart_output]\n",
    "        )\n",
    "        \n",
    "        query_input.submit(\n",
    "            fn=process_query,\n",
    "            inputs=[query_input],\n",
    "            outputs=[answer_output, confidence_output, verification_output, web_output, chart_output]\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"üéì Enhanced Hallucination Detection System v3.2\")\n",
    "    print(\"   Complete 8-Layer Verification with Claim Support\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüî¨ All 8 Verification Layers:\")\n",
    "    print(\"   1. Wikipedia Search (FAISS + BM25)\")\n",
    "    print(\"   2. Cross-Encoder Re-ranking\")\n",
    "    print(\"   3. Self-Consistency Detection (5 attempts)\")\n",
    "    print(\"   4. Semantic Clustering\")\n",
    "    print(\"   5. Neural NLI Verification\")\n",
    "    print(\"   6. Entropy-Based Uncertainty\")\n",
    "    print(\"   7. Web Search Verification\")\n",
    "    print(\"   8. Claim Verification (FEVER) üÜï\")\n",
    "    print(\"\\nInitializing all components...\\n\")\n",
    "    \n",
    "    demo = create_interface()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ System Ready!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüåê Launching interface...\\n\")\n",
    "    \n",
    "    demo.launch(\n",
    "        share=True,\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7889,\n",
    "        show_error=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "433be06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ ADVANCED FEATURES LOADED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "Available features:\n",
      "  1. ConfidenceCalibrator - Calibrate and evaluate confidence scores\n",
      "  2. AdversarialTester - Test robustness with adversarial examples\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ADVANCED FEATURES: Confidence Calibration + Adversarial Testing\n",
    "Paste this after your main HallucinationDetector class\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# ============================================\n",
    "# CONFIDENCE CALIBRATION\n",
    "# ============================================\n",
    "\n",
    "class ConfidenceCalibrator:\n",
    "    \"\"\"\n",
    "    Calibrates confidence scores using temperature scaling\n",
    "    Makes predictions more reliable and trustworthy\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.temperature = 1.5  # Scaling parameter\n",
    "        self.calibration_history = []\n",
    "        print(\"‚úì Confidence Calibrator initialized\")\n",
    "    \n",
    "    def calibrate_confidence(self, raw_confidence, consistency_score, entropy):\n",
    "        \"\"\"\n",
    "        Apply temperature scaling to raw confidence\n",
    "        \n",
    "        Args:\n",
    "            raw_confidence: Original confidence score (0-100)\n",
    "            consistency_score: Self-consistency percentage\n",
    "            entropy: Semantic entropy value\n",
    "        \n",
    "        Returns:\n",
    "            Calibrated confidence score (0-100)\n",
    "        \"\"\"\n",
    "        # Normalize to [-1, 1] range\n",
    "        normalized = (raw_confidence - 50) / 50\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        scaled = normalized / self.temperature\n",
    "        \n",
    "        # Convert back to [0, 100] range with sigmoid\n",
    "        calibrated = 100 / (1 + math.exp(-scaled))\n",
    "        \n",
    "        # Adjust based on consistency and entropy\n",
    "        if consistency_score < 60:\n",
    "            calibrated *= 0.85  # Reduce confidence for low consistency\n",
    "        \n",
    "        if entropy > 0.7:\n",
    "            calibrated *= 0.90  # Reduce confidence for high entropy\n",
    "        \n",
    "        # Store for later analysis\n",
    "        self.calibration_history.append({\n",
    "            'raw': raw_confidence,\n",
    "            'calibrated': calibrated,\n",
    "            'consistency': consistency_score,\n",
    "            'entropy': entropy\n",
    "        })\n",
    "        \n",
    "        return max(0, min(100, calibrated))\n",
    "    \n",
    "    def plot_calibration_curve(self, results):\n",
    "        \"\"\"\n",
    "        Create calibration curve showing how well-calibrated the system is\n",
    "        \n",
    "        Args:\n",
    "            results: List of evaluation results with 'confidence' and 'correct'\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä GENERATING CALIBRATION CURVE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Bin predictions by confidence\n",
    "        bins = np.linspace(0, 100, 11)\n",
    "        bin_accuracies = []\n",
    "        bin_confidences = []\n",
    "        bin_counts = []\n",
    "        \n",
    "        for i in range(len(bins)-1):\n",
    "            bin_results = [r for r in results \n",
    "                          if bins[i] <= r.get('confidence', 0) < bins[i+1]]\n",
    "            if bin_results:\n",
    "                accuracy = sum(r.get('correct', False) for r in bin_results) / len(bin_results)\n",
    "                avg_conf = np.mean([r.get('confidence', 0) for r in bin_results])\n",
    "                bin_accuracies.append(accuracy * 100)\n",
    "                bin_confidences.append(avg_conf)\n",
    "                bin_counts.append(len(bin_results))\n",
    "        \n",
    "        if not bin_confidences:\n",
    "            print(\"‚ö†Ô∏è Not enough data for calibration curve\")\n",
    "            return\n",
    "        \n",
    "        # Create plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Plot 1: Calibration curve\n",
    "        ax1.plot([0, 100], [0, 100], 'k--', linewidth=2, label='Perfect Calibration', alpha=0.7)\n",
    "        ax1.plot(bin_confidences, bin_accuracies, 'bo-', linewidth=3, markersize=10, label='Your System')\n",
    "        ax1.fill_between([0, 100], [0, 100], alpha=0.1, color='green')\n",
    "        ax1.set_xlabel('Confidence (%)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Confidence Calibration Curve', fontsize=15, fontweight='bold', pad=15)\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(alpha=0.3)\n",
    "        ax1.set_xlim(0, 100)\n",
    "        ax1.set_ylim(0, 100)\n",
    "        \n",
    "        # Add gap annotations\n",
    "        for conf, acc in zip(bin_confidences, bin_accuracies):\n",
    "            gap = abs(conf - acc)\n",
    "            if gap > 10:\n",
    "                ax1.annotate(f'{gap:.1f}% gap', \n",
    "                           xy=(conf, acc), \n",
    "                           xytext=(conf+5, acc-5),\n",
    "                           fontsize=9, \n",
    "                           color='red',\n",
    "                           arrowprops=dict(arrowstyle='->', color='red', lw=1))\n",
    "        \n",
    "        # Plot 2: Distribution of predictions\n",
    "        ax2.bar(range(len(bin_counts)), bin_counts, color='#3b82f6', alpha=0.7, edgecolor='black')\n",
    "        ax2.set_xlabel('Confidence Bin', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Number of Predictions', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Distribution of Confidence Scores', fontsize=15, fontweight='bold', pad=15)\n",
    "        ax2.set_xticks(range(len(bin_counts)))\n",
    "        ax2.set_xticklabels([f'{int(bins[i])}-{int(bins[i+1])}' for i in range(len(bin_counts))], rotation=45)\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(r'C:\\Users\\pooji\\Desktop\\calibration_curve.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\n‚úì Saved: calibration_curve.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate Expected Calibration Error (ECE)\n",
    "        ece = np.mean(np.abs(np.array(bin_confidences) - np.array(bin_accuracies)))\n",
    "        \n",
    "        print(f\"\\nüìä Calibration Metrics:\")\n",
    "        print(f\"   Expected Calibration Error (ECE): {ece:.2f}%\")\n",
    "        print(f\"   {'‚úÖ Excellent!' if ece < 5 else '‚úÖ Good' if ece < 10 else '‚ö†Ô∏è Needs improvement'}\")\n",
    "        print(f\"   (Lower is better: <5% excellent, <10% good)\")\n",
    "        \n",
    "        # Calculate over/under confidence\n",
    "        total_predictions = sum(bin_counts)\n",
    "        overconfident = sum(1 for c, a in zip(bin_confidences, bin_accuracies) if c > a)\n",
    "        underconfident = sum(1 for c, a in zip(bin_confidences, bin_accuracies) if c < a)\n",
    "        \n",
    "        print(f\"\\n   Overconfident bins: {overconfident}/{len(bin_confidences)}\")\n",
    "        print(f\"   Underconfident bins: {underconfident}/{len(bin_confidences)}\")\n",
    "        \n",
    "        return {\n",
    "            'ece': ece,\n",
    "            'bin_confidences': bin_confidences,\n",
    "            'bin_accuracies': bin_accuracies,\n",
    "            'bin_counts': bin_counts\n",
    "        }\n",
    "\n",
    "# ============================================\n",
    "# ADVERSARIAL TESTING\n",
    "# ============================================\n",
    "\n",
    "class AdversarialTester:\n",
    "    \"\"\"\n",
    "    Generate adversarial examples to test system robustness\n",
    "    Shows the system can handle edge cases and tricky inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, detector):\n",
    "        self.detector = detector\n",
    "        print(\"‚úì Adversarial Tester initialized\")\n",
    "    \n",
    "    def generate_negation_adversarial(self, claim):\n",
    "        \"\"\"Add negation to flip meaning\"\"\"\n",
    "        adversarial = []\n",
    "        \n",
    "        # Pattern 1: was ‚Üí was not\n",
    "        if \" was \" in claim:\n",
    "            adversarial.append(claim.replace(\" was \", \" was not \", 1))\n",
    "        \n",
    "        # Pattern 2: is ‚Üí is not\n",
    "        if \" is \" in claim:\n",
    "            adversarial.append(claim.replace(\" is \", \" is not \", 1))\n",
    "        \n",
    "        # Pattern 3: has ‚Üí has not\n",
    "        if \" has \" in claim:\n",
    "            adversarial.append(claim.replace(\" has \", \" has not \", 1))\n",
    "        \n",
    "        return adversarial\n",
    "    \n",
    "    def generate_temporal_adversarial(self, claim):\n",
    "        \"\"\"Modify temporal information (years, dates)\"\"\"\n",
    "        adversarial = []\n",
    "        \n",
    "        # Find years\n",
    "        years = re.findall(r'\\b(19|20)\\d{2}\\b', claim)\n",
    "        for year in years[:2]:  # Max 2 years\n",
    "            # Wrong year (+10 years)\n",
    "            wrong_year = str(int(year) + 10)\n",
    "            adversarial.append(claim.replace(year, wrong_year, 1))\n",
    "        \n",
    "        return adversarial\n",
    "    \n",
    "    def generate_numerical_adversarial(self, claim):\n",
    "        \"\"\"Modify numbers (ordinals, quantities)\"\"\"\n",
    "        adversarial = []\n",
    "        \n",
    "        # Find ordinal numbers (1st, 2nd, 44th, etc.)\n",
    "        ordinals = re.findall(r'\\b\\d+(?:st|nd|rd|th)\\b', claim)\n",
    "        for ordinal in ordinals[:2]:\n",
    "            base_num = int(re.findall(r'\\d+', ordinal)[0])\n",
    "            suffix = ordinal[len(str(base_num)):]\n",
    "            wrong_ordinal = str(base_num + 1) + suffix\n",
    "            adversarial.append(claim.replace(ordinal, wrong_ordinal, 1))\n",
    "        \n",
    "        # Find regular numbers\n",
    "        numbers = re.findall(r'\\b\\d+\\b', claim)\n",
    "        for num in numbers[:2]:\n",
    "            if len(num) <= 3:  # Avoid long numbers like years\n",
    "                wrong_num = str(int(num) + 1)\n",
    "                adversarial.append(claim.replace(num, wrong_num, 1))\n",
    "        \n",
    "        return adversarial\n",
    "    \n",
    "    def generate_entity_swap_adversarial(self, claim):\n",
    "        \"\"\"Swap named entities\"\"\"\n",
    "        adversarial = []\n",
    "        \n",
    "        # Common swaps\n",
    "        entity_swaps = [\n",
    "            ('Barack Obama', 'Donald Trump'),\n",
    "            ('United States', 'United Kingdom'),\n",
    "            ('New York', 'Los Angeles'),\n",
    "            ('Einstein', 'Newton'),\n",
    "            ('Apple', 'Microsoft')\n",
    "        ]\n",
    "        \n",
    "        for entity1, entity2 in entity_swaps:\n",
    "            if entity1 in claim:\n",
    "                adversarial.append(claim.replace(entity1, entity2, 1))\n",
    "            if entity2 in claim:\n",
    "                adversarial.append(claim.replace(entity2, entity1, 1))\n",
    "        \n",
    "        return adversarial\n",
    "    \n",
    "    def run_adversarial_test(self, test_claims, num_claims=20):\n",
    "        \"\"\"\n",
    "        Run comprehensive adversarial testing\n",
    "        \n",
    "        Args:\n",
    "            test_claims: List of claims to test\n",
    "            num_claims: How many claims to test (default: 20)\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üéØ ADVERSARIAL ROBUSTNESS TESTING\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nTesting {min(num_claims, len(test_claims))} claims with adversarial examples...\")\n",
    "        print(\"This will take ~5-10 minutes...\\n\")\n",
    "        \n",
    "        results = {\n",
    "            'total_tests': 0,\n",
    "            'correct_detections': 0,\n",
    "            'missed_changes': 0,\n",
    "            'false_alarms': 0,\n",
    "            'by_type': {\n",
    "                'negation': {'total': 0, 'correct': 0},\n",
    "                'temporal': {'total': 0, 'correct': 0},\n",
    "                'numerical': {'total': 0, 'correct': 0},\n",
    "                'entity_swap': {'total': 0, 'correct': 0}\n",
    "            },\n",
    "            'examples': []\n",
    "        }\n",
    "        \n",
    "        from tqdm.notebook import tqdm\n",
    "        \n",
    "        for claim_data in tqdm(test_claims[:num_claims], desc=\"Testing\"):\n",
    "            claim = claim_data.get('claim', '')\n",
    "            \n",
    "            if not claim or len(claim) < 20:\n",
    "                continue\n",
    "            \n",
    "            # Get original result\n",
    "            try:\n",
    "                orig_result = self.detector.detect(claim)\n",
    "                orig_label = orig_result.get('fever_label', 'UNKNOWN')\n",
    "                orig_conf = orig_result.get('combined_confidence', 0)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            # Generate adversarial examples\n",
    "            adversarials = {\n",
    "                'negation': self.generate_negation_adversarial(claim),\n",
    "                'temporal': self.generate_temporal_adversarial(claim),\n",
    "                'numerical': self.generate_numerical_adversarial(claim),\n",
    "                'entity_swap': self.generate_entity_swap_adversarial(claim)\n",
    "            }\n",
    "            \n",
    "            # Test each adversarial example\n",
    "            for adv_type, adv_claims in adversarials.items():\n",
    "                for adv_claim in adv_claims[:2]:  # Max 2 per type\n",
    "                    if adv_claim == claim:  # Skip if no change\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        adv_result = self.detector.detect(adv_claim)\n",
    "                        adv_label = adv_result.get('fever_label', 'UNKNOWN')\n",
    "                        adv_conf = adv_result.get('combined_confidence', 0)\n",
    "                        \n",
    "                        # Check if system detected the change\n",
    "                        detected_change = (orig_label != adv_label) or (abs(orig_conf - adv_conf) > 15)\n",
    "                        \n",
    "                        results['total_tests'] += 1\n",
    "                        results['by_type'][adv_type]['total'] += 1\n",
    "                        \n",
    "                        if detected_change:\n",
    "                            results['correct_detections'] += 1\n",
    "                            results['by_type'][adv_type]['correct'] += 1\n",
    "                        else:\n",
    "                            results['missed_changes'] += 1\n",
    "                        \n",
    "                        # Store example\n",
    "                        if len(results['examples']) < 20:  # Keep first 20\n",
    "                            results['examples'].append({\n",
    "                                'type': adv_type,\n",
    "                                'original': claim,\n",
    "                                'adversarial': adv_claim,\n",
    "                                'orig_label': orig_label,\n",
    "                                'adv_label': adv_label,\n",
    "                                'orig_conf': orig_conf,\n",
    "                                'adv_conf': adv_conf,\n",
    "                                'detected': detected_change\n",
    "                            })\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if results['total_tests'] > 0:\n",
    "            robustness_score = results['correct_detections'] / results['total_tests'] * 100\n",
    "        else:\n",
    "            robustness_score = 0\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä ADVERSARIAL ROBUSTNESS RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\nüéØ Overall Robustness Score: {robustness_score:.1f}%\")\n",
    "        print(f\"   (Percentage of adversarial changes detected)\")\n",
    "        \n",
    "        print(f\"\\nüìà Test Summary:\")\n",
    "        print(f\"   Total Adversarial Tests: {results['total_tests']}\")\n",
    "        print(f\"   Correct Detections: {results['correct_detections']}\")\n",
    "        print(f\"   Missed Changes: {results['missed_changes']}\")\n",
    "        \n",
    "        print(f\"\\nüìä Performance by Attack Type:\")\n",
    "        for attack_type, stats in results['by_type'].items():\n",
    "            if stats['total'] > 0:\n",
    "                accuracy = stats['correct'] / stats['total'] * 100\n",
    "                print(f\"   {attack_type.capitalize():<15} {accuracy:>5.1f}%  ({stats['correct']}/{stats['total']})\")\n",
    "        \n",
    "        # Show examples\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìù SAMPLE ADVERSARIAL EXAMPLES\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for i, ex in enumerate(results['examples'][:5], 1):\n",
    "            print(f\"\\nüîπ Example {i} - {ex['type'].upper()}\")\n",
    "            print(f\"   Original: {ex['original'][:80]}...\")\n",
    "            print(f\"   Label: {ex['orig_label']} | Confidence: {ex['orig_conf']:.1f}%\")\n",
    "            print(f\"\\n   Adversarial: {ex['adversarial'][:80]}...\")\n",
    "            print(f\"   Label: {ex['adv_label']} | Confidence: {ex['adv_conf']:.1f}%\")\n",
    "            print(f\"   {'‚úÖ Change detected' if ex['detected'] else '‚ùå Change missed'}\")\n",
    "        \n",
    "        # Save results\n",
    "        output_file = r\"C:\\Users\\pooji\\Desktop\\adversarial_test_results.json\"\n",
    "        import json\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"\\n‚úì Detailed results saved to: {output_file}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        self.plot_adversarial_results(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_adversarial_results(self, results):\n",
    "        \"\"\"Create visualization of adversarial test results\"\"\"\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Plot 1: Overall results\n",
    "        labels = ['Detected\\nCorrectly', 'Missed\\nChanges']\n",
    "        values = [results['correct_detections'], results['missed_changes']]\n",
    "        colors = ['#10b981', '#ef4444']\n",
    "        \n",
    "        ax1.pie(values, labels=labels, autopct='%1.1f%%', colors=colors, \n",
    "                startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "        ax1.set_title('Adversarial Detection Rate', fontsize=15, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Plot 2: By attack type\n",
    "        attack_types = []\n",
    "        accuracies = []\n",
    "        \n",
    "        for attack_type, stats in results['by_type'].items():\n",
    "            if stats['total'] > 0:\n",
    "                attack_types.append(attack_type.capitalize())\n",
    "                accuracies.append(stats['correct'] / stats['total'] * 100)\n",
    "        \n",
    "        bars = ax2.bar(attack_types, accuracies, color=['#3b82f6', '#8b5cf6', '#ec4899', '#f59e0b'], \n",
    "                       alpha=0.8, edgecolor='black', linewidth=2)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acc:.1f}%',\n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "        \n",
    "        ax2.set_ylabel('Detection Rate (%)', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title('Performance by Attack Type', fontsize=15, fontweight='bold', pad=15)\n",
    "        ax2.set_ylim(0, 100)\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=15)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(r'C:\\Users\\pooji\\Desktop\\adversarial_results.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\n‚úì Saved: adversarial_results.png\")\n",
    "        plt.show()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ ADVANCED FEATURES LOADED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAvailable features:\")\n",
    "print(\"  1. ConfidenceCalibrator - Calibrate and evaluate confidence scores\")\n",
    "print(\"  2. AdversarialTester - Test robustness with adversarial examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16fc40cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì FEVER EVALUATION - JUPYTER NOTEBOOK VERSION\n",
      "\n",
      "Choose test size:\n",
      "  1. Quick test (100 claims) - ~2 minutes\n",
      "  2. Medium test (1,000 claims) - ~15 minutes\n",
      "  3. Full test (15,000 claims) - ~3-4 hours\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Running quick test with 100 claims...\n",
      "\n",
      "======================================================================\n",
      "üî¨ AUTOMATED FEVER EVALUATION\n",
      "======================================================================\n",
      "\n",
      "üìÅ Loading claims from: C:\\Users\\pooji\\Desktop\\fever_claims_full.json\n",
      "‚úì Loaded 100 claims\n",
      "   Sample: The Wolf of Wall Street was a film of 1999....\n",
      "\n",
      "üöÄ Initializing system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:24:29,479 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-11-11 00:24:31,564 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-11-11 00:24:32,060 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì System ready\n",
      "\n",
      "======================================================================\n",
      "PROCESSING CLAIMS\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70171df36754964814b328635d1e26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953fa0b4f21d4194b52baf6c36286cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff9c32f4d40462489cdd2e1fafc8931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:24:35,383 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:36,499 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:37,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:39,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:40,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f93fdef24c0499e83724bd8579fe3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa80807a2df9454cb312828d38d37a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fce1dcc783f474581fe59d3616780dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06cc63ecfd94c368c96b1235464e049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:24:41,485 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20Wolf%20of%20Wall%20Street%20was%20a%20film%20of%201999. 200\n",
      "2025-11-11 00:24:41,590 - primp - INFO - response: https://www.bing.com/search?q=The+Wolf+of+Wall+Street+was+a+film+of+1999.&pq=The+Wolf+of+Wall+Street+was+a+film+of+1999.&cc=en 200\n",
      "2025-11-11 00:24:45,587 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b046a9bd2d443bba9fb73f676c0b8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc50d699feb41c387493f4af70747ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:24:48,949 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:51,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:52,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:54,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:24:56,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41e3ad483684b7cb2ad4ac0119cab5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc2e3d367e54a1982fadecbb533bf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce11ced444f0427a80e8c28bfe1c652d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb838ab878bf46aba27483e5dd979fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:24:58,804 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Rope%20starred%20Bill%20Clinton. 200\n",
      "2025-11-11 00:24:59,369 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:25:01,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:258: ResourceWarning: unclosed <ssl.SSLSocket fd=6596, family=2, type=1, proto=0, laddr=('10.0.0.30', 61729), raddr=('52.149.246.39', 443)>\n",
      "  def schedule(self, f):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d973367599314dbcb4a83f3b84955621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5716fb45da43b9a7fd58c501988172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:04,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:06,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:07,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:09,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:10,343 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae12e0368e74b568ccda4f4258d342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffca82d27bc4ff096d25dea9b48c13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680f13530fc64f1094943c1566fd317d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7792390ae684ceda64f5c4c2bb50378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:12,742 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Jared%20Leto%20has%20a%20former%20name%20called%20Toast. 200\n",
      "2025-11-11 00:25:12,856 - primp - INFO - response: https://www.bing.com/search?q=Jared+Leto+has+a+former+name+called+Toast.&pq=Jared+Leto+has+a+former+name+called+Toast.&cc=en 200\n",
      "2025-11-11 00:25:15,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997208b9cbba44d4ae2f3db49f785809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50c6dd299024a209fefe45b0b684899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:18,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:19,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:20,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:21,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:22,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:24,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:24,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:25,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:26,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:27,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41350f5e2e6242c7a83cd3ae4c4335d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36f269ed67f434e9b13b6741f02452e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c5e6ce2fee4dac8bf2715f32ba4ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57cb1a5c5f843fcbc852cf562f0a0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:29,460 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Linkin%20Park%20is%20a%20British%20rock%20band. 200\n",
      "2025-11-11 00:25:29,541 - primp - INFO - response: https://www.bing.com/search?q=Linkin+Park+is+a+British+rock+band.&pq=Linkin+Park+is+a+British+rock+band.&cc=en 200\n",
      "2025-11-11 00:25:31,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bc71b0a58a425b8057ef7a777618d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7ab27acc714f2e86e7e63dc2b67ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:33,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:34,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:36,087 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:37,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:38,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6939058e5414692b3f68c9fe6676c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0cae689cca45068d9dd040ac68dc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65f7de931594012941f6820f7823bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fcbd463e0548349aaf4f2cf99bea77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:41,172 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Celine%20Dion%20sings%20in%20Arabic. 200\n",
      "2025-11-11 00:25:41,892 - primp - INFO - response: https://search.brave.com/search?q=Celine+Dion+sings+in+Arabic.&source=web 200\n",
      "2025-11-11 00:25:44,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9067834f9cfd48ca81ed3988df289de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b91a41ee464188b737918d4dc84e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:48,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:50,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:52,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:53,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:25:54,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a533436f814ff6a42ba4d281a779df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea31a29bc474a4bb237b64d1fd00fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d395b6d7809447baed8569fed4e8646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef9c7d46f574123ac5ff9f3b29cf1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:25:57,430 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Richard%20Nixon%27s%20wife%27s%20friend%27s%20name%20was%20Ryan. 200\n",
      "2025-11-11 00:25:57,498 - primp - INFO - response: https://www.bing.com/search?q=Richard+Nixon%27s+wife%27s+friend%27s+name+was+Ryan.&pq=Richard+Nixon%27s+wife%27s+friend%27s+name+was+Ryan.&cc=en 200\n",
      "2025-11-11 00:25:59,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96048f7b42a4088bbc352c4f9f67073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0798f73f43864f5e84ddfe6890c0c077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:26:03,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:05,136 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:06,367 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:07,823 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:09,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a631844369f48298e4e0787a3720207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a2928c048e416aa43e6d56eb4144a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94b7507e8de45b6bedf79d42a9318f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2730f00d4ed24d729584807d12bb432d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe24fc895dc4e638cb5136f03deaa8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb20b758a1d4aa399d72c7d60f793ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919f69816bd040dbbed4200767884b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:26:12,553 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Neymar%20finished%20college%20on%20February. 200\n",
      "2025-11-11 00:26:12,630 - primp - INFO - response: https://search.brave.com/search?q=Neymar+finished+college+on+February.&source=web 429\n",
      "2025-11-11 00:26:13,895 - primp - INFO - response: https://yandex.com/search/site/?text=Neymar+finished+college+on+February.&web=1&searchid=6680964 200\n",
      "2025-11-11 00:26:15,764 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48297e2b590458e81b32b7440e361e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640fdcb3723b4ad9b6f847f88bebd995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:26:19,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:21,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:23,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:24,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:26,413 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb48194321745b7b836c1b1710d5296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aea1374edf5486ea79929c865aa7738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a2812d81b642ce979d3ddbda361e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16255ad92a34d139f2528797201dc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:26:28,914 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Estella%20Warren%20is%20an%20actress. 200\n",
      "2025-11-11 00:26:29,120 - primp - INFO - response: https://search.brave.com/search?q=Estella+Warren+is+an+actress.&source=web 429\n",
      "2025-11-11 00:26:30,077 - primp - INFO - response: https://www.mojeek.com/search?q=Estella+Warren+is+an+actress. 403\n",
      "2025-11-11 00:26:31,371 - primp - INFO - response: https://yandex.com/search/site/?text=Estella+Warren+is+an+actress.&web=1&searchid=6340769 200\n",
      "2025-11-11 00:26:34,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5173fe0bca0d4ee38d185880d490942e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014afbdae5ac4d5690e802eb1e88f81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:26:37,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:38,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:40,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:42,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:45,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bcaf961e9842dd9eba6cb478f1f660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec45f5733d694b0cbc4893d2f77f79a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3efb62a6a34a1a996681fb8e19e86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762e06f415c94404a33c9ed1cef035cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:26:47,376 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=True%20Blood%20ignores%20Sookie%20Stackhouse. 200\n",
      "2025-11-11 00:26:47,532 - primp - INFO - response: https://search.brave.com/search?q=True+Blood+ignores+Sookie+Stackhouse.&source=web 429\n",
      "2025-11-11 00:26:47,882 - primp - INFO - response: https://search.yahoo.com/search;_ylt=ZW7oBC3q6_CEiCmuF3YlwRTe;_ylu=tsihF9M_9mG3Wq7E5N5HLFjsB-IxMc7JCsjlgcOma6KTWic?p=True+Blood+ignores+Sookie+Stackhouse. 200\n",
      "2025-11-11 00:26:50,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6bb25b408841b3a003fafd1a8bf31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634505883e764292bc170dfd5e50f047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:26:54,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:55,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:56,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:58,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:26:59,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7271a2f795414caf86a9b0010a1820af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af6fed7f21e46cdb4cee72de448d0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ab8ed957f744a391ccd85007408a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55e19ac28674dff85d5197adaca5926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:02,094 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Dileep%20designed%20a%20toy%20factory. 200\n",
      "2025-11-11 00:27:02,099 - primp - INFO - response: https://search.yahoo.com/search;_ylt=JDTA3VjfJhe3mJ5FG3P22Oe8;_ylu=gY-v2wp2N238hGuxnxCBNqbfFwSKeAGF3NmO041-Iiv_hY8?p=Dileep+designed+a+toy+factory. 200\n",
      "2025-11-11 00:27:04,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90907c72a16741d6bfb999e481808720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c1c680927540d1a4ffe5f34cd28fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:08,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:10,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:13,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:15,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:17,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b74f5e1bed44c1995afc0132ea10c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f4b9de822f42a1ba70975eac933786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2510796270124591a27206ca7183e4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843f65f91a2942ceadad69f471621ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:19,202 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Desperate%20Housewives%20strictly%20a%20book%20series%20from%20Canada. 200\n",
      "2025-11-11 00:27:19,280 - primp - INFO - response: https://www.bing.com/search?q=Desperate+Housewives+strictly+a+book+series+from+Canada.&pq=Desperate+Housewives+strictly+a+book+series+from+Canada.&cc=en 200\n",
      "2025-11-11 00:27:21,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8284c42fdf4754a3da88e8336705f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8690cce576746d69d4416b03c966f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:24,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:25,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:27,368 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:28,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:30,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788008a0696e407da69dfb4fbc649b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eebb827228d49ba8d2046f45694ae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41c912607ec465995cafe7364520eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c79cfd44864819a9930cd992440b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:32,708 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=IBM%20only%20used%20programming%20language%20invented%20by%20others. 200\n",
      "2025-11-11 00:27:32,897 - primp - INFO - response: https://search.brave.com/search?q=IBM+only+used+programming+language+invented+by+others.&source=web 429\n",
      "2025-11-11 00:27:34,326 - primp - INFO - response: https://www.bing.com/search?q=IBM+only+used+programming+language+invented+by+others.&pq=IBM+only+used+programming+language+invented+by+others.&cc=en 200\n",
      "2025-11-11 00:27:38,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6759fb9899541ee8b0383d641c47f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a0894109c143828f3ecae2f09fe7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:41,861 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:43,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:44,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:45,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:48,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5effe440504453cb96c665c484242be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65038cbe190c4ca2ad9bcc3dc6aae463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dd2017531847bab5eeb49f1f170cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53c1826489f41d5b2dc50e92bd4cf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:49,492 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Dwayne%20Douglas%20Johnson%20is%20a%20professional%20wrestler%20for%20the%20WWE. 200\n",
      "2025-11-11 00:27:50,359 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:27:52,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da887064d7454dc9badbd76e305e4bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\jupyter_client\\session.py:834: ResourceWarning: unclosed <ssl.SSLSocket fd=6020, family=2, type=1, proto=0, laddr=('10.0.0.30', 55101), raddr=('52.149.246.39', 443)>\n",
      "  for idx, buf in enumerate(buffers):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549f36e4233b42379d33d8b5b04ba4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:27:55,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:57,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:57,994 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:27:58,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:00,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2df1dff714140f0b7086a11549ca65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89053dd51a244c5193e5c5b29e338b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339121d95ae646a29863fdfdc9c1ac53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0634f79527ef4b3cab39896929f9d772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:01,384 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Alfred%20Hitchcock%20framed%20shots%20to%20maximize%20only%20two%20things. 200\n",
      "2025-11-11 00:28:01,575 - primp - INFO - response: https://www.bing.com/search?q=Alfred+Hitchcock+framed+shots+to+maximize+only+two+things.&pq=Alfred+Hitchcock+framed+shots+to+maximize+only+two+things.&cc=en 200\n",
      "2025-11-11 00:28:03,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8a815d4d3a4aad9cdff94cc3de7b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb20976355c74d1f9a79806896c5c111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:05,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:07,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:09,906 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:11,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:12,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fda419dd4db4501afc4165064a43ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb89c90e9ac84259bb6e271de3a6d73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9875929d28a74a35840bbde590bd050e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a5bf1b170f48028011bd750782a639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:14,367 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Vacation%20has%20an%20all-American%20cast. 200\n",
      "2025-11-11 00:28:14,923 - primp - INFO - response: https://search.yahoo.com/search;_ylt=lauuzrwNGopshHXmI7um3hjB;_ylu=mKxDd9OLbm8-SwuvJB6_65Fh87bOG-Qz-UZBRTvs4RjoQiM?p=Vacation+has+an+all-American+cast. 200\n",
      "2025-11-11 00:28:17,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7d3e9487784614a835bd3716cd7a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd28ebc597b42019650a58b7b995ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:19,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:20,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:21,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:22,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:23,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b88bfe1f4c4e98a041333beb33a032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddcf0f7e38d41b88f0b5ca18e322cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433411121fc546fb8504498293176f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2295e080fc4836a434461af35aed9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:25,214 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Comedian%20Jason%20Sudeikis%20was%20born%20in%20America. 200\n",
      "2025-11-11 00:28:25,437 - primp - INFO - response: https://www.mojeek.com/search?q=Comedian+Jason+Sudeikis+was+born+in+America. 403\n",
      "2025-11-11 00:28:26,698 - primp - INFO - response: https://yandex.com/search/site/?text=Comedian+Jason+Sudeikis+was+born+in+America.&web=1&searchid=9353428 200\n",
      "2025-11-11 00:28:28,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3b0e0f6d344259a5203297a5c21eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9345339ea754304a0f3bfe2d2ed3071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:31,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:32,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:34,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:36,787 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:38,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e814444805466dbd7bc6444098d061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae4c433576f434abea41c6312b309d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6e903971ea4fa48c99b2f99ded561c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fa8f2ce5d948179f2501460fb665f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:40,010 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Ty%20Cobb%20finished%20his%20career%20with%20the%20Philadelphia%20Athletics%20in%202011. 200\n",
      "2025-11-11 00:28:40,742 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:28:43,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\threading.py:588: ResourceWarning: unclosed <ssl.SSLSocket fd=6016, family=2, type=1, proto=0, laddr=('10.0.0.30', 59145), raddr=('52.149.246.39', 443)>\n",
      "  def __init__(self):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23910a7c0a2749c48bc9272862a1ae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1658239f610748d8954d52141067961f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:45,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:47,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:49,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:50,631 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:51,834 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2e1948935f451e8bea8716a14f7c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5015097d64a488e826e6d59728125ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c328b3a0fde54627854079688a0e5e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c52ff47e4e43d7aba14b743704ce4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:53,054 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Gemma%20Arterton%20refused%20to%20appear%20in%20the%20film%20Hansel%20and%20Grentel%3A%20Witch%20Hunters. 200\n",
      "2025-11-11 00:28:54,049 - primp - INFO - response: https://yandex.com/search/site/?text=Gemma+Arterton+refused+to+appear+in+the+film+Hansel+and+Grentel%3A+Witch+Hunters.&web=1&searchid=5211096 200\n",
      "2025-11-11 00:28:56,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50312ca65c0347a1b40919bbd87969d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609c8f8a38f94f2da6d79480053f5125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:28:58,402 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:28:59,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:03,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:04,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:05,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ef0c57ca5f449baf903e32533d63da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23482e6a306641efa775945221230fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976f476040cf491d9f10d9efa31e2878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b7167bf87745dea8cef1b1ac74b408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:07,286 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Michael%20Clarke%20Duncan%20was%20in%20a%20film. 200\n",
      "2025-11-11 00:29:07,469 - primp - INFO - response: https://search.brave.com/search?q=Michael+Clarke+Duncan+was+in+a+film.&source=web 429\n",
      "2025-11-11 00:29:08,643 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:29:10,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7b847b5f75404ebfda9f8de94b82f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf4e59f3ba542de871fb7688c66d9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:697: ResourceWarning: unclosed <ssl.SSLSocket fd=6940, family=2, type=1, proto=0, laddr=('10.0.0.30', 49678), raddr=('52.149.246.39', 443)>\n",
      "  def convert_to_tensors(\n",
      "2025-11-11 00:29:12,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:15,096 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:16,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:18,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:19,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a383eb44531e41efb101659d4c533228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78a6b287e9643e8a98e46cd05627390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdd247cf4414dd6b6e9adf6fd2b2d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134cb658c144924b57045d716666d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:21,381 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Galaxy%20Quest%20is%20a%20rapper. 200\n",
      "2025-11-11 00:29:21,457 - primp - INFO - response: https://www.bing.com/search?q=Galaxy+Quest+is+a+rapper.&pq=Galaxy+Quest+is+a+rapper.&cc=en 200\n",
      "2025-11-11 00:29:23,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0d4818cf244b3dac9ab5468ded2c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86506b20955741ec9f46687a127aaf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:25,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:26,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:27,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:28,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:29,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac46a6e2e5f4b178c5d31cae2199742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc171db99b8a4942be7af3d479a006a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b877886e68e345df8086a0d9e8110490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b8901eddd74458a0164dba34ee1597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:32,101 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=50%20First%20Dates%20is%20a%202004%20American%20film. 200\n",
      "2025-11-11 00:29:32,238 - primp - INFO - response: https://search.yahoo.com/search;_ylt=PWLuHjE4vYut794ZoaFF3oIo;_ylu=7zJTCuCTV-1t3VmjHZi_EsmvsC-WI5nwilKKRe7dmSD38q8?p=50+First+Dates+is+a+2004+American+film. 200\n",
      "2025-11-11 00:29:34,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b731435215d74b9d9d18e43e87bfe484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e65f50328f49c1b0dddc502b0d570f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:36,081 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:37,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:38,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:40,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:41,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d083087784478e9e05c41d9ee170f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fa1b7e581d40f6b16a0abc61305203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b126dc2ba1cc4bd4b4e8ab3a8e9c16b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65abe2e1892a483fa024aea7d748a4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:43,498 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Tesla%2C%20Inc.%20has%20no%20subsidiary. 200\n",
      "2025-11-11 00:29:43,557 - primp - INFO - response: https://search.yahoo.com/search;_ylt=X29jV5ePzt-rxi0h8HM_21QV;_ylu=5e8VLJMW8-8iDW4pXmhGFPYaKJxpkeN6e4yT85Uis7T4Tjg?p=Tesla%2C+Inc.+has+no+subsidiary. 200\n",
      "2025-11-11 00:29:47,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e869a16e27394519bdd79cb9ca4a17b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217da5bc194648518642ee68381c787d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:50,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:51,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:53,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:54,739 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:29:56,261 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50ad8a4e3c34fb089b4608f43eb5194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2030a764cff49f0848776fc156d9a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f2e12433ab455c9a03f0b18b45cb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169567fe3801470890e083026acb3912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:29:57,723 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Jackie%20Chan%20is%20not%20a%20Cantopop%20star. 200\n",
      "2025-11-11 00:29:58,109 - primp - INFO - response: https://www.mojeek.com/search?q=Jackie+Chan+is+not+a+Cantopop+star. 403\n",
      "2025-11-11 00:29:58,965 - primp - INFO - response: https://www.bing.com/search?q=Jackie+Chan+is+not+a+Cantopop+star.&pq=Jackie+Chan+is+not+a+Cantopop+star.&cc=en 200\n",
      "2025-11-11 00:30:01,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbc3d60d8e440aea2125c0cc8c9deab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7284ccc9a940d6b699a974a1747581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:30:03,404 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:04,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:06,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:07,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:08,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb14190381544ec93daf338dd4df988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d91bced646b4345a3363b78261124cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d5352c786c495695a5df7c2dc59d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0808e3085b24b62ac7e2eb4266f9ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:30:10,323 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Harry%20Styles%20only%20released%20an%20album%20in%201011. 200\n",
      "2025-11-11 00:30:11,035 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:30:12,502 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d345f8e04b458aa93e57b5875ae645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:1931: ResourceWarning: unclosed <ssl.SSLSocket fd=6068, family=2, type=1, proto=0, laddr=('10.0.0.30', 49685), raddr=('52.149.246.39', 443)>\n",
      "  for name, trait in traits.items():\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285ed06d789f4dcf83b06b7da72bc5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:30:15,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:16,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:17,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:19,257 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:20,632 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef2d7b7576243e3b0f12498895031d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6569a176da4440b3d160fe1410f5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3db54e7ee114d7aafb89a3fde3806ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4014bc93824ab8911d3de77bcb5877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:30:22,584 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Mel%20Gibson%20did%20not%20direct%20and%20produce%20a%20biblical%20drama%20film. 200\n",
      "2025-11-11 00:30:23,185 - primp - INFO - response: https://www.mojeek.com/search?q=Mel+Gibson+did+not+direct+and+produce+a+biblical+drama+film. 403\n",
      "2025-11-11 00:30:24,444 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:30:26,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\ipykernel\\comm\\comm.py:31: ResourceWarning: unclosed <ssl.SSLSocket fd=7108, family=2, type=1, proto=0, laddr=('10.0.0.30', 55159), raddr=('52.149.246.39', 443)>\n",
      "  content = json_clean(dict(data=data, comm_id=self.comm_id, **keys))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6b0c225fc5490e9777065f4b7748dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b807691acb4a9fb1c1f17783767b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:30:31,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:34,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:36,745 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:38,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:40,623 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69bc1a20e5b495b81b9420cca7c1c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6801180445a4990964a8794503d6c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a12267b51f43c1b174c79aa41c2be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed8d482ab574905bb21057fc2282156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:30:42,972 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=There%20is%20a%20WWE%20wrestler%20name%20John%20Cena. 200\n",
      "2025-11-11 00:30:43,939 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:30:47,809 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc686e1fa2a48bfa1a0ac070dad8cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2b251390534e0aab661f6671e145b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:30:50,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:51,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:52,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\asyncio\\events.py:36: ResourceWarning: unclosed <ssl.SSLSocket fd=2868, family=2, type=1, proto=0, laddr=('10.0.0.30', 62893), raddr=('52.149.246.39', 443)>\n",
      "  def __init__(self, callback, args, loop, context=None):\n",
      "2025-11-11 00:30:53,257 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:54,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:56,266 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:57,723 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:58,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:00,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:02,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d9841295744f47bee3547f6715b181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63a6d7bba534cb98f3fad60792dff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc18ab4be3e4e70a96c23404c096c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f42e22081e41ac9e1073a53c7af50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:31:07,261 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Katie%20Stevens%20was%20born%20on%20December%208%2C%201992. 200\n",
      "2025-11-11 00:31:07,321 - primp - INFO - response: https://www.bing.com/search?q=Katie+Stevens+was+born+on+December+8%2C+1992.&pq=Katie+Stevens+was+born+on+December+8%2C+1992.&cc=en 200\n",
      "2025-11-11 00:31:09,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f7e84899a74dcfbb829a30295227bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38da6332ae24447b27aafaf94b0c3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:31:12,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:13,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:15,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:16,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:18,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a521227759fe49d496a028ffdcd1f172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c0c9dd41fb4df58223ab4e0e72f7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1649f6978f7414e8839093d0443c3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f6b0be617c4a12b66c60a39b14273a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:31:20,834 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Buddy%20Holly%20died%20on%20February%203rd%2C%201959. 200\n",
      "2025-11-11 00:31:21,301 - primp - INFO - response: https://www.bing.com/search?q=Buddy+Holly+died+on+February+3rd%2C+1959.&pq=Buddy+Holly+died+on+February+3rd%2C+1959.&cc=en 200\n",
      "2025-11-11 00:31:23,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827e008e57494595b75997fd5bd62e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf94ca1eceb4439ab06d37c083cbfe09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:31:26,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:28,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:29,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:30,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:32,413 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dcbe30ce4b4c7f87174a705cc9e7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cead660a1fc147bfab6ce0211450c135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253f9a8d01f047448ba0f3343fbbff8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b44008295a4a39ab37a5dbaf61e8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56532674fe5a43e28962d19bafbbe980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b5ffb379d340ae87c10db55da1a3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:31:35,012 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Film%20is%20an%20industry%20that%20Taylor%20Kitsch%20works%20in. 200\n",
      "2025-11-11 00:31:35,690 - primp - INFO - response: https://www.mojeek.com/search?q=Film+is+an+industry+that+Taylor+Kitsch+works+in. 403\n",
      "2025-11-11 00:31:37,374 - primp - INFO - response: https://yandex.com/search/site/?text=Film+is+an+industry+that+Taylor+Kitsch+works+in.&web=1&searchid=1680904 200\n",
      "2025-11-11 00:31:39,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c1c37b51cb4d3da3015ebb0275b42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4d7eda22cd43ddb35ee671e131a890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:31:43,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:44,412 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:45,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:47,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:48,481 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67eb97edac9414d9b34946c27e4080b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849b9bf398c54ea29b10da9ff480b5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9530538f461943309fa61a2a938b5e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9652edd69145b7b179e6ff8949eefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:31:50,666 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Winona%20Ryder%20was%20the%20lead%20actor%20in%20When%20Love%20Is%20Not%20Enough. 200\n",
      "2025-11-11 00:31:51,599 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:31:54,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfc74d056e94cf3b195d858c8c1e0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12827472b8e41d08255cd0811785be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:349: ResourceWarning: unclosed <ssl.SSLSocket fd=6888, family=2, type=1, proto=0, laddr=('10.0.0.30', 59315), raddr=('52.149.246.39', 443)>\n",
      "  if return_length:\n",
      "2025-11-11 00:31:57,502 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:31:59,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:01,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:03,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:05,911 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1818f956899642bbb60f19fd0f67bf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22023026db82486992a4b58bd3aad6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef7d38775df425d9da1c3bfd3ba14e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc5aa5c86d74de9928437589c1ccb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:32:08,331 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Resident%20Evil%20has%20multiple%20weapons. 200\n",
      "2025-11-11 00:32:08,819 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:32:11,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed821b463774511a5aebbffe8737a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\asyncio\\events.py:111: ResourceWarning: unclosed <ssl.SSLSocket fd=7128, family=2, type=1, proto=0, laddr=('10.0.0.30', 59317), raddr=('52.149.246.39', 443)>\n",
      "  def __init__(self, when, callback, args, loop, context=None):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e602e3ab9e4da6b4483aec90fac601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:32:16,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:17,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:19,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:21,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:23,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c0cc62d8ff4c71a14ba6fa43aff527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8981617a2ed748c1a27df62000cf30e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d7f3faf88040f1a48c316da018523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8839fd3f9c574356b9e3740156ef5b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb9d1784e7043eeba8e57c154938567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:32:25,504 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=One%20Direction%20made%20Life. 200\n",
      "2025-11-11 00:32:25,666 - primp - INFO - response: https://www.bing.com/search?q=One+Direction+made+Life.&pq=One+Direction+made+Life.&cc=en 200\n",
      "2025-11-11 00:32:27,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418cc2f7c7e04e099c04633bfa050b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc71d7f9e354438b6f7b2f26ad1aec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:32:31,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:32,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:33,739 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:35,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:36,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cefd30ba4e4cf789341df849c34230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dfb7a859214da6afdec5946e3e723a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498a0e55666a44e8b94cf17776083aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc31df1b51d940a1be7791d704a349de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:32:38,869 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Seth%20MacFarlane%20wrote%20Everybody%20Needs%20a%20Best%20Friend%27s%20lyrics. 200\n",
      "2025-11-11 00:32:39,817 - primp - INFO - response: https://yandex.com/search/site/?text=Seth+MacFarlane+wrote+Everybody+Needs+a+Best+Friend%27s+lyrics.&web=1&searchid=6072368 200\n",
      "2025-11-11 00:32:41,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dc634fe91a47aabf2e86100b3faa42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d21d956346d4812b4a74f1f667b4362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:32:45,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:47,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:49,290 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:50,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:32:52,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774efc4acf2b4aeeab4006129919b0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4defc468a442378aecf87d5725205e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2d0f104ab64c9b82d10b7fcacd379b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a9410f1a64ea8860f61dd58ca258d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:32:55,378 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Charles%20Mackay%20was%20born%20on%20March%2027%2C%201914. 200\n",
      "2025-11-11 00:32:56,188 - primp - INFO - response: https://yandex.com/search/site/?text=Charles+Mackay+was+born+on+March+27%2C+1914.&web=1&searchid=1473685 200\n",
      "2025-11-11 00:32:57,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40674196b3aa4126a55c12e9e2531cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a278e7146b6a43dda1cad88454dd46d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:33:01,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:03,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:05,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:08,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:09,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14336ccc34974f3fb73435b7eae6d811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6353c528283548659d201904b95b0392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0146a8997a6400697000192d4de42e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbf0a8cb09d432e8ff017e7f53d0f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:33:11,952 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Measles%20complications%20occur%20in%20about%2030%25%20of%20clams. 200\n",
      "2025-11-11 00:33:12,564 - primp - INFO - response: https://www.mojeek.com/search?q=Measles+complications+occur+in+about+30%25+of+clams. 403\n",
      "2025-11-11 00:33:13,423 - primp - INFO - response: https://search.brave.com/search?q=Measles+complications+occur+in+about+30%25+of+clams.&source=web 429\n",
      "2025-11-11 00:33:14,963 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:33:17,190 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\ipykernel\\comm\\comm.py:31: ResourceWarning: unclosed <ssl.SSLSocket fd=6824, family=2, type=1, proto=0, laddr=('10.0.0.30', 59925), raddr=('52.149.246.39', 443)>\n",
      "  content = json_clean(dict(data=data, comm_id=self.comm_id, **keys))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61fd18fde5742528fc612b0336923ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d0222be54848d381e456bcf2f65bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:33:20,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:21,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:22,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:23,666 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:24,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098f55011b014a4a8cf2f26f6ad3d0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b6ab4744e84c64967aa9fe29e2f38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a67b1f56394cb8b7d38000514b28ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2a00d7fdf14f7681c3b57c4287a175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:33:26,822 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Steve%20Mouzakis%20was%20in%20The%20Suicide%20Theory. 200\n",
      "2025-11-11 00:33:26,937 - primp - INFO - response: https://search.brave.com/search?q=Steve+Mouzakis+was+in+The+Suicide+Theory.&source=web 429\n",
      "2025-11-11 00:33:27,507 - primp - INFO - response: https://www.mojeek.com/search?q=Steve+Mouzakis+was+in+The+Suicide+Theory. 403\n",
      "2025-11-11 00:33:28,726 - primp - INFO - response: https://yandex.com/search/site/?text=Steve+Mouzakis+was+in+The+Suicide+Theory.&web=1&searchid=5193936 200\n",
      "2025-11-11 00:33:32,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdcd04404d14d65b167835a59a65d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f69f02bfa740eebae2756e97d6233b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:33:35,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:37,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:38,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:39,249 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:40,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:42,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:43,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:44,962 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:46,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:33:47,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855d51ae86884c959c64f5397a3531f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7697d9587f7b4666a20eabddb2675655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299e4ce7f57f439b9caaa5034f013994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840eeda13abf406da2a59e553028e447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:33:52,584 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=A%20Song%20of%20Ice%20and%20Fire%20was%20written%20by%20Peter%20Jackson. 200\n",
      "2025-11-11 00:33:52,880 - primp - INFO - response: https://www.mojeek.com/search?q=A+Song+of+Ice+and+Fire+was+written+by+Peter+Jackson. 403\n",
      "2025-11-11 00:33:53,170 - primp - INFO - response: https://search.yahoo.com/search;_ylt=AP1zfcRqAEGHm5v3nFGjZ9pP;_ylu=C5iSAHSfrBpiuudW1RV8i0CxUP_YaoEYXiNxyGJVsueUDeo?p=A+Song+of+Ice+and+Fire+was+written+by+Peter+Jackson. 200\n",
      "2025-11-11 00:33:55,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4f5c3c03f74d73aab9fe511171d1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4173af0d9c93409a888f9b81e6058896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:33:59,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:00,733 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:01,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:03,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:04,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b8f25a283b484885c933cc3006ff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfe9031180e4a5eb0c157363398c0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3b0bc6ddb74b6b87e1ad92f1ccf086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f055b8127bf40f3914d21a796108c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:34:06,895 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20United%20Kingdom%20is%20a%20developing%20country. 200\n",
      "2025-11-11 00:34:08,121 - primp - INFO - response: https://yandex.com/search/site/?text=The+United+Kingdom+is+a+developing+country.&web=1&searchid=1832799 200\n",
      "2025-11-11 00:34:09,641 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a122da390394b4ebdc543345165730c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1e8661b0394404b456d37d022f9ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:34:12,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:13,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:13,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:14,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:15,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:17,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:18,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:20,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:22,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:23,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70936e0c29b409991b9035c2bbfb153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f535df273f4249569e17a0685c4ced4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e8b8d1cc4a4783842b64143b2994e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657ba5cbd07641949e0c11a968d780bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:34:27,727 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Diana%20Ross%20is%20a%20jazz%20singer. 200\n",
      "2025-11-11 00:34:27,841 - primp - INFO - response: https://search.brave.com/search?q=Diana+Ross+is+a+jazz+singer.&source=web 429\n",
      "2025-11-11 00:34:28,541 - primp - INFO - response: https://search.yahoo.com/search;_ylt=NbPaR5Q5YnacdlEid0wavOMQ;_ylu=rd5vJ20Sgje49aTL2fIeagTEpKzP5yT4OfFQKUXdUUxpGJQ?p=Diana+Ross+is+a+jazz+singer. 200\n",
      "2025-11-11 00:34:32,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f6638e5c56402992891b37d9a3fdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eca2dd5c0e8419dbd3ba675667c7de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:34:36,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:37,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:38,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:39,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:40,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecea3ccf9ec44c80a452cf1dae44581f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae8591cddd44d58a5675c7c74544b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68132f6ae2b1489fb020e86331552608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb38ba7420ac4b85b11b5c8dddf404f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:34:43,191 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Samsung%20Life%20Insurance%27s%20headquarters%20have%20been%20in%20Seoul%2C%20South%20Korea%20since%201997. 200\n",
      "2025-11-11 00:34:44,005 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:34:46,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc89243e8d84ad0bf22bd61778da460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0d6e423b7541718d42e252de79411e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\typing.py:407: ResourceWarning: unclosed <ssl.SSLSocket fd=5696, family=2, type=1, proto=0, laddr=('10.0.0.30', 51974), raddr=('52.149.246.39', 443)>\n",
      "  def _eval_type(t, globalns, localns, type_params=None, *, recursive_guard=frozenset()):\n",
      "2025-11-11 00:34:49,745 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:51,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:53,872 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:55,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:34:58,489 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303bfd84bb974bf5a320aac342e111b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2ff60ca7384df3b28e4d2137fc4fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9549ebee207c447fb46cf9df69245688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99fb02de4ce4e9397644c8f05f306ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:00,734 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Stone%20Temple%20Pilots%20had%20an%20original%20member%20that%20died%20on%20September%203. 200\n",
      "2025-11-11 00:35:01,718 - primp - INFO - response: https://yandex.com/search/site/?text=Stone+Temple+Pilots+had+an+original+member+that+died+on+September+3.&web=1&searchid=4499963 200\n",
      "2025-11-11 00:35:06,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af818c28b9d4e849ca512192122bc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b475ff0a8cf467a921f666f95bf619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:09,301 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:11,796 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:13,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:14,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:16,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ce14638a664edf801174f6f8d35122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca3c08a4e8343e1878ffcc1c21f1398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcc5248c85f4789bdc81eb498053d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4479b6b1f743c296faf915740b458b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:18,624 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Theodore%20Roosevelt%20was%20privately%20schooled. 200\n",
      "2025-11-11 00:35:19,457 - primp - INFO - response: https://yandex.com/search/site/?text=Theodore+Roosevelt+was+privately+schooled.&web=1&searchid=7625859 200\n",
      "2025-11-11 00:35:21,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fd8d66795d450a9b6e5087e83ca6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021b4231ccfb4d839f9cffc9c0119000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:24,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:26,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:28,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:29,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:31,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c72704f99f6431f90ea0fb43062b487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7684250e1e384cc981f66ce3fb5127e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065ddc9bc0f84b60859c70c93629bfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aba0b717e8c438f98d92323e19ae22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:33,653 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Roman%20Atwood%20is%20a%20youtube%20vlogger. 200\n",
      "2025-11-11 00:35:33,660 - primp - INFO - response: https://www.bing.com/search?q=Roman+Atwood+is+a+youtube+vlogger.&pq=Roman+Atwood+is+a+youtube+vlogger.&cc=en 200\n",
      "2025-11-11 00:35:34,711 - primp - INFO - response: https://search.brave.com/search?q=Roman+Atwood+is+a+youtube+vlogger.&source=web 429\n",
      "2025-11-11 00:35:35,935 - primp - INFO - response: https://yandex.com/search/site/?text=Roman+Atwood+is+a+youtube+vlogger.&web=1&searchid=7218938 200\n",
      "2025-11-11 00:35:39,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd1b786508f4be98ed8ab655b968c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92143252c32f4870ac5f426dc1f9f985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:43,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:45,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:47,296 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:49,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:35:50,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa354d566234c1297d5f37f3d2ac275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c7c95bb80842d2ad8dec24397bec69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3863407ebc964d33a7378c01ac97cb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94c2e2fd5054b3c808d445673c307cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:52,132 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Paul%20Simon%20is%20a%20singer. 200\n",
      "2025-11-11 00:35:53,192 - primp - INFO - response: https://yandex.com/search/site/?text=Paul+Simon+is+a+singer.&web=1&searchid=4225194 200\n",
      "2025-11-11 00:35:55,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5702462f7214c71acaa30078ea520fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884041df977f4e12820f6ea54761f736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:35:58,559 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:00,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:02,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:03,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:05,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e309543f7cf2469d81c9046154396f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59192080cd9419b8d4ab6036a0db67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86903656482d4edd890c8911c385f17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c78b1de94b4058880f59b7b12e8570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:07,366 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Jack%20Dorsey%20is%20an%20entrepreneur. 200\n",
      "2025-11-11 00:36:07,369 - primp - INFO - response: https://search.yahoo.com/search;_ylt=kMI4XqhX8Jhvrn1HUDAP14No;_ylu=vICuBw8WWeR4a9j3qqTvPLtan1Y0Bd8MiUTUe5vlSr6Ob4U?p=Jack+Dorsey+is+an+entrepreneur. 200\n",
      "2025-11-11 00:36:10,134 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f700272ac64298abdf5aabcdede1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ca8c0a09e94514ba643d0cb0293aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:12,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:13,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:14,740 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:15,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:16,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e597132ab7ef447f93dd9fd68d55a947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468283bb3362447babe7909ec80c06e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a8db1012d04ba5968f0ac6ef0c257f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1aa24b2a9945438bd86923d6d9f1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:18,734 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=As%20the%20World%20Turns%20is%20set%20in%20Chicago. 200\n",
      "2025-11-11 00:36:18,937 - primp - INFO - response: https://www.bing.com/search?q=As+the+World+Turns+is+set+in+Chicago.&pq=As+the+World+Turns+is+set+in+Chicago.&cc=en 200\n",
      "2025-11-11 00:36:21,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8728156bad4e4a9326ec088b0ddcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9091e0b889442580ca909051f28e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:24,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:25,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:27,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:28,693 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:30,275 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c650f46a114671b35d3697a93e2b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5babcad094704cc68b6e5f333a13aaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645c897102f2441b84359978d654dfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da023a126c24f4ab53daa23088c898a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:31,826 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Followers%20of%20asceticism%20pursue%20condemnation. 200\n",
      "2025-11-11 00:36:32,047 - primp - INFO - response: https://search.brave.com/search?q=Followers+of+asceticism+pursue+condemnation.&source=web 429\n",
      "2025-11-11 00:36:33,080 - primp - INFO - response: https://search.yahoo.com/search;_ylt=-apPLP_LJ1k5hPeYI0q_bh8f;_ylu=mJhoxY1zTHwUewX1CKp_nHaCwQpqE9sfgtHBRFy8fAL0jEI?p=Followers+of+asceticism+pursue+condemnation. 200\n",
      "2025-11-11 00:36:35,432 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a499f13e6a34059be9c7154706bef05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ed734d9510453bbe83acfda9508c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:38,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:40,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:42,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:43,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:45,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb3682bae8a410db4262193230a7b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7069ae529129458ba3f62d21dac70c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9824b96b11ed4b79a59f8631a00d9fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a2642b577e466abe6c47026fff8ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:47,125 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Britney%20Spears%20was%20turned%20down%20for%20any%20leading%20role%20in%20the%20movie%20Crossroads. 200\n",
      "2025-11-11 00:36:47,127 - primp - INFO - response: https://search.brave.com/search?q=Britney+Spears+was+turned+down+for+any+leading+role+in+the+movie+Crossroads.&source=web 429\n",
      "2025-11-11 00:36:49,596 - primp - INFO - response: https://yandex.com/search/site/?text=Britney+Spears+was+turned+down+for+any+leading+role+in+the+movie+Crossroads.&web=1&searchid=4063350 200\n",
      "2025-11-11 00:36:52,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bb8e094adb480eb8b86819bd25a92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af17efe310e4012a91d519acdd53d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:36:54,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:56,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:36:59,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:00,920 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:03,017 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9ca3b762454e67b5c1a20ed874d17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238006b7a0bc4333974a7a95f2c1bde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548c5d293c9145d88457ff60fc779698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f34fe6d46314b81822dc46c02531e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:37:05,164 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Bette%20Davis%20had%20a%20persona. 200\n",
      "2025-11-11 00:37:06,083 - primp - INFO - response: https://yandex.com/search/site/?text=Bette+Davis+had+a+persona.&web=1&searchid=8675048 200\n",
      "2025-11-11 00:37:09,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2d7e0889534286a91a53a6548aa426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0c82d494d04674807df72123f1010b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:37:12,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:14,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:15,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:16,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:17,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82225657f6244d1935e2c65b8e84b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58344284bba04b98b74ff844a61cac7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9236860dea9041ada18cc393606bf0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c73c404bf8541718ad77493f5c765ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:37:19,063 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Gillian%20Jacobs%20appeared%20in%20Life%20Partners. 200\n",
      "2025-11-11 00:37:19,304 - primp - INFO - response: https://search.yahoo.com/search;_ylt=9-MciDYmTvVF1Lo_JixcV6dO;_ylu=hrMgFExlRlCXCZqUag5201uMZp9HyAJ5tG5Ak1i1VMRZDdc?p=Gillian+Jacobs+appeared+in+Life+Partners. 200\n",
      "2025-11-11 00:37:22,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2ea9bb5d0e4b72baefecb302de2bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513ede4e130e47a98079e4a549aa509f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:37:25,906 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:28,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:29,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:31,677 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:33,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c89187fbd854e948818926c7d023852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2d89490a2843498f8f24135a6066e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf233e124484861a2c9297f2e6f98dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3c7101341e412c90ae5fe2d3924c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:37:34,864 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=My%20Sweet%20Lord%27s%20lyrics%20are%20meant%20to%20be%20an%20appeal%20to%20get%20rid%20of%20religious%20sectarianism. 200\n",
      "2025-11-11 00:37:36,041 - primp - INFO - response: https://yandex.com/search/site/?text=My+Sweet+Lord%27s+lyrics+are+meant+to+be+an+appeal+to+get+rid+of+religious+sectarianism.&web=1&searchid=5128674 200\n",
      "2025-11-11 00:37:38,542 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236723a14b9546a09cd0da1905a362dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6769238fa5b4455bb5140452c48ea8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:37:42,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:43,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:45,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:47,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:37:50,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa11703005a345a493eacdd3e4476945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c28eb707d624af39e4ccf2f9619cb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b91ebec4dd417aa7e36404dbcf556e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b104208dccda4a86a158c855cdbe62e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:37:52,754 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Sachin%20Tendulkar%20was%20excluded%20from%20an%20all-time%20Test%20World%20XI. 200\n",
      "2025-11-11 00:37:52,898 - primp - INFO - response: https://search.brave.com/search?q=Sachin+Tendulkar+was+excluded+from+an+all-time+Test+World+XI.&source=web 429\n",
      "2025-11-11 00:37:54,380 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:37:56,666 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015f177804f14e7ba55406f41e925281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:270: ResourceWarning: unclosed <ssl.SSLSocket fd=6692, family=2, type=1, proto=0, laddr=('10.0.0.30', 60927), raddr=('52.149.246.39', 443)>\n",
      "  def send_multipart(self, *args, **kwargs):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3c9d3613134ac2a933ae0b1910964b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:38:01,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:02,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:04,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:06,922 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:08,622 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45ea8ab1560440aa94e296509d90cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab820e64882641f6951062d55c35ee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040ab10b7721417388ec5ede47117736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc12f43dfe94eac8b410f2c42db13e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:38:13,526 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=AC/DC%20has%20dubbed%20their%20music%20as%20rock%20and%20roll%20even%20though%20its%20been%20considered%20heavy%20metal. 200\n",
      "2025-11-11 00:38:13,544 - primp - INFO - response: https://search.yahoo.com/search;_ylt=OEE7ehzdWV52qHFiTl0sHXcW;_ylu=q2XhnhPVPL-_0V62xRHZ2zFtsuXxi4vFXh9ZK7yg4jcebOU?p=AC%2FDC+has+dubbed+their+music+as+rock+and+roll+even+though+its+been+considered+heavy+metal. 200\n",
      "2025-11-11 00:38:16,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb65656e4be643449060f6e82fbc171a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e674d0257024f5bbdafe84669245a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:38:20,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:21,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:22,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:23,504 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:24,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c514fe781c8e4bd8ba4723901c09e568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eb0ca4e65d49fba5e7d359d394dff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b876c8a8354de2ab571fb8c20112d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d62e93c9f64e4880f5b703a1027117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:38:26,634 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Indiana%20Jones%20was%20killed%20by%20Harrison%20Ford. 200\n",
      "2025-11-11 00:38:27,898 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:38:30,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a08da3f3851425d9634bb0ac4468ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a27dbdb77640c5a2e322f2c1892d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\asyncio\\events.py:36: ResourceWarning: unclosed <ssl.SSLSocket fd=5772, family=2, type=1, proto=0, laddr=('10.0.0.30', 58756), raddr=('52.149.246.39', 443)>\n",
      "  def __init__(self, callback, args, loop, context=None):\n",
      "2025-11-11 00:38:34,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:35,542 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:36,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:38,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:39,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5902a5a1c1400ba9b9e690e4a3f0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e1e453685e405196734ea27823041f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfac299ef130473b806bf7dd9e821b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8578691308104451ae8b3d764dd8e7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:38:41,574 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Pablo%20Fenjves%20ghostwrote%20for%20a%20comedian%20and%20he%20was%20successful. 200\n",
      "2025-11-11 00:38:42,704 - primp - INFO - response: https://yandex.com/search/site/?text=Pablo+Fenjves+ghostwrote+for+a+comedian+and+he+was+successful.&web=1&searchid=7371089 200\n",
      "2025-11-11 00:38:45,075 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f591ce98b9476f88b364007bcb39e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b0a29e81d544e89599ed6a37b7e81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:38:49,006 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:52,542 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:54,258 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:55,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:38:57,621 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de261d8188147a0b620d7ae694f520b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f3b45327d241eaba5d4f6ef52e4214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3daeb6dc83174af78cf9b7c52b18dbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8432e9cb2443dca0d4daa2d1fca5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:00,526 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Emily%20Dickinson%27s%20poetry%20was%20edited%20by%20publishers%20during%20her%20lifetime. 200\n",
      "2025-11-11 00:39:01,393 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:39:04,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1712ddcf714aa49917860550cb7571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:222: ResourceWarning: unclosed <ssl.SSLSocket fd=7040, family=2, type=1, proto=0, laddr=('10.0.0.30', 59313), raddr=('52.149.246.39', 443)>\n",
      "  def __init__(self, value: t.Any) -> None:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e557d47fb7b481a90084d5001a0923a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:07,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:09,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:10,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:11,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:12,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d27c26d6b4c4baf8b1d13e20779b4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b1bf479ef74f7699e7520acf023c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4fe058e0394c1e8f48a4455e0c4b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37bedd76a124b5dacae141ae6dababc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:14,809 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Michelle%20Williams%20acted%20in%20a%20Martin%20Scorsese%20film. 200\n",
      "2025-11-11 00:39:15,073 - primp - INFO - response: https://search.yahoo.com/search;_ylt=T03f1uIeK_eAMPHaWAkXCfhK;_ylu=79c_B_yvU8GarJxedmjPJVOM311L-qmByuCiGSfBRDwb2ko?p=Michelle+Williams+acted+in+a+Martin+Scorsese+film. 200\n",
      "2025-11-11 00:39:18,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c473ec92874e5c8299042de3ac27e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8287fe68396d4866ab6953eb41f75e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:21,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:23,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:24,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:25,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:26,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c74c6e2ee54f34bb084c76501d5a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596f97bdcc6d493dab1b1b7d962013d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fbd6c7ba814467a379970232fc4ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281f527a13bf4dcc922cd4dbbd27a3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:28,966 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20Long%20Run%20was%20solely%20written%20by%20Glenn%20Frey. 200\n",
      "2025-11-11 00:39:29,050 - primp - INFO - response: https://www.bing.com/search?q=The+Long+Run+was+solely+written+by+Glenn+Frey.&pq=The+Long+Run+was+solely+written+by+Glenn+Frey.&cc=en 200\n",
      "2025-11-11 00:39:31,501 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bbed3325d346b285944846b9204c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae43d0b62b884fe688f956c90812a81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:34,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:36,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:37,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:39,402 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:41,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8863ace509224d2ea52c28f973c5e681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a3382be011488f8ca8ab6783b47465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ef876fdd4447c7a7188cad35b60849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44d78bff17c4342a98fe2a2a2f37dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:43,820 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Sleep%20is%20undisturbed%20by%20any%20forces. 200\n",
      "2025-11-11 00:39:44,679 - primp - INFO - response: https://yandex.com/search/site/?text=Sleep+is+undisturbed+by+any+forces.&web=1&searchid=5531692 200\n",
      "2025-11-11 00:39:47,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5b49988be34ba1ac063809c6e25d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc0f31b3a174d9d83ebe097c84be2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:39:52,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:53,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:55,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:57,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:39:58,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e6e1cf2e3f4ce49e34e5d6e471716b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8173b9576c5443baa933d498d791650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100ee90a893c4e5d9db38436e4168b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda37f145f4645d09c428a383a6835bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:40:01,719 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Cancer%20has%20the%20potential%20to%20invade%20or%20spread%20to%20other%20parts%20of%20the%20arm. 200\n",
      "2025-11-11 00:40:01,859 - primp - INFO - response: https://www.bing.com/search?q=Cancer+has+the+potential+to+invade+or+spread+to+other+parts+of+the+arm.&pq=Cancer+has+the+potential+to+invade+or+spread+to+other+parts+of+the+arm.&cc=en 200\n",
      "2025-11-11 00:40:04,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71d1d0de37c4e94a1650407894d0a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68115f4671934d55b796f13feb28b9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:40:07,268 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:08,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:08,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:09,963 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:10,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:13,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:15,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:17,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:19,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:20,696 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98c7724e1c244a4bd103550cb68b22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c77039c6e254ddda3ba44f39c265ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ca6d2d6b9844aab468cf896e10b2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a3846f4f40422bada2e532cef3f19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:40:25,369 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=24%20is%20an%20American%20film. 200\n",
      "2025-11-11 00:40:26,550 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:40:30,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d2b3933e974c09a4f9d67f6aa98b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bd4f42215848398cdf61791194e43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\typing.py:407: ResourceWarning: unclosed <ssl.SSLSocket fd=6800, family=2, type=1, proto=0, laddr=('10.0.0.30', 64276), raddr=('52.149.246.39', 443)>\n",
      "  def _eval_type(t, globalns, localns, type_params=None, *, recursive_guard=frozenset()):\n",
      "2025-11-11 00:40:35,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:36,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:37,309 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:38,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:39,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b8ff3b6dfd4213a7a370a26850962a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd687b103fb44d249a9b619565f3f9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56e678d591840e2a3f834854cb5eee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f3decb5f2e45c39300ceab03cd5a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642e86efbcaf4c1fb437893b1f382c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06192b6f1e1f45dd954ab3e55ace2ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc087e4d01e4497ad856a0f5586cf7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:40:42,631 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Snowden%20was%20not%20filmed%20in%20Europe. 200\n",
      "2025-11-11 00:40:43,985 - primp - INFO - response: https://yandex.com/search/site/?text=Snowden+was+not+filmed+in+Europe.&web=1&searchid=7366645 200\n",
      "2025-11-11 00:40:47,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ae85c5aec44527adff0b5df5ca0829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af303a1fd8342bcb5b0a6b36d586e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:40:50,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:51,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:53,683 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:54,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:40:56,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9b5c67f8464590bc9518ecf5626614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887953df3ded4a8e81c092578b404360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7d7b44d9444659b31795b14977cb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b24d21add42b3ad05b7974b579644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:40:58,348 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Saamy%20is%20a%202003%20television%20show. 200\n",
      "2025-11-11 00:40:58,638 - primp - INFO - response: https://www.bing.com/search?q=Saamy+is+a+2003+television+show.&pq=Saamy+is+a+2003+television+show.&cc=en 200\n",
      "2025-11-11 00:41:00,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e67cd5440d64334ae6193c6baf2587f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45986c80d414f668af15640b029fbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:41:05,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:08,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:10,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:14,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:16,971 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d16967492041968d9dd590b5956a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ded6c8744144dd8f4ed4aaeb0a4849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3c2e568ae04a9a9a8dc64ba7d0790f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e35169d04b44be8838c02082bd7c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:41:18,897 - primp - INFO - response: https://search.yahoo.com/search;_ylt=gIZtK4fXPHM77i3JycPABB6n;_ylu=d8zYbUGgyIT7vdsTc1eyBfJdp2l3_d8XW-fAH0KbBWm2Lkw?p=Sense+and+Sensibility+continued+in+editing+throughout+the+19th%2C+20th%2C+and+21st+centuries. 200\n",
      "2025-11-11 00:41:20,132 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Sense%20and%20Sensibility%20continued%20in%20editing%20throughout%20the%2019th%2C%2020th%2C%20and%2021st%20centuries. 200\n",
      "2025-11-11 00:41:22,946 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2c2ffcb5a64cb586ed22f53a28cd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4798917db98d4f3c8cc83e3269006738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:41:25,220 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:26,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:26,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:28,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:29,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c97a45829b24b018e701e94f64c360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6aea0c492154d73a5e9b516af38adb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b039be2ab9e4b47b5f7f6d41fdef5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43c950b4a754ad2ab715fdb2b235c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:41:30,959 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=J.%20Cole%20was%20born%20in%20January%2028th%2C1985. 200\n",
      "2025-11-11 00:41:31,556 - primp - INFO - response: https://search.brave.com/search?q=J.+Cole+was+born+in+January+28th%2C1985.&source=web 429\n",
      "2025-11-11 00:41:33,213 - primp - INFO - response: https://yandex.com/search/site/?text=J.+Cole+was+born+in+January+28th%2C1985.&web=1&searchid=7395691 200\n",
      "2025-11-11 00:41:35,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff8092e6e024482ad196624ce540149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd7fd587dfc430c80f0b400e04e847e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:41:37,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:39,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:41,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:43,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:45,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a313c4b6dd3341c6b097d8c4e1281dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd3777a45484f2a8867b7aea168c736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9daa281ff8462786fc29f5202f186f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e54caa519c343e3bafbb5881b1a45ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:41:47,588 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Enemy%20has%20only%20ever%20been%20a%20book. 200\n",
      "2025-11-11 00:41:47,588 - primp - INFO - response: https://www.bing.com/search?q=Enemy+has+only+ever+been+a+book.&pq=Enemy+has+only+ever+been+a+book.&cc=en 200\n",
      "2025-11-11 00:41:50,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e8b770d20e4880888a2e01eddcf0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119b2efd55184db3b62712cdc06333bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:41:53,154 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:54,506 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:56,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:57,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:41:59,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41496dfae2314ab9b18f1aa2888dfbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60b3b7bc4fd428a872e40e5f4b6d080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88655a3fbff44db28c8bcee6887f0597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded3f0bca2ac4392a3b9eec0c2a9631f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9898863af434f41a8da13e46ad1e564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc5153b193740d3a3880910b144519d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19967963c55447fcb44c2e4f3222a893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:00,999 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Gwen%20Stefani%20is%20a%20radio%20personality. 200\n",
      "2025-11-11 00:42:02,227 - primp - INFO - response: https://yandex.com/search/site/?text=Gwen+Stefani+is+a+radio+personality.&web=1&searchid=2625658 200\n",
      "2025-11-11 00:42:05,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68deef1d59ae47d99da55ceb8061fae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d1908a47a8414c9e188cb81fea4841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:08,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:10,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:13,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:16,733 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:19,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430859b670c2418cb1b0674e833d401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993cb5c24da14acdbfc9d64e5f246f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c18fbe4e4a43f7ab69e42d01ce5d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9ecc807bd341ef8d05b75e4439ecd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:20,941 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Colombia%20has%20endemic%20species. 200\n",
      "2025-11-11 00:42:21,562 - primp - INFO - response: https://search.yahoo.com/search;_ylt=u4uLTW7ajWpY_808BuOtafoH;_ylu=Ouv-FBsnnFXMwwSIYsaPbnhscSK5VoRVdUB9LIEw8n0C9nw?p=Colombia+has+endemic+species. 200\n",
      "2025-11-11 00:42:24,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fa0e35648e4452aff9ac6aeaf15cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32493ba4879d4004b5636cae71ee74a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:26,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:27,474 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:28,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:29,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:30,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5012fbbcc96d42dea1110e08d6ef1bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535841f30e044c699ca4dc7ec1d4799e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107bb758b29f40dbae15eced0d6265ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42902e6ccd74253a043708d815da73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:32,702 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Steffi%20Graf%20has%20won%2031%20Grand%20Slam%20singles%20finals%20of%20tennis. 200\n",
      "2025-11-11 00:42:32,702 - primp - INFO - response: https://search.brave.com/search?q=Steffi+Graf+has+won+31+Grand+Slam+singles+finals+of+tennis.&source=web 429\n",
      "2025-11-11 00:42:36,809 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:42:40,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2f6b8687c941e6a72df6ccc9e32dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:1932: ResourceWarning: unclosed <ssl.SSLSocket fd=6920, family=2, type=1, proto=0, laddr=('10.0.0.30', 50661), raddr=('52.149.246.39', 443)>\n",
      "  for meta_name, meta_eval in metadata.items():\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09263a5be25e43668e705fdb1ebdd1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:42,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:43,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:45,200 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:46,426 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:47,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d11f6fc16034d62977826320f59eef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4400763eda474db36a9d0a5829a314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a10ab77f0a9457cb6e227fda248d089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ff385e52f743578eb79e746b92467b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:49,218 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Peyton%20Manning%20is%20currently%20an%20active%20athlete. 200\n",
      "2025-11-11 00:42:50,526 - primp - INFO - response: https://yandex.com/search/site/?text=Peyton+Manning+is+currently+an+active+athlete.&web=1&searchid=1608016 200\n",
      "2025-11-11 00:42:53,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dd0c0f47f844b296e78bfcee024f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61139f606fd846a5afed0d4aacafb2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:42:55,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:57,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:42:59,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:00,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:01,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d794dcdd5f47400a8cfa15e51a0ba586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67db7e1aa63e4858b04a0cea98db0580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea243b8008a4648a68b8666b781da13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ecac51ef1247fc9b73de25f29d0b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:02,623 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Denzel%20Washington%20played%20a%20corrupt%20cop%20in%202011. 200\n",
      "2025-11-11 00:43:03,330 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:43:05,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def24b1834d4475fa47c76b4b8060aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\jupyter_client\\session.py:834: ResourceWarning: unclosed <ssl.SSLSocket fd=6956, family=2, type=1, proto=0, laddr=('10.0.0.30', 62504), raddr=('52.149.246.39', 443)>\n",
      "  for idx, buf in enumerate(buffers):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339a9d51f58f42e5a7934c951e02701e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:07,725 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:08,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:09,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:11,002 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:11,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:12,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:14,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:15,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:16,615 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:17,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05088223814b49dbb66ef5ba72798de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1a46cbcedc4622850b028d3eb7cc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0e48790c4340e1b1c192f5d0780e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8615a3bef3e4b099f01b9923342cde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:20,794 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Miley%20Cyrus%20did%20not%20star%20in%20Hannah%20Montana. 200\n",
      "2025-11-11 00:43:20,794 - primp - INFO - response: https://search.brave.com/search?q=Miley+Cyrus+did+not+star+in+Hannah+Montana.&source=web 429\n",
      "2025-11-11 00:43:22,326 - primp - INFO - response: https://yandex.com/search/site/?text=Miley+Cyrus+did+not+star+in+Hannah+Montana.&web=1&searchid=3938672 200\n",
      "2025-11-11 00:43:23,911 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63659b355dac43b3883e3adab9ef59f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454fba14b39b4ebbb4b0b5711acafeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:26,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:27,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:28,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:29,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:30,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad1563df0094c239f48848b84b7649d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf005880abb4945ac133e724701862b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7018d77facd5424894e8e2b50c502714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee19b3d2d1dc42cbba014e8db944803d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:31,782 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Reese%20Witherspoon%20was%20named%20Global%20Ambassador%20of%20Avon%20Products%20in%20March%202007. 200\n",
      "2025-11-11 00:43:32,100 - primp - INFO - response: https://www.mojeek.com/search?q=Reese+Witherspoon+was+named+Global+Ambassador+of+Avon+Products+in+March+2007. 403\n",
      "2025-11-11 00:43:32,396 - primp - INFO - response: https://search.yahoo.com/search;_ylt=abYIJtRf55rgYeY3TdpHywvJ;_ylu=EsK1I3gDTmUjLTpZuFviJdxnQKeiOov2TksKqszc24nKOUU?p=Reese+Witherspoon+was+named+Global+Ambassador+of+Avon+Products+in+March+2007. 200\n",
      "2025-11-11 00:43:36,563 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43389648a1f41d888cb75dc49428e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869a9eb744734ae5b4f2c36c9f84ecd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:38,459 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:39,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:40,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:41,525 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:42,394 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482a727c51454f8aafd36ca072133e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c2a48e97ac455497e0671f0ee3903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4615f9c8e564a2aaa8011cf2987f1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6032726ff048948525904aafd1b63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:44,119 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Professional%20wrestling%20is%20Kurt%20Angle%27s%20profession. 200\n",
      "2025-11-11 00:43:44,839 - primp - INFO - response: https://yandex.com/search/site/?text=Professional+wrestling+is+Kurt+Angle%27s+profession.&web=1&searchid=6934011 200\n",
      "2025-11-11 00:43:47,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d125ef99a024ebc843ed872a818cce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7de6668da74453ba626d5cd16d333f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:50,224 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:51,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:52,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:53,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:43:54,215 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8310a43a4ab43bbacd068786bd4a6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7c3194d6ba4026b82a1d7614bf3963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd900724f994cfdaee64ce2c3e07e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b4d4eaaab34fc28ae063be5a7dda68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:43:55,663 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Katy%20Perry%20is%20a%20Texan. 200\n",
      "2025-11-11 00:43:56,780 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:43:59,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab288a8f5e54f1c842e9d1a6f0b9140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:1248: ResourceWarning: unclosed <ssl.SSLSocket fd=6176, family=2, type=1, proto=0, laddr=('10.0.0.30', 62754), raddr=('52.149.246.39', 443)>\n",
      "  return types.MethodType(self.func, inst)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d20ec3bc1646d88fb1005506dd0f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:01,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:02,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:04,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:05,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:06,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d70fb415684dfcba3eff56449d0d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7382142c804a228f3d4040f92e1fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21181138e90a424d8f80f281adff967e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59af981ab080496fad4d86c33da36998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:08,171 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Hugh%20Jackman%20appeared%20in%20the%20movie%20Les%20Mis%C3%A9rables. 200\n",
      "2025-11-11 00:44:09,024 - primp - INFO - response: https://search.brave.com/search?q=Hugh+Jackman+appeared+in+the+movie+Les+Mis%C3%A9rables.&source=web 429\n",
      "2025-11-11 00:44:10,923 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:44:12,848 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\inspect.py:3213: ResourceWarning: unclosed <ssl.SSLSocket fd=6272, family=2, type=1, proto=0, laddr=('10.0.0.30', 62757), raddr=('52.149.246.39', 443)>\n",
      "  for param in itertools.chain(parameters_ex, parameters):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47834e641e0f4296a7a50d4853700e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3698b2ff5a4efeaec54954b09883e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:15,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:17,861 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:19,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:21,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:22,502 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b971e9ffeb9840fdb96f44511267a8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e661679e149c46e09c081457371cbdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5321392d860947ed953186307499b688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15a13354f6b495c84b46b6ab91bade5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:23,814 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Hippocrates%20was%20only%20called%20Hippocrates. 200\n",
      "2025-11-11 00:44:23,888 - primp - INFO - response: https://search.brave.com/search?q=Hippocrates+was+only+called+Hippocrates.&source=web 429\n",
      "2025-11-11 00:44:25,901 - primp - INFO - response: https://yandex.com/search/site/?text=Hippocrates+was+only+called+Hippocrates.&web=1&searchid=3657837 200\n",
      "2025-11-11 00:44:28,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d71b217bfe4403b1ff4b55366f15c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca521eb7b8c4fde8031a58ed3ab896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:30,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:31,911 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:32,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:34,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:35,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ee1f5ecc6d4b56878da508cc2c352f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195b7322621d4beab6b49ecca24b8466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8b4324931b45f483ef8e032fe483d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4710e14d23f64ae2802f7b9e93e1749d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:37,174 - primp - INFO - response: https://search.brave.com/search?q=Horseshoe+Falls+is+the+largest+of+three+waterfalls+also+known+as+Canadian+Falls.&source=web 429\n",
      "2025-11-11 00:44:37,206 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Horseshoe%20Falls%20is%20the%20largest%20of%20three%20waterfalls%20also%20known%20as%20Canadian%20Falls. 200\n",
      "2025-11-11 00:44:38,462 - primp - INFO - response: https://yandex.com/search/site/?text=Horseshoe+Falls+is+the+largest+of+three+waterfalls+also+known+as+Canadian+Falls.&web=1&searchid=5646568 200\n",
      "2025-11-11 00:44:40,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242295f8dc574380b8465059dfef4e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c949bd2d6aa94559b498105e2921ee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:42,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:43,187 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:44,404 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:45,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:46,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:47,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:48,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:49,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:50,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:50,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b16cd710a4a4e17aec64979eb69dd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69e3fb238c84c7195ae5998341a75bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661bc37425024d76a81349109267cf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77244938dea04a8c9364a3328bbfab25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:53,601 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Saving%20Face%20is%20a%20winner%20at%20the%2084th%20Academy%20Awards. 200\n",
      "2025-11-11 00:44:54,199 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:44:55,867 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:258: ResourceWarning: unclosed <ssl.SSLSocket fd=5312, family=2, type=1, proto=0, laddr=('10.0.0.30', 58855), raddr=('52.149.246.39', 443)>\n",
      "  def schedule(self, f):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599ac2fe8280408e903787dd2c5adbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a625507a044342f391be3c440bbe83a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:44:57,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:58,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:44:59,555 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:00,574 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:01,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99c4aca493545a883838fddd2a39c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc8dfb30a3442c8aac64c2418bce10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e0f4643de9406189bf45e306c25da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c477a1fd98b43d88df89695f4e2c6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:45:03,056 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Queen%20Latifah%20is%20an%20American%20citizen. 200\n",
      "2025-11-11 00:45:03,953 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:45:05,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2131501448f4fc68375dd283714f274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a40937ce58f4a1c8864d6508bbff2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:45:08,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:10,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\_weakrefset.py:21: ResourceWarning: unclosed <ssl.SSLSocket fd=5860, family=2, type=1, proto=0, laddr=('10.0.0.30', 58857), raddr=('52.149.246.39', 443)>\n",
      "  def __enter__(self):\n",
      "2025-11-11 00:45:11,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:13,682 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:14,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75d8b25cd8b49cba54c78a532c68a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a76f86c52494d4cac5f29fb48a18dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62980d267eca494ea5bfa586c9cc8e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919e5712ff27478eb6cbbdc21cd513f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:45:18,008 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Michelle%20Williams%20has%20been%20in%20a%20film. 200\n",
      "2025-11-11 00:45:18,180 - primp - INFO - response: https://search.brave.com/search?q=Michelle+Williams+has+been+in+a+film.&source=web 429\n",
      "2025-11-11 00:45:19,214 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:45:20,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71b4bbbf7534af596c9e8b32c58a71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0553f92d3c6494e961e9ab14db21972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\typing.py:430: ResourceWarning: unclosed <ssl.SSLSocket fd=5860, family=2, type=1, proto=0, laddr=('10.0.0.30', 58863), raddr=('52.149.246.39', 443)>\n",
      "  ev_args = tuple(\n",
      "2025-11-11 00:45:24,390 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:25,458 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:26,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:28,073 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:29,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3a45be0fcc4afba133a332fb765cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bd79073f044f83afa77dbe082979a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae74ef06f97548138c1c6b12aae7f31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936ad46adbb84e32b41e064132743de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:45:32,155 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Enemy%20%282013%20film%29%20features%20an%20American%20actor%20born%20in%201980%20in%20a%20lead%20role. 200\n",
      "2025-11-11 00:45:32,412 - primp - INFO - response: https://www.bing.com/search?q=Enemy+%282013+film%29+features+an+American+actor+born+in+1980+in+a+lead+role.&pq=Enemy+%282013+film%29+features+an+American+actor+born+in+1980+in+a+lead+role.&cc=en 200\n",
      "2025-11-11 00:45:34,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23660a06162e4395b26a041e4c922f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bd30a67f3242b9b278b5c4ec322643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:45:38,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:40,391 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:42,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:43,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:45:45,838 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ab4543096941d7a3fcdb346f758898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1757490066f44f178279640abe9b8a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7fb2f8abfd4158a86c6498851eae23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9094ecf3534434681fd9b9a70290c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:45:48,481 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Dileep%20slept%20in%20Punjabi%20House. 200\n",
      "2025-11-11 00:45:48,613 - primp - INFO - response: https://search.brave.com/search?q=Dileep+slept+in+Punjabi+House.&source=web 429\n",
      "2025-11-11 00:45:49,061 - primp - INFO - response: https://search.yahoo.com/search;_ylt=R7rmN6wjtTBRdaXFBCwMn4af;_ylu=E8tj_sgrem_QSe0VSjreZ4RFwRX7XiLoC4oqy4t7dwBd08U?p=Dileep+slept+in+Punjabi+House. 200\n",
      "2025-11-11 00:45:58,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51d35624e9b4227beafbb6b7b0231c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6e28eb6f954e68804d9adc0c809b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:02,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:03,769 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:04,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:06,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:07,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264a8b808fb748b0a80e817e3abb472b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d118c99474b445d2b4f5d9b6d564febb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1a067e210647219a6861fe92930b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd2543f778a49448c4004e558f55316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:09,829 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Serena%20Williams%20is%20not%20a%20tennis%20player. 200\n",
      "2025-11-11 00:46:09,894 - primp - INFO - response: https://search.brave.com/search?q=Serena+Williams+is+not+a+tennis+player.&source=web 429\n",
      "2025-11-11 00:46:11,129 - primp - INFO - response: https://yandex.com/search/site/?text=Serena+Williams+is+not+a+tennis+player.&web=1&searchid=7965401 200\n",
      "2025-11-11 00:46:12,513 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df4117637894d0b9b76064ac8793a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba691c0c027f466bb09ec73191690053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:15,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:16,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:18,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:18,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:19,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f2ceaf167b4f938a039749291eaa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65f37ba70de403bb245a3b50259f5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3777a24574754fbbb038020006cd10aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d8432aaf6f490aaeb4d5e1ca09f52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:20,920 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Veronica%20Mars%20is%20the%20protagonist%20of%20a%20show%20with%20a%20completely%20different%20name. 200\n",
      "2025-11-11 00:46:21,046 - primp - INFO - response: https://search.brave.com/search?q=Veronica+Mars+is+the+protagonist+of+a+show+with+a+completely+different+name.&source=web 429\n",
      "2025-11-11 00:46:21,307 - primp - INFO - response: https://search.yahoo.com/search;_ylt=2KpYvCTlkI8vxmMvs-q8itQR;_ylu=_sbHp5FlsGNV4zxMNN1QsghtQmdCb7kMsTeF80vtibmJFRo?p=Veronica+Mars+is+the+protagonist+of+a+show+with+a+completely+different+name. 200\n",
      "2025-11-11 00:46:24,059 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5044a80fc2714864b8f501bc80050530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0fd9ae0b0144d0ad4dc9ee2494a528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:27,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:28,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:30,457 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:32,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:35,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b30561ac6124d7bb89dae08d2d93986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e441173c94540dfad05088f28775d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d7ad4789d1414c85124f30f1cd7161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923f2277dfc24a7db86c434984a639c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:37,245 - primp - INFO - response: https://search.brave.com/search?q=John+Stewart+is+a+real+American+hero.&source=web 429\n",
      "2025-11-11 00:46:37,246 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=John%20Stewart%20is%20a%20real%20American%20hero. 200\n",
      "2025-11-11 00:46:38,721 - primp - INFO - response: https://search.yahoo.com/search;_ylt=YPWs4UIIdvaABJKU-gLfAnWy;_ylu=jBhZdW2DA3XavA03q0_yVfuKKOpemdk4YAz1Y6PDfxV2CQo?p=John+Stewart+is+a+real+American+hero. 200\n",
      "2025-11-11 00:46:42,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410663dfad13413da1a863ec540911c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10430f50b59c480a99fd8ef94a84aea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:44,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:45,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:46,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:47,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:48,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:49,556 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:50,281 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:51,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:51,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:46:52,560 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b40e03ca03414aa07ce444b80a682c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6842fa61eec94fd0b63f3a2151a0a197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57d48958a49488294ac2e8b922b65e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0844971f79a1459398ec21737f382f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:55,091 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=United%20States%20Congress%20has%20200%20Senators. 200\n",
      "2025-11-11 00:46:55,629 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:46:57,555 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa5cecda7bf4c399715d26bfd61e6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972e24e492774ca084262d9b6c8918ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:46:59,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:02,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:03,216 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\asyncio\\base_events.py:838: ResourceWarning: unclosed <ssl.SSLSocket fd=7072, family=2, type=1, proto=0, laddr=('10.0.0.30', 63257), raddr=('52.149.246.39', 443)>\n",
      "  def call_soon_threadsafe(self, callback, *args, context=None):\n",
      "2025-11-11 00:47:05,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:06,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36e31c0a86e49dca0ea79cee3e32fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadaf4085bfd404cbd429a07316bbb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdbaf3d8f0d4e6c9dc74f6e13f9bb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d79caf54ed443f4a02cb60e474cb116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:47:08,469 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Sunrise%20created%20a%20co-production. 200\n",
      "2025-11-11 00:47:08,795 - primp - INFO - response: https://www.mojeek.com/search?q=Sunrise+created+a+co-production. 403\n",
      "2025-11-11 00:47:09,945 - primp - INFO - response: https://search.brave.com/search?q=Sunrise+created+a+co-production.&source=web 429\n",
      "2025-11-11 00:47:11,413 - primp - INFO - response: https://www.bing.com/search?q=Sunrise+created+a+co-production.&pq=Sunrise+created+a+co-production.&cc=en 200\n",
      "2025-11-11 00:47:14,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715c5b9096294b09840fd689d53b2e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa57014321e4ac885c0b92fc0f448f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:47:18,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:19,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:20,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:22,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:24,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a83df48cefb471f8910f41a16063906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb84061e16a457e926e77c1fc3d30ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4416b8bb85b6469d8601a7c7e0bf3920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75c48d2063d40999376c73fbc8d3674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:47:25,988 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Dr.%20Dre%20established%20his%20own%20country. 200\n",
      "2025-11-11 00:47:26,034 - primp - INFO - response: https://www.bing.com/search?q=Dr.+Dre+established+his+own+country.&pq=Dr.+Dre+established+his+own+country.&cc=en 200\n",
      "2025-11-11 00:47:27,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bb588f4430466ca4dc9d92b19ff9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7725bf267c434c8693a0861d9e07b239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:47:31,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:33,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:34,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:36,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:37,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ee5fa1052e414e86723d4dcb09ddbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388defd9a86748c0aaa9a2eb81cf175e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d0f37a8ab149229156c48c6f232123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce3b5e95218433d8e03a6dae25b2483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:47:39,335 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Clarence%20Thomas%20was%20exclusively%20self-educated. 200\n",
      "2025-11-11 00:47:39,471 - primp - INFO - response: https://search.brave.com/search?q=Clarence+Thomas+was+exclusively+self-educated.&source=web 429\n",
      "2025-11-11 00:47:40,474 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:47:42,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6c9acdfd4d4296bd10671f61610c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294133a4e6c2474a8e89603a4e90fdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:349: ResourceWarning: unclosed <ssl.SSLSocket fd=5528, family=2, type=1, proto=0, laddr=('10.0.0.30', 60679), raddr=('52.149.246.39', 443)>\n",
      "  if return_length:\n",
      "2025-11-11 00:47:44,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:45,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:46,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:47,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:48,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cd09ccf6414393965f5a0d495f82a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611fa0e8892248f6b48b4ccf2788e850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc2f4caf5fb47d18791e138e316839e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab39e1811cc43d7aec70ccaf29df931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:47:51,824 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Audrey%20Horne%20was%20presented%20in%20the%20pilot. 200\n",
      "2025-11-11 00:47:52,650 - primp - INFO - response: https://yandex.com/search/site/?text=Audrey+Horne+was+presented+in+the+pilot.&web=1&searchid=7619932 200\n",
      "2025-11-11 00:47:54,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6821bbff194f47519f27aea702c68dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c0cee72975410caf7f5c845bfa1ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:47:56,471 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:57,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:58,352 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:47:59,568 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:00,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:02,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:03,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:05,005 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:06,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:08,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1a44f6315d439281bdc8116b239c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2351d0cb7c80453197784d2087033add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e1566ef40b409dbd2a77fa7b2f15b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14df9a7ad2e436b8fbcb31d258fba4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:48:11,068 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Vera%20Farmiga%20is%20a%20award-winning%20director. 200\n",
      "2025-11-11 00:48:12,581 - primp - INFO - response: https://yandex.com/search/site/?text=Vera+Farmiga+is+a+award-winning+director.&web=1&searchid=9600176 200\n",
      "2025-11-11 00:48:14,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2492bab4fd4d94ae1508eacd00eaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb8447a4d64460bbef89f7c19d27214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:48:17,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:19,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:20,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:22,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:23,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afb2dea6df4441d9af286a80f14e3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4d2296e6e3436d83088dbf9786addf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6794ff459c483a9faa2ed45bf23547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae712985e72444faa0af9a26a804659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:48:25,478 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Broad%20Green%20Pictures%20supports%20American%20companies. 200\n",
      "2025-11-11 00:48:26,199 - primp - INFO - response: https://www.mojeek.com/search?q=Broad+Green+Pictures+supports+American+companies. 403\n",
      "2025-11-11 00:48:27,328 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:48:29,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ce277016ba4980915c04c9c7c05a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b925a195f14a458cb1b338892530b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:697: ResourceWarning: unclosed <ssl.SSLSocket fd=6504, family=2, type=1, proto=0, laddr=('10.0.0.30', 60687), raddr=('52.149.246.39', 443)>\n",
      "  def convert_to_tensors(\n",
      "2025-11-11 00:48:32,561 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:34,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:36,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:37,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:38,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c95fe8b15744b098be56a9da5370d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567b6478425c4e18943916d293d7b12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f3e0897a9e48f68404abff0a597d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc1c1f8ad8d48589f2e8fca9a4af4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:48:40,433 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20Dakota%20is%20an%20apartment%20located%20in%20the%20Upper%20East%20Side%20of%20Manhattan. 200\n",
      "2025-11-11 00:48:41,248 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:48:43,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62d9f202eff4f6b997ec660709c7e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\ipykernel\\comm\\comm.py:31: ResourceWarning: unclosed <ssl.SSLSocket fd=5604, family=2, type=1, proto=0, laddr=('10.0.0.30', 64201), raddr=('52.149.246.39', 443)>\n",
      "  content = json_clean(dict(data=data, comm_id=self.comm_id, **keys))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540335a5031242908b873299e4e0d0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:48:46,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:48,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:50,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:52,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:48:54,969 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf46a5b99d94b19ad51b658e6c8a982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737a754ec6154fd5938dd42cd4da03e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0aaf0026ae442fb6f44b64c6b8e7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e010df03365441bb39bf6b992a447c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:48:56,301 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Alex%20Rodriguez%20received%20feedback%20from%20the%20media. 200\n",
      "2025-11-11 00:48:57,537 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:49:00,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab8d25bad2842c6aef0ffa1bd3ad609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1755: ResourceWarning: unclosed <ssl.SSLSocket fd=7060, family=2, type=1, proto=0, laddr=('10.0.0.30', 64204), raddr=('52.149.246.39', 443)>\n",
      "  def _call_impl(self, *args, **kwargs):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ffc03926034895a12e83fcd5715a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:02,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:03,644 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:04,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:05,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:07,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b122426ae1b0430390a6895617fbb08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80f34492bcf40759ef29b64a71c21f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee06ab501744cadac0d40c7d2e81ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882f5c057e3a4bcd8010557e4452626e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:08,638 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Ryan%20Seacrest%20was%20born%20on%20a%20boat. 200\n",
      "2025-11-11 00:49:09,827 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-11 00:49:11,008 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45576faa6d74fe982f2806b883725a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf6c565b8e74aaaa1880039b25ffcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:12,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:13,903 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\typing.py:407: ResourceWarning: unclosed <ssl.SSLSocket fd=6880, family=2, type=1, proto=0, laddr=('10.0.0.30', 52530), raddr=('52.149.246.39', 443)>\n",
      "  def _eval_type(t, globalns, localns, type_params=None, *, recursive_guard=frozenset()):\n",
      "2025-11-11 00:49:14,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:16,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:17,699 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e7ef5e9faf410389afbf513c7d0320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dbb181274d4b36a9526f5e8b0d5de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1dd3b08a464c959160ac577b915294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28dbf0abf9b4e428d7c647202b9a454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:19,246 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Kris%20Wu%20was%20born%20in%202010. 200\n",
      "2025-11-11 00:49:19,580 - primp - INFO - response: https://www.mojeek.com/search?q=Kris+Wu+was+born+in+2010. 403\n",
      "2025-11-11 00:49:19,864 - primp - INFO - response: https://search.yahoo.com/search;_ylt=QUO8hIq2whX16Y9XEyIpbz5Q;_ylu=KRG4IuS_uBokLcjamTK8JzTxo7GiTUyUpBSrV9Th64lhJA8?p=Kris+Wu+was+born+in+2010. 200\n",
      "2025-11-11 00:49:22,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba4e605ef4a408b9e5df763ceaad278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6364f87c4ea44809b96c5e778bac50e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:23,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:24,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:25,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:26,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:27,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:28,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:28,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:29,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:30,680 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:31,420 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bb74b798234183aa93d00661ab824a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7cd7cda6c34b48ac97326676743306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8d3dce1c2a4a14b42cbfc7efe1fbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9960dde61347eb960a7d5aae7b17c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:34,019 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Seth%20MacFarlane%20directed%20Ted. 200\n",
      "2025-11-11 00:49:34,019 - primp - INFO - response: https://www.bing.com/search?q=Seth+MacFarlane+directed+Ted.&pq=Seth+MacFarlane+directed+Ted.&cc=en 200\n",
      "2025-11-11 00:49:35,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bc734d108643df874327de47e36789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb6e62359064fa59a21fa2fea726c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:37,635 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:38,680 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:40,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:41,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:43,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad86b34a7f3476d901cad507460c4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740af73bb07b4797b9442e5221af7b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a2392979f642609d726846213de5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2a976075154932821107783de6be8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:44,532 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Barbados%20has%20a%20population%20of%20280%2C121%20people%20that%20reside%20on%20the%20island. 200\n",
      "2025-11-11 00:49:44,742 - primp - INFO - response: https://search.yahoo.com/search;_ylt=bZUWlBhqTwxqSwSO5d4SRgLg;_ylu=2jNsdYc1-N1Aq9Sb0ilR3EmcmMbLFc-H6yNB806RyiOCDcs?p=Barbados+has+a+population+of+280%2C121+people+that+reside+on+the+island. 200\n",
      "2025-11-11 00:49:49,251 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a694f45c214adf8d2ba059976fc4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58052ae5872e4c3d9de5c688168d9d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:51,402 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:52,835 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:53,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:54,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:49:55,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa81fb35966458fa5dfd205885df1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324d3367bd884c149400bd75411e5735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981bfca5177c46e0914857aae29d379b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482702729fe845a497309cda2d092c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:49:57,031 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Paul%20Walker%20was%20a%20citizen%20of%20a%20country. 200\n",
      "2025-11-11 00:49:57,764 - primp - INFO - response: https://yandex.com/search/site/?text=Paul+Walker+was+a+citizen+of+a+country.&web=1&searchid=1803820 200\n",
      "2025-11-11 00:49:59,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Checkpoint saved at claim 100\n",
      "   Current accuracy: 65.00%\n",
      "   ETA: 0 minutes\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä FINAL RESULTS\n",
      "======================================================================\n",
      "\n",
      "Total Claims: 100\n",
      "Correct: 65\n",
      "Incorrect: 35\n",
      "\n",
      "üéØ ACCURACY: 65.00%\n",
      "\n",
      "======================================================================\n",
      "CONFUSION MATRIX\n",
      "======================================================================\n",
      "\n",
      "Actual               SUPPORTS        REFUTES         NOT ENOUGH INFO\n",
      "-----------------------------------------------------------------\n",
      "SUPPORTS             29              2               1              \n",
      "REFUTES              5               33              0              \n",
      "NOT ENOUGH INFO      14              13              3              \n",
      "\n",
      "======================================================================\n",
      "PER-CLASS ACCURACY\n",
      "======================================================================\n",
      "\n",
      "SUPPORTS             90.62%  (29/32)\n",
      "\n",
      "REFUTES              86.84%  (33/38)\n",
      "\n",
      "NOT ENOUGH INFO      10.00%  (3/30)\n",
      "\n",
      "======================================================================\n",
      "üíæ SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "‚úì Results saved to: C:\\Users\\pooji\\Desktop\\complete_8layer_results_15000.json\n",
      "\n",
      "======================================================================\n",
      "üìä COMPARISON WITH BASELINES\n",
      "======================================================================\n",
      "\n",
      "System                                   Accuracy        Improvement    \n",
      "----------------------------------------------------------------------\n",
      "Baseline (GPT-4o only)                   59.05%\n",
      "RAG (Wikipedia only)                     62.75%      +3.7%\n",
      "8-Layer System                           65.00%      +5.9%\n",
      "\n",
      "üéØ Total improvement: +5.9 percentage points\n",
      "\n",
      "‚úì Checkpoint cleaned up\n",
      "\n",
      "======================================================================\n",
      "‚úÖ EVALUATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Results saved to: C:\\Users\\pooji\\Desktop\\complete_8layer_results_15000.json\n",
      "üéì Ready for Progress Update 2!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FEVER EVALUATION - JUPYTER NOTEBOOK VERSION\n",
    "Run this cell after running your UI code cell\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from tqdm.notebook import tqdm  # Use notebook version of tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# HallucinationDetector is already defined in the previous cell!\n",
    "# No import needed!\n",
    "\n",
    "def evaluate_on_fever(num_claims=15000):\n",
    "    \"\"\"\n",
    "    Fully automated evaluation on FEVER dataset\n",
    "    For Jupyter Notebook\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"üî¨ AUTOMATED FEVER EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 1: LOAD FEVER CLAIMS\n",
    "    # ============================================\n",
    "    claims_file = r\"C:\\Users\\pooji\\Desktop\\fever_claims_full.json\"\n",
    "    \n",
    "    print(f\"\\nüìÅ Loading claims from: {claims_file}\")\n",
    "    \n",
    "    if not os.path.exists(claims_file):\n",
    "        print(f\"‚ùå ERROR: File not found: {claims_file}\")\n",
    "        return\n",
    "    \n",
    "    with open(claims_file, 'r', encoding='utf-8') as f:\n",
    "        all_claims = json.load(f)\n",
    "    \n",
    "    claims = all_claims[:num_claims]\n",
    "    print(f\"‚úì Loaded {len(claims)} claims\")\n",
    "    print(f\"   Sample: {claims[0]['claim'][:80]}...\")\n",
    "    print()\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 2: INITIALIZE DETECTOR\n",
    "    # ============================================\n",
    "    print(\"üöÄ Initializing system...\")\n",
    "    detector = HallucinationDetector()\n",
    "    print(\"‚úì System ready\\n\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 3: CHECK FOR CHECKPOINT\n",
    "    # ============================================\n",
    "    checkpoint_file = r\"C:\\Users\\pooji\\Desktop\\fever_checkpoint.json\"\n",
    "    results = []\n",
    "    \n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(\"üìÇ Found checkpoint!\")\n",
    "        response = input(\"Resume from checkpoint? (y/n): \").strip().lower()\n",
    "        if response == 'y':\n",
    "            with open(checkpoint_file, 'r') as f:\n",
    "                checkpoint = json.load(f)\n",
    "            results = checkpoint['results']\n",
    "            print(f\"‚úì Resuming from claim {len(results)}\\n\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 4: PROCESS CLAIMS\n",
    "    # ============================================\n",
    "    print(\"=\"*70)\n",
    "    print(\"PROCESSING CLAIMS\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "    \n",
    "    correct = len([r for r in results if r.get('correct', False)])\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get remaining claims\n",
    "        remaining_claims = claims[len(results):]\n",
    "        \n",
    "        # Progress bar (notebook version)\n",
    "        pbar = tqdm(remaining_claims, desc=\"Processing\", initial=len(results), total=len(claims))\n",
    "        \n",
    "        for i, claim_data in enumerate(pbar, start=len(results)):\n",
    "            claim_text = claim_data['claim']\n",
    "            actual_label = claim_data['label']\n",
    "            \n",
    "            try:\n",
    "                # Run detection\n",
    "                result = detector.detect(claim_text)\n",
    "                \n",
    "                # Get predicted FEVER label\n",
    "                predicted_label = result.get('fever_label')\n",
    "                \n",
    "                # Handle cases where it wasn't detected as a claim\n",
    "                if predicted_label is None:\n",
    "                    if result.get('claim_verification'):\n",
    "                        predicted_label = result['claim_verification']['label']\n",
    "                    else:\n",
    "                        predicted_label = 'NOT ENOUGH INFO'\n",
    "                \n",
    "                # Check correctness\n",
    "                is_correct = (predicted_label == actual_label)\n",
    "                if is_correct:\n",
    "                    correct += 1\n",
    "                \n",
    "                # Calculate current accuracy\n",
    "                current_acc = correct / (i + 1)\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'Accuracy': f'{current_acc:.2%}',\n",
    "                    'Correct': f'{correct}/{i+1}'\n",
    "                })\n",
    "                \n",
    "                # Store result\n",
    "                results.append({\n",
    "                    'claim_id': claim_data.get('id', i),\n",
    "                    'claim': claim_text,\n",
    "                    'actual': actual_label,\n",
    "                    'predicted': predicted_label,\n",
    "                    'correct': is_correct,\n",
    "                    'answer': result.get('answer', ''),\n",
    "                    'confidence': result.get('combined_confidence', 0),\n",
    "                    'risk_level': result.get('risk_level', ''),\n",
    "                    'mode': result.get('mode', 'Unknown')\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è Error on claim {i}: {str(e)[:100]}\")\n",
    "                results.append({\n",
    "                    'claim_id': claim_data.get('id', i),\n",
    "                    'claim': claim_text,\n",
    "                    'actual': actual_label,\n",
    "                    'predicted': 'ERROR',\n",
    "                    'correct': False,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "            \n",
    "            # Save checkpoint every 100 claims\n",
    "            if (i + 1) % 100 == 0:\n",
    "                save_checkpoint(results, i + 1, checkpoint_file)\n",
    "                \n",
    "                # Calculate ETA\n",
    "                elapsed = time.time() - start_time\n",
    "                claims_per_sec = (i + 1 - len(results)) / elapsed if elapsed > 0 else 0\n",
    "                remaining = len(claims) - (i + 1)\n",
    "                eta_minutes = (remaining / claims_per_sec / 60) if claims_per_sec > 0 else 0\n",
    "                \n",
    "                print(f\"\\nüíæ Checkpoint saved at claim {i+1}\")\n",
    "                print(f\"   Current accuracy: {current_acc:.2%}\")\n",
    "                print(f\"   ETA: {eta_minutes:.0f} minutes\\n\")\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(0.3)\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è INTERRUPTED BY USER\")\n",
    "        print(f\"Processed {len(results)} claims\")\n",
    "        save_checkpoint(results, len(results), checkpoint_file)\n",
    "        print(\"Progress saved. Run cell again to resume.\\n\")\n",
    "        return\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 5: CALCULATE METRICS\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä FINAL RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    accuracy = correct / len(results) if results else 0\n",
    "    \n",
    "    print(f\"\\nTotal Claims: {len(results)}\")\n",
    "    print(f\"Correct: {correct}\")\n",
    "    print(f\"Incorrect: {len(results) - correct}\")\n",
    "    print(f\"\\nüéØ ACCURACY: {accuracy:.2%}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 6: CONFUSION MATRIX\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONFUSION MATRIX\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    confusion = calculate_confusion_matrix(results)\n",
    "    \n",
    "    print(f\"\\n{'Actual':<20} {'SUPPORTS':<15} {'REFUTES':<15} {'NOT ENOUGH INFO':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for actual in ['SUPPORTS', 'REFUTES', 'NOT ENOUGH INFO']:\n",
    "        row = confusion.get(actual, {})\n",
    "        print(f\"{actual:<20} {row.get('SUPPORTS', 0):<15} {row.get('REFUTES', 0):<15} {row.get('NOT ENOUGH INFO', 0):<15}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 7: PER-CLASS ACCURACY\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PER-CLASS ACCURACY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for label in ['SUPPORTS', 'REFUTES', 'NOT ENOUGH INFO']:\n",
    "        label_results = [r for r in results if r.get('actual') == label and r.get('predicted') != 'ERROR']\n",
    "        label_correct = len([r for r in label_results if r.get('correct', False)])\n",
    "        label_total = len(label_results)\n",
    "        label_acc = label_correct / label_total if label_total > 0 else 0\n",
    "        print(f\"\\n{label:<20} {label_acc:.2%}  ({label_correct}/{label_total})\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 8: SAVE RESULTS\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üíæ SAVING RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    output_file = r\"C:\\Users\\pooji\\Desktop\\complete_8layer_results_15000.json\"\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'system': '8-layer system with claim verification',\n",
    "            'accuracy': accuracy,\n",
    "            'correct': correct,\n",
    "            'total': len(results),\n",
    "            'confusion_matrix': confusion,\n",
    "            'per_class_accuracy': {\n",
    "                label: len([r for r in results if r.get('actual') == label and r.get('correct', False)]) / len([r for r in results if r.get('actual') == label]) if [r for r in results if r.get('actual') == label] else 0\n",
    "                for label in ['SUPPORTS', 'REFUTES', 'NOT ENOUGH INFO']\n",
    "            },\n",
    "            'sample_results': results[:100]\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úì Results saved to: {output_file}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 9: COMPARISON\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä COMPARISON WITH BASELINES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    baseline_acc = 0.5905\n",
    "    rag_acc = 0.6275\n",
    "    \n",
    "    print(f\"\\n{'System':<40} {'Accuracy':<15} {'Improvement':<15}\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Baseline (GPT-4o only)':<40} {baseline_acc:.2%}\")\n",
    "    print(f\"{'RAG (Wikipedia only)':<40} {rag_acc:.2%}      +{(rag_acc-baseline_acc)*100:.1f}%\")\n",
    "    print(f\"{'8-Layer System':<40} {accuracy:.2%}      +{(accuracy-baseline_acc)*100:.1f}%\")\n",
    "    \n",
    "    improvement = (accuracy - baseline_acc) * 100\n",
    "    print(f\"\\nüéØ Total improvement: +{improvement:.1f} percentage points\")\n",
    "    \n",
    "    # Cleanup checkpoint\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        os.remove(checkpoint_file)\n",
    "        print(\"\\n‚úì Checkpoint cleaned up\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ EVALUATION COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nüìÅ Results saved to: {output_file}\")\n",
    "    print(\"üéì Ready for Progress Update 2!\\n\")\n",
    "\n",
    "def calculate_confusion_matrix(results):\n",
    "    \"\"\"Calculate confusion matrix from results\"\"\"\n",
    "    matrix = {\n",
    "        'SUPPORTS': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0},\n",
    "        'REFUTES': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0},\n",
    "        'NOT ENOUGH INFO': {'SUPPORTS': 0, 'REFUTES': 0, 'NOT ENOUGH INFO': 0}\n",
    "    }\n",
    "    \n",
    "    for result in results:\n",
    "        actual = result.get('actual')\n",
    "        predicted = result.get('predicted')\n",
    "        \n",
    "        if predicted != 'ERROR' and actual in matrix:\n",
    "            if predicted in matrix[actual]:\n",
    "                matrix[actual][predicted] += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def save_checkpoint(results, num_processed, checkpoint_file):\n",
    "    \"\"\"Save progress checkpoint\"\"\"\n",
    "    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'num_processed': num_processed,\n",
    "            'results': results\n",
    "        }, f, indent=2)\n",
    "\n",
    "# ============================================\n",
    "# RUN THE EVALUATION\n",
    "# ============================================\n",
    "\n",
    "print(\"üéì FEVER EVALUATION - JUPYTER NOTEBOOK VERSION\")\n",
    "print()\n",
    "print(\"Choose test size:\")\n",
    "print(\"  1. Quick test (100 claims) - ~2 minutes\")\n",
    "print(\"  2. Medium test (1,000 claims) - ~15 minutes\")  \n",
    "print(\"  3. Full test (15,000 claims) - ~3-4 hours\")\n",
    "print()\n",
    "\n",
    "choice = input(\"Enter choice (1/2/3): \").strip()\n",
    "\n",
    "if choice == '1':\n",
    "    print(\"\\nüß™ Running quick test with 100 claims...\\n\")\n",
    "    evaluate_on_fever(num_claims=100)\n",
    "elif choice == '2':\n",
    "    print(\"\\nüß™ Running medium test with 1,000 claims...\\n\")\n",
    "    evaluate_on_fever(num_claims=1000)\n",
    "elif choice == '3':\n",
    "    print(\"\\nüß™ Running FULL test with 15,000 claims...\\n\")\n",
    "    confirm = input(\"This will take 3-4 hours. Continue? (y/n): \").strip().lower()\n",
    "    if confirm == 'y':\n",
    "        evaluate_on_fever(num_claims=15000)\n",
    "    else:\n",
    "        print(\"Cancelled.\")\n",
    "else:\n",
    "    print(\"Invalid choice. Run the cell again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109974e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéØ ADVERSARIAL ROBUSTNESS TESTING\n",
      "======================================================================\n",
      "\n",
      "‚úì Loaded 15000 claims\n",
      "   Selected 20 diverse claims for testing\n",
      "   ‚Ä¢ SUPPORTS: 7 claims\n",
      "   ‚Ä¢ REFUTES: 7 claims\n",
      "   ‚Ä¢ NOT ENOUGH INFO: 6 claims\n",
      "\n",
      "‚è≥ Initializing detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:48:26,628 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-11-10 23:48:31,009 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-11-10 23:48:31,326 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Initializing adversarial tester...\n",
      "\n",
      "‚è≥ Starting adversarial testing...\n",
      "   This will generate ~60-80 adversarial examples\n",
      "   Estimated time: 5-10 minutes\n",
      "   (Each claim is tested with detect() - may take a while)\n",
      "\n",
      "======================================================================\n",
      "üéØ ADVERSARIAL ROBUSTNESS TESTING\n",
      "======================================================================\n",
      "\n",
      "üî¨ Testing 20 claims...\n",
      "   Generating adversarial examples...\n",
      "\n",
      "   Testing: Estella Warren is an actress....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e867fe43b3e54e3a8a5c396c8a6b99c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f24d301d01a462980d0e07a1beaf8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:48:34,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:36,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:38,427 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:39,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:41,583 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f51fba8ee04e0b9fe830b0938a4e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6166366aa1534e88a092e76269646c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc6468c1fba480fa1b90ddc6079b00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16de78f0869b41dc888000db91377789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:48:42,967 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Estella%20Warren%20is%20an%20actress. 200\n",
      "2025-11-10 23:48:43,381 - primp - INFO - response: https://www.mojeek.com/search?q=Estella+Warren+is+an+actress. 403\n",
      "2025-11-10 23:48:44,170 - primp - INFO - response: https://search.yahoo.com/search;_ylt=q2sSmETRR9oO23lMbk7-ZyhP;_ylu=nRoTGQzZBNiAt_1w0riHGZYYz3KEVaOn-PjKFTeMEzlDv6o?p=Estella+Warren+is+an+actress. 200\n",
      "2025-11-10 23:48:47,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84deb9a6ea342958b3755be96e17874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f147fd0345d14b34bcd4e5af44d13998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:48:49,485 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:50,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:52,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:53,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:48:53,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd217b455814276af1f4c61f13509d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f218a1911fc42fcb57d1713e6d30dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec86ffd6ea5d4e6e8086f687cd390e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d869254a2e41c1ad883d43002ec256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:48:55,422 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Estella%20Warren%20is%20not%20an%20actress. 200\n",
      "2025-11-10 23:48:55,861 - primp - INFO - response: https://search.yahoo.com/search;_ylt=cf-ohlBYVZEyTJ-cCyDGNsdR;_ylu=l5i9vA37b9Qw09C1uGR87dDE2WwLRcAfCc89Di0unXO0oco?p=Estella+Warren+is+not+an+actress. 200\n",
      "2025-11-10 23:48:58,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Dwayne Douglas Johnson is a professional wrestler for the WW...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a0eb37abe14086af5447de0f2c926f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582bb1c1047c42ce9a7afee1d4791678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:00,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:01,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:03,764 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:05,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:07,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f623cbdf814a2d974f8339151b0ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c28614efcad4a91bad4b3deabf752a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bb304a3f99421c842f80a737c4524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bf5dd48171421aabda3592e1babaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:08,895 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Dwayne%20Douglas%20Johnson%20is%20a%20professional%20wrestler%20for%20the%20WWE. 200\n",
      "2025-11-10 23:49:08,986 - primp - INFO - response: https://www.bing.com/search?q=Dwayne+Douglas+Johnson+is+a+professional+wrestler+for+the+WWE.&pq=Dwayne+Douglas+Johnson+is+a+professional+wrestler+for+the+WWE.&cc=en 200\n",
      "2025-11-10 23:49:11,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff3b1e1739140a4af4d529665c123b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cff5d69b9a456a97a7007d3fc9767d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:12,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:14,044 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:15,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:17,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:18,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a098f55433f44ed5b2b724da58734cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559dbb3f56644ee8b359b2564e323d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48920b2f9565430ebfd0feaced8c6505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318153f1b0f0476e80aa3b6b2d9de9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:20,921 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Dwayne%20Douglas%20Johnson%20is%20not%20a%20professional%20wrestler%20for%20the%20WWE. 200\n",
      "2025-11-10 23:49:21,051 - primp - INFO - response: https://search.yahoo.com/search;_ylt=B_e5TlbaoYqfx7OSWfy1Gsoq;_ylu=f4WtSHytLy6jwcyP35Qiv0bLN2vr0s2XSkMCnljKjBYZ7iE?p=Dwayne+Douglas+Johnson+is+not+a+professional+wrestler+for+the+WWE. 200\n",
      "2025-11-10 23:49:23,282 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Michael Clarke Duncan was in a film....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d6a7a3eb06466db4b658d5f9b6555c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9733b5193d4e908671a3b1d3aedc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:24,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:26,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:27,576 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:28,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:29,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e864adb617408da2d5fa1c4e54860b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9e0f19b66f40eea2f0fcb8a115d016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d6910b713c42a580275ef276fce33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4868188df0f4c149077ca8313d2802f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:31,040 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Michael%20Clarke%20Duncan%20was%20in%20a%20film. 200\n",
      "2025-11-10 23:49:31,786 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:49:33,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985c20392a4f4c688114fedd4a93dd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaec42edc0624226956398895dc26408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:349: ResourceWarning: unclosed <ssl.SSLSocket fd=6244, family=2, type=1, proto=0, laddr=('10.0.0.30', 52338), raddr=('52.149.246.39', 443)>\n",
      "  if return_length:\n",
      "2025-11-10 23:49:35,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:36,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:38,461 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:40,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:41,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46418e353fd4fbbb603e732984f5de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543dc7e8405f4eceb1141ac17821275d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56ead0ce8144848bd625f52c9880f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6c3560432341c3be24081fdd984437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:42,819 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Michael%20Clarke%20Duncan%20was%20not%20in%20a%20film. 200\n",
      "2025-11-10 23:49:43,239 - primp - INFO - response: https://search.yahoo.com/search;_ylt=jGr_JiEYFrbeZzk5_vsp6jfo;_ylu=BgrHWEHfza_tUjKs-KgRgy4Guw5Vg-bqV5zbOI0uJBMhZbs?p=Michael+Clarke+Duncan+was+not+in+a+film. 200\n",
      "2025-11-10 23:49:45,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: 50 First Dates is a 2004 American film....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b74902c497d412f994916857bf61b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502be6a46b8540119e5ebf93a7267ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:47,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:48,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:49,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:51,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:49:52,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ab8e8062464eed8b6f08dadbdd76b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4571e22a0a14f73ad0c9765b3053de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9549d059f93b48758002d4454c6cef68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd6ebc37fec47d98cddac2416f68c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:49:54,917 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=50%20First%20Dates%20is%20a%202004%20American%20film. 200\n",
      "2025-11-10 23:49:55,222 - primp - INFO - response: https://search.brave.com/search?q=50+First+Dates+is+a+2004+American+film.&source=web 429\n",
      "2025-11-10 23:49:57,202 - primp - INFO - response: https://yandex.com/search/site/?text=50+First+Dates+is+a+2004+American+film.&web=1&searchid=4650597 200\n",
      "2025-11-10 23:49:58,856 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a5c53822d748a7b8181ffb864373ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54873969d408446690e3b2d3d5a1be48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:50:00,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:02,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:04,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:05,060 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:06,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:07,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:07,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:08,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:10,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:11,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424125bf35a04542a894f9e287218bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5eaf6b34a8414a873852539f23c453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23219fd519f40d3927b65cbe383a5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a26dd93d9548e880bc93ecee5fff1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:50:13,940 - primp - INFO - response: https://search.brave.com/search?q=50+First+Dates+is+not+a+2004+American+film.&source=web 429\n",
      "2025-11-10 23:50:13,978 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=50%20First%20Dates%20is%20not%20a%202004%20American%20film. 200\n",
      "2025-11-10 23:50:15,155 - primp - INFO - response: https://www.mojeek.com/search?q=50+First+Dates+is+not+a+2004+American+film. 403\n",
      "2025-11-10 23:50:15,475 - primp - INFO - response: https://search.yahoo.com/search;_ylt=SJH1PCZXTtmIPJ_aEKiNGDBX;_ylu=Dtu8KjMO9PFaL2IoQdu8eIY8TuQIbEiCy4UHm24bqbeA5VM?p=50+First+Dates+is+not+a+2004+American+film. 200\n",
      "2025-11-10 23:50:17,852 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1863e8aaf6f432fb3d65123ae3563ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4cc25a3b88424babbfbb84b43bc10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:50:19,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:20,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:21,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:22,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:23,814 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:25,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:27,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:28,652 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:30,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:31,679 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6277f030f4254c758690ea138962fffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eace4443174a467f88a2512962134b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8645ea42474bffa1cce9c608a92b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27510226c04f4dfab1fb8aff777b354e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:50:37,752 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=50%20First%20Dates%20is%20a%203004%20American%20film. 200\n",
      "2025-11-10 23:50:38,163 - primp - INFO - response: https://www.mojeek.com/search?q=50+First+Dates+is+a+3004+American+film. 403\n",
      "2025-11-10 23:50:39,499 - primp - INFO - response: https://yandex.com/search/site/?text=50+First+Dates+is+a+3004+American+film.&web=1&searchid=9640054 200\n",
      "2025-11-10 23:50:42,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45dbaa7221148dbad0e3128e12d5282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9316e4d2c7dd4e749d3e92cb165ade0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:50:45,200 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:46,425 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:47,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:48,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:49,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:51,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:52,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:54,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:56,876 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:50:58,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f7efa5495d48108f8211ba7eec7924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8cbbdd75fd4f688ac07eec62975868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861c37e8a6b4f68a6fc36aa3ed24ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360914d2ce0f4f298b7e98ab74865037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:51:04,044 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=100%20First%20Dates%20is%20a%202004%20American%20film. 200\n",
      "2025-11-10 23:51:05,181 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:51:08,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: There is a WWE wrestler name John Cena....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729f39d76b7a43ecb041677eb0ba2c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12865aa93c484e5ba50d52ba31f282af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:51:13,205 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\threading.py:589: ResourceWarning: unclosed <ssl.SSLSocket fd=6532, family=2, type=1, proto=0, laddr=('10.0.0.30', 57407), raddr=('52.149.246.39', 443)>\n",
      "  self._cond = Condition(Lock())\n",
      "2025-11-10 23:51:15,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:16,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:19,345 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:21,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd710403ad974606af5c9361162f534d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aeea6451b624c6a807a0d8176236e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31773dc21ad242a9a3302f510b2e4132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5ed88c02b04b4692a153e9c9e32778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:51:24,698 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=There%20is%20a%20WWE%20wrestler%20name%20John%20Cena. 200\n",
      "2025-11-10 23:51:25,482 - primp - INFO - response: https://yandex.com/search/site/?text=There+is+a+WWE+wrestler+name+John+Cena.&web=1&searchid=6058576 200\n",
      "2025-11-10 23:51:28,055 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ec265222eb4962bfbba286c9530c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248f74bfba524744af426c84d3db21c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:51:31,777 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:33,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:34,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:35,978 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:37,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac1aad21e7040069b8acd166b935969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20ba8d1b20d48cd86e7a2496041f3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24535ab087aa40bca5953e1f102c8663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10979b3d96dd4296ae20c2c136649b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:51:38,794 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=There%20is%20not%20a%20WWE%20wrestler%20name%20John%20Cena. 200\n",
      "2025-11-10 23:51:38,884 - primp - INFO - response: https://www.bing.com/search?q=There+is+not+a+WWE+wrestler+name+John+Cena.&pq=There+is+not+a+WWE+wrestler+name+John+Cena.&cc=en 200\n",
      "2025-11-10 23:51:40,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 5/20 claims\n",
      "   Testing: Katie Stevens was born on December 8, 1992....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b2367d7b4d4ab288dff2cb0d0994e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21b1312bffa41feba43e853611157a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:51:42,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:43,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:44,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:45,215 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:46,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:47,764 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:48,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:50,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:51,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:51:53,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1dda8cefbd4f70bcafe967d0fca37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121943c0fd634a898a2e180888cb1b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9f5ee5cd8f4256bd736298c3d219ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a19392807c469d81a45cd7700ac982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:51:56,206 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Katie%20Stevens%20was%20born%20on%20December%208%2C%201992. 200\n",
      "2025-11-10 23:51:56,571 - primp - INFO - response: https://search.yahoo.com/search;_ylt=_r7Cz_L5NwNuzfiZsUQHI7CG;_ylu=lRu6Rtdry-80aEf7E1o2XqZGiaQtL0mL-kb75O6WaVzq0XU?p=Katie+Stevens+was+born+on+December+8%2C+1992. 200\n",
      "2025-11-10 23:51:59,885 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86f024f0ad9453bb7c3c4d57c54ee0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f7086dfab84762869ade991c562e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:01,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:03,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:03,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:04,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:05,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722779ff851249aeb47acae3ae33b8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09332605e6484e188e796eaabf369536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e79eee7cef4a9e942842427c6be733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc94a556e174006be27ad134b07ddfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:06,923 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Katie%20Stevens%20was%20not%20born%20on%20December%208%2C%201992. 200\n",
      "2025-11-10 23:52:08,166 - primp - INFO - response: https://yandex.com/search/site/?text=Katie+Stevens+was+not+born+on+December+8%2C+1992.&web=1&searchid=8572291 200\n",
      "2025-11-10 23:52:09,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a79806f376499197a1f7c5bf4ce2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cac48257c77486cbc528758f8255f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:11,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:12,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:13,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:14,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:15,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee70664cc0b4cbb80180bb88943f21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0fdd13c50c4024848e01732c7730a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884fcf11e78a4da282ce61f6f4c9555d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0a607df5744211a4cdee1a17e813d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:16,996 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Katie%20Stevens%20was%20born%20on%20December%208%2C%202992. 200\n",
      "2025-11-10 23:52:18,228 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:52:19,623 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67a7e7ff0dd4bb68e02ae0193a6568a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\inspect.py:3146: ResourceWarning: unclosed <ssl.SSLSocket fd=6940, family=2, type=1, proto=0, laddr=('10.0.0.30', 63328), raddr=('52.149.246.39', 443)>\n",
      "  break\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f5f9cf2c0c474a92b2cecfb4b84989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:21,323 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:22,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:23,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:24,326 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:25,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116c50e082d14966a1fd0444303811f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271f72b8769e4cf9b888beee4d3c2e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b463ebacc9454996c2585bf00a01c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ef746592514de084183259c134ee1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:27,120 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Katie%20Stevens%20was%20born%20on%20December%2080%2C%201992. 200\n",
      "2025-11-10 23:52:27,642 - primp - INFO - response: https://search.yahoo.com/search;_ylt=pAV0rMo_FFWo_L8lm4FFMZ4f;_ylu=DWvDeIMo_AergM3HHE_3OijtUCqw18SerVj0qiyCbDO66dY?p=Katie+Stevens+was+born+on+December+80%2C+1992. 200\n",
      "2025-11-10 23:52:29,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Buddy Holly died on February 3rd, 1959....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f15879daccb49a7abb1903df05bc6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9321da9d2e443839b22fc81b2382884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:31,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:32,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:34,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:35,163 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:36,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e39068e45ac4ed0a8066bb029c51121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea095f0cb14475eb44398a7d2ba5a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f6f605bdf4499ab1786b29c508d136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992c832b404948e9b84fd9ead6ea496e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:37,731 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Buddy%20Holly%20died%20on%20February%203rd%2C%201959. 200\n",
      "2025-11-10 23:52:37,863 - primp - INFO - response: https://search.brave.com/search?q=Buddy+Holly+died+on+February+3rd%2C+1959.&source=web 429\n",
      "2025-11-10 23:52:38,058 - primp - INFO - response: https://www.bing.com/search?q=Buddy+Holly+died+on+February+3rd%2C+1959.&pq=Buddy+Holly+died+on+February+3rd%2C+1959.&cc=en 200\n",
      "2025-11-10 23:52:39,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89f92227c374a7fac683d87acc36b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1b3faafde942ea9f989e41470427bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:41,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:42,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:43,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:44,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:45,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9b37c487ed487798562f437eb4e8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c255731b59bb42b5abf7d11d6f67d2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb886a925c1b4995b30ec9720aba3f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ae9eb7bc1d4b49bc277e301af4f1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:47,067 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Buddy%20Holly%20died%20on%20February%203rd%2C%202959. 200\n",
      "2025-11-10 23:52:48,066 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:52:49,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7f28645b564649ba978ced8e83e51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:1932: ResourceWarning: unclosed <ssl.SSLSocket fd=6240, family=2, type=1, proto=0, laddr=('10.0.0.30', 51399), raddr=('52.149.246.39', 443)>\n",
      "  for meta_name, meta_eval in metadata.items():\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3305c76ac8a14695b8da99802635dafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:51,358 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:52,367 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:53,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:54,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:52:55,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def00359b0b94dbdb0cbdc1427ff7e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ceb7a5e8094a44b4793c024d2b0d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc45f924517e4fc6959bb2b9d7927706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0b9991a549484caf6620c9af7d594e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:52:56,843 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Buddy%20Holly%20died%20on%20February%203rd%2C%203918. 200\n",
      "2025-11-10 23:52:58,790 - primp - INFO - response: https://yandex.com/search/site/?text=Buddy+Holly+died+on+February+3rd%2C+3918.&web=1&searchid=1867790 200\n",
      "2025-11-10 23:53:00,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: The Wolf of Wall Street was a film of 1999....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98245f308794e05b17f7664e496cf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b5c9a0c4bd4dd3a4a66de5a00e338a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:02,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:04,570 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:05,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:06,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:08,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8549b6c624ca4967861c9b205ec64781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937ed8dd3dc489ab03b879348ebaa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6929c1ae764890bd55239a3523ac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2560827f9b964f06870d78401704e74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:10,300 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20Wolf%20of%20Wall%20Street%20was%20a%20film%20of%201999. 200\n",
      "2025-11-10 23:53:10,843 - primp - INFO - response: https://yandex.com/search/site/?text=The+Wolf+of+Wall+Street+was+a+film+of+1999.&web=1&searchid=1563822 200\n",
      "2025-11-10 23:53:12,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd818c4e04ca4c23811a0bbb4811dae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5be92a35ff42069a49d79dfea87af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:14,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:15,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:15,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:17,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:18,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36af94282aec47b5a938f7b4972bac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b8c75db1654cb48c7505cc5e7d61e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b84b6f26d6a4c1f8bbad44ae3c37e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5e0ba1464a4a9e838d30d5754c039b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:19,906 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20Wolf%20of%20Wall%20Street%20was%20not%20a%20film%20of%201999. 200\n",
      "2025-11-10 23:53:21,315 - primp - INFO - response: https://yandex.com/search/site/?text=The+Wolf+of+Wall+Street+was+not+a+film+of+1999.&web=1&searchid=9370815 200\n",
      "2025-11-10 23:53:23,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400d18834bbe47a4a61acf85137a3502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ade2afe7d14dfcb438a57c16e7577d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:25,357 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:27,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:28,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:30,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:31,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d67fd3542fd46d9a7bd7f711fc31f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10dda70ea4a40f89fb88f5034189fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e5511bea50485b9c935d2ae95d3c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435e5977a77948bba71bcd52a600d271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:32,849 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20Wolf%20of%20Wall%20Street%20was%20a%20film%20of%202999. 200\n",
      "2025-11-10 23:53:33,824 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:53:37,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\json\\encoder.py:249: ResourceWarning: unclosed <ssl.SSLSocket fd=6824, family=2, type=1, proto=0, laddr=('10.0.0.30', 62778), raddr=('52.149.246.39', 443)>\n",
      "  _iterencode = c_make_encoder(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a954572c4b6d4096a0969a7d30f915ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099632b52c474ea7b78eeb3e8ebd8b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:38,970 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:40,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:42,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:43,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:45,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc45c84ab4a8464ea56e6b590c497c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec69c11f34f43deb353306010b4ba5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e633b4e700548cd81d28082cf918627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8090476752449e931f51c87391c961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8c1c2f24c74c77b1cf480f88ac0b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9671af0d8cfb4c1799ce3e4c959231bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:47,162 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=The%20Wolf%20of%20Wall%20Street%20was%20a%20film%20of%203998. 200\n",
      "2025-11-10 23:53:48,056 - primp - INFO - response: https://yandex.com/search/site/?text=The+Wolf+of+Wall+Street+was+a+film+of+3998.&web=1&searchid=1949730 200\n",
      "2025-11-10 23:53:49,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Rope starred Bill Clinton....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305bc3d225984018b438aa7caf004e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fed961c0b2496980bef15b9a2d8632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:53:51,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:54,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:55,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:53:58,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:00,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a61e55e8ccd48a4bcb6978256738943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77674c3d534d420881389dedf72a66f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a2d05f0083490686520ed09af456e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d152ec730f254e5d875c2398a634175b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:02,028 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Rope%20starred%20Bill%20Clinton. 200\n",
      "2025-11-10 23:54:02,634 - primp - INFO - response: https://www.mojeek.com/search?q=Rope+starred+Bill+Clinton. 403\n",
      "2025-11-10 23:54:04,031 - primp - INFO - response: https://yandex.com/search/site/?text=Rope+starred+Bill+Clinton.&web=1&searchid=5861612 200\n",
      "2025-11-10 23:54:05,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Linkin Park is a British rock band....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ae03216137493d84a35962739d1197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c95a619ae7e485d8abf6c64a279de5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:07,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:08,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:09,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:09,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:10,863 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:11,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:12,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:13,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:13,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:14,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e8b22a2158407d9837461404c28ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97ae617d2184cacb78bff4fb767e0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebceed31ac2643efbacfb26f492f19e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a1e3d570e949ddac2e9e59349ccf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:17,140 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Linkin%20Park%20is%20a%20British%20rock%20band. 200\n",
      "2025-11-10 23:54:17,773 - primp - INFO - response: https://www.mojeek.com/search?q=Linkin+Park+is+a+British+rock+band. 403\n",
      "2025-11-10 23:54:19,026 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:54:20,555 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01be9d3422464951957564671cf4819e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49a38a5bc37489382dacf842cc4589a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:22,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:22,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\typing.py:407: ResourceWarning: unclosed <ssl.SSLSocket fd=6748, family=2, type=1, proto=0, laddr=('10.0.0.30', 62789), raddr=('52.149.246.39', 443)>\n",
      "  def _eval_type(t, globalns, localns, type_params=None, *, recursive_guard=frozenset()):\n",
      "2025-11-10 23:54:23,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:24,538 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:25,466 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6dd51ca26e40ac8acddab21401bc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d40681de0474982ae8cbc65c043b197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59c9bf9100347bd8f5046cf50a783ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f98100682a546aca91d06ef1cb5ded9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:27,804 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Linkin%20Park%20is%20not%20a%20British%20rock%20band. 200\n",
      "2025-11-10 23:54:28,948 - primp - INFO - response: https://yandex.com/search/site/?text=Linkin+Park+is+not+a+British+rock+band.&web=1&searchid=2144748 200\n",
      "2025-11-10 23:54:30,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 10/20 claims\n",
      "   Testing: Celine Dion sings in Arabic....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a56057d6e140e09111f1f7ca29a211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa6c429a88b4d53a57d06e48cd22fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:32,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:33,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:34,680 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:36,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:37,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168ac4bc1f1b415bb4f7c555c7c9e310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac2358625c943e1a8a31580591c3e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d06a4fa5aa41dcb5a895ebf9ec50c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03d2775387946a6a752bfbdcb8cd3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:38,904 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Celine%20Dion%20sings%20in%20Arabic. 200\n",
      "2025-11-10 23:54:39,172 - primp - INFO - response: https://www.mojeek.com/search?q=Celine+Dion+sings+in+Arabic. 403\n",
      "2025-11-10 23:54:40,043 - primp - INFO - response: https://search.yahoo.com/search;_ylt=n0Wk_WiW5UGSdPyQT3LUf2aj;_ylu=Ii3SprJ1Igcrm3RnYlow-N6RFpGMvsXotWHKyEIjL67e-34?p=Celine+Dion+sings+in+Arabic. 200\n",
      "2025-11-10 23:54:42,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: True Blood ignores Sookie Stackhouse....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d049c76bf0e49d599f9205d87f56ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f80b57d21e47cda241dc088cd2240f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:45,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:47,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:49,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:50,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:54:54,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd397286ac641efbbb4089380a1b67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7700986ed5ef4842b1e3f286cd79853f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5dedfc46ef454ca746c8307c9c65e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecab95ce4d3943c9afbe79a714dbb778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:54:56,213 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=True%20Blood%20ignores%20Sookie%20Stackhouse. 200\n",
      "2025-11-10 23:54:56,361 - primp - INFO - response: https://search.brave.com/search?q=True+Blood+ignores+Sookie+Stackhouse.&source=web 429\n",
      "2025-11-10 23:54:58,197 - primp - INFO - response: https://yandex.com/search/site/?text=True+Blood+ignores+Sookie+Stackhouse.&web=1&searchid=3062997 200\n",
      "2025-11-10 23:55:00,786 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Desperate Housewives strictly a book series from Canada....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef47c194e6f444d9e0fb9e2c51dd110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55fc78bad6d47c79b359e44d732e582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:03,321 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:05,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:07,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:09,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:12,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd622d3e205487ab0d44025d02114cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61afbc5d1d66404c9b30764f52e5f806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0508636ae4ac47d794b013e3082fa6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3064badb26545118ddab855f3c590a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:14,613 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Desperate%20Housewives%20strictly%20a%20book%20series%20from%20Canada. 200\n",
      "2025-11-10 23:55:15,157 - primp - INFO - response: https://yandex.com/search/site/?text=Desperate+Housewives+strictly+a+book+series+from+Canada.&web=1&searchid=7821917 200\n",
      "2025-11-10 23:55:17,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Vacation has an all-American cast....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028fac1ca87a41ad8535ea78c094ab16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36521262f938451ebc7255e61b221efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:19,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:21,551 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:22,983 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:25,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:26,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c339150c6ec447399cf55e52568d64cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce3a3c32de9438cb3c024c33442313b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbeeaa42f104717802b59d6be200676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5521286b26584887b77467c982d80402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:28,347 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Vacation%20has%20an%20all-American%20cast. 200\n",
      "2025-11-10 23:55:28,462 - primp - INFO - response: https://search.yahoo.com/search;_ylt=UzfSlcyepMom9dd1_rncbm3T;_ylu=WkudJ9eDjATQsJhkHWF5yqnTQHwyIetpwvg2k52wbSbMNCo?p=Vacation+has+an+all-American+cast. 200\n",
      "2025-11-10 23:55:31,443 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45102628fd5f4fdcb0a195a55ed18d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a064f49db8f44a98eb38e6dc174843b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:33,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:35,407 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:37,411 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:38,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:40,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1109d8eee52a4f55a2e2caca683fdc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe39a0f7b3a497aafcc8d2fca38c8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c80010288a41bf939b3e2af0d28e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a59c4ae0b464880b893de273208b9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaafc641ef94e67bba10be77a025f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:41,761 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Vacation%20has%20not%20an%20all-American%20cast. 200\n",
      "2025-11-10 23:55:41,945 - primp - INFO - response: https://search.yahoo.com/search;_ylt=HovaRySes5QJAmxKcuFfWWba;_ylu=flc_8lPdzf-kA6aEbx1U0Tjudv-032PHk_9yCGmzCrbBPRg?p=Vacation+has+not+an+all-American+cast. 200\n",
      "2025-11-10 23:55:45,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Jared Leto has a former name called Toast....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1c9f518b494d158beac1402ce7824c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a642a2def8564227af1334f74b699ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:47,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:48,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:49,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:51,383 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:55:52,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c75009c9995410eb699e317527afc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e907dcb9f4b34ea58324296660ec3bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4217b41a50f74ca89158c92b39ce7ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3fcd121eb649f1ad989037500b4263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:53,773 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Jared%20Leto%20has%20a%20former%20name%20called%20Toast. 200\n",
      "2025-11-10 23:55:54,246 - primp - INFO - response: https://www.mojeek.com/search?q=Jared+Leto+has+a+former+name+called+Toast. 403\n",
      "2025-11-10 23:55:54,759 - primp - INFO - response: https://search.brave.com/search?q=Jared+Leto+has+a+former+name+called+Toast.&source=web 429\n",
      "2025-11-10 23:55:55,621 - primp - INFO - response: https://www.bing.com/search?q=Jared+Leto+has+a+former+name+called+Toast.&pq=Jared+Leto+has+a+former+name+called+Toast.&cc=en 200\n",
      "2025-11-10 23:55:57,853 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a480b87b592450490253313cac8a28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef44ddf7675f4da385e3c08a91b154c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:55:59,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:00,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:01,799 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:03,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:05,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef51022988946038b5e714d9dfa43fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7331beb056b74cf6877f196b2ffa2222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da24b7531a79407d96a6d8703b87d8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fbe8243e984f7180117bb4d34d9078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:06,029 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Jared%20Leto%20has%20not%20a%20former%20name%20called%20Toast. 200\n",
      "2025-11-10 23:56:06,157 - primp - INFO - response: https://www.bing.com/search?q=Jared+Leto+has+not+a+former+name+called+Toast.&pq=Jared+Leto+has+not+a+former+name+called+Toast.&cc=en 200\n",
      "2025-11-10 23:56:07,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 15/20 claims\n",
      "   Testing: Richard Nixon's wife's friend's name was Ryan....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e744751a80f04c808d6ad16e5bfd5976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f333a0a4631b4824b1b57f0d7315a507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:09,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:11,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:13,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:15,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:16,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74b141214e243d8a43d2f5728589d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e36ec8386e4cb5a5f24fe2844da438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be48f1ecdd6e48fa8202d1b8cbb6c4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d48246cd3c747199af596f6dec6bd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:18,189 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Richard%20Nixon%27s%20wife%27s%20friend%27s%20name%20was%20Ryan. 200\n",
      "2025-11-10 23:56:19,341 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:56:21,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\traitlets\\traitlets.py:718: ResourceWarning: unclosed <ssl.SSLSocket fd=6596, family=2, type=1, proto=0, laddr=('10.0.0.30', 58691), raddr=('52.149.246.39', 443)>\n",
      "  def _validate(self, obj: t.Any, value: t.Any) -> G | None:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51efa750f4d24844a5f8b58402f17196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d496ca022e4715955765b15270f309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:22,888 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:23,843 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:24,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:25,530 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:26,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8c3f5cee284b128a61b4be2624357a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f350f276e740d0aa20bbad0277eea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e901e3d1b3a4622b662b1867246e3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63742a4a974f4fe1ac6fecc5938c8340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf8627da208483c98a02773b6a63a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb84dddc54b4b95b3f4a478b25bec0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:27,647 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Richard%20Nixon%27s%20wife%27s%20friend%27s%20name%20was%20not%20Ryan. 200\n",
      "2025-11-10 23:56:27,801 - primp - INFO - response: https://search.yahoo.com/search;_ylt=5sNlceti1DzTrJ1_FoJZWdOd;_ylu=0ErG-O5MO4RTdpR92MaCObU2oOd6MlMx5NS5-PscubHaSg4?p=Richard+Nixon%27s+wife%27s+friend%27s+name+was+not+Ryan. 200\n",
      "2025-11-10 23:56:29,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Neymar finished college on February....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e886758ca5f4f089dabdc35d205cb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a9460a3cd746bc8046033526faeff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:31,817 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:32,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:34,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:35,681 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:37,542 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b4a2b9ba874cb09aac1319c8d46a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a91d602b0849daa62dc88715121d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52a6f36a85e47edbfe5b7b6a38a5f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfa841db96a43e8a39d44afe3944caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:38,903 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Neymar%20finished%20college%20on%20February. 200\n",
      "2025-11-10 23:56:39,704 - httpx - INFO - HTTP Request: POST https://html.duckduckgo.com/html/ \"HTTP/2 200 OK\"\n",
      "2025-11-10 23:56:41,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Dileep designed a toy factory....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a07d2505df49fba20b4744a33e6a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooji\\anaconda3\\Lib\\site-packages\\dateutil\\tz\\tz.py:74: ResourceWarning: unclosed <ssl.SSLSocket fd=6396, family=2, type=1, proto=0, laddr=('10.0.0.30', 58696), raddr=('52.149.246.39', 443)>\n",
      "  def utcoffset(self, dt):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a0b4e4a0b041d1a03777e269410ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:44,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:46,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:48,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:49,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:56:51,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3e94bb305d41bda9c5bc760656385f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b174542ee74229a071dfb62be9ebb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebebc6bcef043c4b37211cb7636dce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06493b04c8c94246b5a60cfbf0252931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:52,922 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Dileep%20designed%20a%20toy%20factory. 200\n",
      "2025-11-10 23:56:53,129 - primp - INFO - response: https://search.brave.com/search?q=Dileep+designed+a+toy+factory.&source=web 429\n",
      "2025-11-10 23:56:55,063 - primp - INFO - response: https://yandex.com/search/site/?text=Dileep+designed+a+toy+factory.&web=1&searchid=1175299 200\n",
      "2025-11-10 23:56:57,200 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: IBM only used programming language invented by others....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6729b1fcaf994eb9ac459b8b234ece27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9d719196da4af79094cda93240020b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:56:59,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:01,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:03,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:05,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:07,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51ab2020cee434b923dc1bbfbf07007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d14ca7d1d8a45ec93cf7fd31f004054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97d6fbf28d44a10b651a8c54880e8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf6fdda11b64a628fb54a4bc50e69f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:57:09,481 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=IBM%20only%20used%20programming%20language%20invented%20by%20others. 200\n",
      "2025-11-10 23:57:09,619 - primp - INFO - response: https://search.brave.com/search?q=IBM+only+used+programming+language+invented+by+others.&source=web 429\n",
      "2025-11-10 23:57:11,454 - primp - INFO - response: https://www.mojeek.com/search?q=IBM+only+used+programming+language+invented+by+others. 403\n",
      "2025-11-10 23:57:12,088 - primp - INFO - response: https://www.bing.com/search?q=IBM+only+used+programming+language+invented+by+others.&pq=IBM+only+used+programming+language+invented+by+others.&cc=en 200\n",
      "2025-11-10 23:57:14,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing: Alfred Hitchcock framed shots to maximize only two things....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6605272b044391a2a5cb29959da818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734a745c58d54b1fa9eadce45a917e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:57:16,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:17,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:18,631 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:19,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 23:57:21,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28df7c37c8b4fcf9383fb88effca1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91037de7206c464cbb7944072392357f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb46f5ba6314e0aad1ecaecadff0e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1bb5de95964e1888115797f8bcadd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 23:57:22,890 - primp - INFO - response: https://en.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=Alfred%20Hitchcock%20framed%20shots%20to%20maximize%20only%20two%20things. 200\n",
      "2025-11-10 23:57:23,371 - primp - INFO - response: https://search.yahoo.com/search;_ylt=svtRlK3isCTJWw3ZLsoRpeIA;_ylu=vgJFNPiOiIBIM5qO4-lMWRlDXeeNTaPciGDxZET5gmifD30?p=Alfred+Hitchcock+framed+shots+to+maximize+only+two+things. 200\n",
      "2025-11-10 23:57:26,429 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 20/20 claims\n",
      "\n",
      "======================================================================\n",
      "üéØ Overall Robustness Score: 73.7%\n",
      "   (Percentage of adversarial changes detected)\n",
      "======================================================================\n",
      "\n",
      "üìà Test Summary:\n",
      "   Total Adversarial Tests: 19\n",
      "   Correct Detections: 14\n",
      "   Missed Changes: 5\n",
      "\n",
      "üìä Performance by Attack Type:\n",
      "   Negation         81.8%  (9/11)\n",
      "   Temporal         50.0%  (2/4)\n",
      "   Numerical        75.0%  (3/4)\n",
      "\n",
      "======================================================================\n",
      "üìù SAMPLE ADVERSARIAL EXAMPLES\n",
      "======================================================================\n",
      "\n",
      "üîπ Example 1 - NEGATION\n",
      "   Original: Estella Warren is an actress....\n",
      "   Label: SUPPORTS | Confidence: 97.5%\n",
      "\n",
      "   Adversarial: Estella Warren is not an actress....\n",
      "   Label: REFUTES | Confidence: 100.0%\n",
      "   ‚úÖ Change detected\n",
      "\n",
      "üîπ Example 2 - NEGATION\n",
      "   Original: Dwayne Douglas Johnson is a professional wrestler for the WWE....\n",
      "   Label: REFUTES | Confidence: 97.5%\n",
      "\n",
      "   Adversarial: Dwayne Douglas Johnson is not a professional wrestler for the WWE....\n",
      "   Label: REFUTES | Confidence: 100.0%\n",
      "   ‚ùå Change missed\n",
      "\n",
      "üîπ Example 3 - NEGATION\n",
      "   Original: Michael Clarke Duncan was in a film....\n",
      "   Label: SUPPORTS | Confidence: 100.0%\n",
      "\n",
      "   Adversarial: Michael Clarke Duncan was not in a film....\n",
      "   Label: REFUTES | Confidence: 97.5%\n",
      "   ‚úÖ Change detected\n",
      "\n",
      "üîπ Example 4 - NEGATION\n",
      "   Original: 50 First Dates is a 2004 American film....\n",
      "   Label: SUPPORTS | Confidence: 91.1%\n",
      "\n",
      "   Adversarial: 50 First Dates is not a 2004 American film....\n",
      "   Label: REFUTES | Confidence: 62.2%\n",
      "   ‚úÖ Change detected\n",
      "\n",
      "üîπ Example 5 - TEMPORAL\n",
      "   Original: 50 First Dates is a 2004 American film....\n",
      "   Label: SUPPORTS | Confidence: 91.1%\n",
      "\n",
      "   Adversarial: 50 First Dates is a 3004 American film....\n",
      "   Label: REFUTES | Confidence: 90.7%\n",
      "   ‚úÖ Change detected\n",
      "\n",
      "üíæ Saved detailed results to: adversarial_test_results.json\n",
      "üìä Saved visualization to: adversarial_results.png\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ADVERSARIAL TESTING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Generated files:\n",
      "   1. adversarial_test_results.json\n",
      "   2. adversarial_results.png\n",
      "\n",
      "üéì Use these to show robustness in your presentation!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ADVERSARIAL ROBUSTNESS TESTING\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "class AdversarialTester:\n",
    "    \"\"\"\n",
    "    Tests hallucination detection system with adversarial examples\n",
    "    Compatible with HallucinationDetector.detect() method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, detector):\n",
    "        self.detector = detector\n",
    "        self.attack_types = {\n",
    "            'negation': self.negation_attack,\n",
    "            'temporal': self.temporal_attack,\n",
    "            'numerical': self.numerical_attack\n",
    "        }\n",
    "    \n",
    "    def negation_attack(self, claim: str) -> str:\n",
    "        \"\"\"\n",
    "        Add negation to flip the meaning of a claim\n",
    "        Example: \"X is Y\" -> \"X is not Y\"\n",
    "        \"\"\"\n",
    "        patterns = [\n",
    "            (r'\\bis\\b', 'is not'),\n",
    "            (r'\\bwas\\b', 'was not'),\n",
    "            (r'\\bare\\b', 'are not'),\n",
    "            (r'\\bwere\\b', 'were not'),\n",
    "            (r'\\bhas\\b', 'has not'),\n",
    "            (r'\\bhave\\b', 'have not'),\n",
    "            (r'\\bhad\\b', 'had not'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in patterns:\n",
    "            if re.search(pattern, claim):\n",
    "                adversarial = re.sub(pattern, replacement, claim, count=1)\n",
    "                return adversarial\n",
    "        \n",
    "        return claim\n",
    "    \n",
    "    def temporal_attack(self, claim: str) -> str:\n",
    "        \"\"\"\n",
    "        Change temporal information (dates, years, times)\n",
    "        Example: \"in 2004\" -> \"in 3004\"\n",
    "        \"\"\"\n",
    "        year_match = re.search(r'\\b(1[0-9]{3}|20[0-9]{2})\\b', claim)\n",
    "        if year_match:\n",
    "            original_year = year_match.group(1)\n",
    "            new_year = str(int(original_year) + 1000)\n",
    "            adversarial = claim.replace(original_year, new_year, 1)\n",
    "            return adversarial\n",
    "        \n",
    "        month_year = re.search(r'(January|February|March|April|May|June|July|August|September|October|November|December)\\s+(\\d{4})', claim)\n",
    "        if month_year:\n",
    "            original = month_year.group(0)\n",
    "            year = month_year.group(2)\n",
    "            new_year = str(int(year) + 1000)\n",
    "            adversarial = claim.replace(year, new_year, 1)\n",
    "            return adversarial\n",
    "        \n",
    "        return claim\n",
    "    \n",
    "    def numerical_attack(self, claim: str) -> str:\n",
    "        \"\"\"\n",
    "        Change numerical values\n",
    "        Example: \"won 3 awards\" -> \"won 30 awards\"\n",
    "        \"\"\"\n",
    "        number_match = re.search(r'\\b(\\d+)\\b', claim)\n",
    "        if number_match:\n",
    "            original_num = number_match.group(1)\n",
    "            original_int = int(original_num)\n",
    "            \n",
    "            if original_int < 10:\n",
    "                new_num = str(original_int * 10)\n",
    "            else:\n",
    "                new_num = str(original_int * 2)\n",
    "            \n",
    "            adversarial = claim.replace(original_num, new_num, 1)\n",
    "            return adversarial\n",
    "        \n",
    "        return claim\n",
    "    \n",
    "    def generate_adversarial_examples(self, claim: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Generate all types of adversarial examples for a claim\n",
    "        \"\"\"\n",
    "        examples = {}\n",
    "        \n",
    "        for attack_name, attack_func in self.attack_types.items():\n",
    "            adversarial = attack_func(claim)\n",
    "            if adversarial != claim:\n",
    "                examples[attack_name] = adversarial\n",
    "        \n",
    "        return examples\n",
    "    \n",
    "    def test_claim(self, original_claim: str, original_label: str, \n",
    "                   original_evidence: str = \"\") -> Dict:\n",
    "        \"\"\"\n",
    "        Test a single claim with all adversarial attacks\n",
    "        Uses detector.detect() method\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'original_claim': original_claim,\n",
    "            'original_label': original_label,\n",
    "            'attacks': []\n",
    "        }\n",
    "        \n",
    "        # Get original prediction using detect() method\n",
    "        print(f\"   Testing: {original_claim[:60]}...\")\n",
    "        orig_result = self.detector.detect(original_claim)\n",
    "        \n",
    "        # Extract label and confidence from detect() results\n",
    "        # fever_label is the FEVER classification, combined_confidence is the score\n",
    "        orig_pred = orig_result.get('fever_label')\n",
    "        if orig_pred is None:\n",
    "            # Fallback if fever_label not available (question mode)\n",
    "            orig_pred = 'UNKNOWN'\n",
    "        \n",
    "        orig_conf = orig_result.get('combined_confidence', 50.0)\n",
    "        \n",
    "        results['original_prediction'] = orig_pred\n",
    "        results['original_confidence'] = float(orig_conf)\n",
    "        \n",
    "        # Generate adversarial examples\n",
    "        adversarial_examples = self.generate_adversarial_examples(original_claim)\n",
    "        \n",
    "        # Test each adversarial example\n",
    "        for attack_type, adv_claim in adversarial_examples.items():\n",
    "            adv_result = self.detector.detect(adv_claim)\n",
    "            \n",
    "            # Extract label and confidence\n",
    "            adv_pred = adv_result.get('fever_label')\n",
    "            if adv_pred is None:\n",
    "                adv_pred = 'UNKNOWN'\n",
    "            \n",
    "            adv_conf = adv_result.get('combined_confidence', 50.0)\n",
    "            \n",
    "            # Check if the model detected the change\n",
    "            change_detected = (orig_pred != adv_pred)\n",
    "            \n",
    "            attack_result = {\n",
    "                'attack_type': attack_type,\n",
    "                'adversarial_claim': adv_claim,\n",
    "                'adversarial_prediction': adv_pred,\n",
    "                'adversarial_confidence': float(adv_conf),\n",
    "                'change_detected': bool(change_detected)\n",
    "            }\n",
    "            \n",
    "            results['attacks'].append(attack_result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def convert_to_json_serializable(self, obj):\n",
    "        \"\"\"\n",
    "        Recursively convert NumPy types to native Python types\n",
    "        THIS IS THE FIX FOR THE JSON ERROR\n",
    "        \"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {key: self.convert_to_json_serializable(value) \n",
    "                    for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self.convert_to_json_serializable(item) for item in obj]\n",
    "        elif isinstance(obj, np.bool_):\n",
    "            return bool(obj)\n",
    "        elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    def run_adversarial_test(self, test_claims: List[Dict], \n",
    "                            num_claims: int = 20) -> Dict:\n",
    "        \"\"\"\n",
    "        Run comprehensive adversarial testing\n",
    "        \"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"üéØ ADVERSARIAL ROBUSTNESS TESTING\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        all_results = []\n",
    "        attack_stats = {\n",
    "            'negation': {'total': 0, 'detected': 0},\n",
    "            'temporal': {'total': 0, 'detected': 0},\n",
    "            'numerical': {'total': 0, 'detected': 0}\n",
    "        }\n",
    "        \n",
    "        test_claims = test_claims[:num_claims]\n",
    "        \n",
    "        print(f\"\\nüî¨ Testing {len(test_claims)} claims...\")\n",
    "        print(\"   Generating adversarial examples...\\n\")\n",
    "        \n",
    "        for i, claim_data in enumerate(test_claims):\n",
    "            claim = claim_data['claim']\n",
    "            label = claim_data['label']\n",
    "            evidence = claim_data.get('evidence', '')\n",
    "            \n",
    "            result = self.test_claim(claim, label, evidence)\n",
    "            all_results.append(result)\n",
    "            \n",
    "            for attack in result['attacks']:\n",
    "                attack_type = attack['attack_type']\n",
    "                attack_stats[attack_type]['total'] += 1\n",
    "                if attack['change_detected']:\n",
    "                    attack_stats[attack_type]['detected'] += 1\n",
    "            \n",
    "            if (i + 1) % 5 == 0:\n",
    "                print(f\"   ‚úì Processed {i + 1}/{len(test_claims)} claims\")\n",
    "        \n",
    "        total_attacks = sum(stats['total'] for stats in attack_stats.values())\n",
    "        total_detected = sum(stats['detected'] for stats in attack_stats.values())\n",
    "        overall_robustness = (total_detected / total_attacks * 100) if total_attacks > 0 else 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"üéØ Overall Robustness Score: {overall_robustness:.1f}%\")\n",
    "        print(\"   (Percentage of adversarial changes detected)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\nüìà Test Summary:\")\n",
    "        print(f\"   Total Adversarial Tests: {total_attacks}\")\n",
    "        print(f\"   Correct Detections: {total_detected}\")\n",
    "        print(f\"   Missed Changes: {total_attacks - total_detected}\")\n",
    "        \n",
    "        print(f\"\\nüìä Performance by Attack Type:\")\n",
    "        for attack_type, stats in attack_stats.items():\n",
    "            if stats['total'] > 0:\n",
    "                accuracy = (stats['detected'] / stats['total']) * 100\n",
    "                print(f\"   {attack_type.capitalize():15s}  {accuracy:.1f}%  ({stats['detected']}/{stats['total']})\")\n",
    "        \n",
    "        self._print_sample_examples(all_results)\n",
    "        \n",
    "        results = {\n",
    "            'overall_robustness': float(overall_robustness),\n",
    "            'total_attacks': int(total_attacks),\n",
    "            'total_detected': int(total_detected),\n",
    "            'attack_statistics': {\n",
    "                k: {'total': int(v['total']), 'detected': int(v['detected'])}\n",
    "                for k, v in attack_stats.items()\n",
    "            },\n",
    "            'detailed_results': all_results\n",
    "        }\n",
    "        \n",
    "        # THE FIX - Convert to JSON-serializable format\n",
    "        results = self.convert_to_json_serializable(results)\n",
    "        \n",
    "        with open('adversarial_test_results.json', 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nüíæ Saved detailed results to: adversarial_test_results.json\")\n",
    "        \n",
    "        self.plot_results(attack_stats, overall_robustness)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _print_sample_examples(self, all_results: List[Dict], num_samples: int = 5):\n",
    "        \"\"\"\n",
    "        Print sample adversarial examples\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìù SAMPLE ADVERSARIAL EXAMPLES\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        sample_count = 0\n",
    "        for result in all_results:\n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "            \n",
    "            for attack in result['attacks']:\n",
    "                if sample_count >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                sample_count += 1\n",
    "                \n",
    "                status = \"‚úÖ Change detected\" if attack['change_detected'] else \"‚ùå Change missed\"\n",
    "                \n",
    "                print(f\"\\nüîπ Example {sample_count} - {attack['attack_type'].upper()}\")\n",
    "                print(f\"   Original: {result['original_claim'][:80]}...\")\n",
    "                print(f\"   Label: {result['original_prediction']} | Confidence: {result['original_confidence']:.1f}%\")\n",
    "                print(f\"\\n   Adversarial: {attack['adversarial_claim'][:80]}...\")\n",
    "                print(f\"   Label: {attack['adversarial_prediction']} | Confidence: {attack['adversarial_confidence']:.1f}%\")\n",
    "                print(f\"   {status}\")\n",
    "    \n",
    "    def plot_results(self, attack_stats: Dict, overall_robustness: float):\n",
    "        \"\"\"\n",
    "        Create visualization of adversarial testing results\n",
    "        \"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        attack_types = []\n",
    "        accuracies = []\n",
    "        \n",
    "        for attack_type, stats in attack_stats.items():\n",
    "            if stats['total'] > 0:\n",
    "                attack_types.append(attack_type.capitalize())\n",
    "                accuracy = (stats['detected'] / stats['total']) * 100\n",
    "                accuracies.append(accuracy)\n",
    "        \n",
    "        colors = ['#2ecc71' if acc >= 75 else '#e74c3c' if acc < 50 else '#f39c12' \n",
    "                  for acc in accuracies]\n",
    "        \n",
    "        bars = ax1.bar(attack_types, accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
    "        ax1.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='50% Baseline')\n",
    "        ax1.axhline(y=75, color='green', linestyle='--', alpha=0.5, label='75% Target')\n",
    "        ax1.set_ylabel('Detection Rate (%)', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title('Robustness by Attack Type', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylim(0, 100)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        categories = ['Overall\\nRobustness']\n",
    "        scores = [overall_robustness]\n",
    "        \n",
    "        if overall_robustness >= 80:\n",
    "            color = '#2ecc71'\n",
    "            rating = 'Excellent'\n",
    "        elif overall_robustness >= 70:\n",
    "            color = '#3498db'\n",
    "            rating = 'Good'\n",
    "        elif overall_robustness >= 50:\n",
    "            color = '#f39c12'\n",
    "            rating = 'Moderate'\n",
    "        else:\n",
    "            color = '#e74c3c'\n",
    "            rating = 'Needs Improvement'\n",
    "        \n",
    "        bar = ax2.bar(categories, scores, color=color, alpha=0.8, edgecolor='black', width=0.5)\n",
    "        ax2.axhline(y=50, color='red', linestyle='--', alpha=0.5)\n",
    "        ax2.axhline(y=70, color='orange', linestyle='--', alpha=0.5)\n",
    "        ax2.axhline(y=80, color='green', linestyle='--', alpha=0.5)\n",
    "        ax2.set_ylabel('Score (%)', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title('Overall Adversarial Robustness', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylim(0, 100)\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        ax2.text(0, overall_robustness + 3, f'{overall_robustness:.1f}%\\n({rating})',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('adversarial_results.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"üìä Saved visualization to: adversarial_results.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RUNNABLE SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"üéØ ADVERSARIAL ROBUSTNESS TESTING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load FEVER claims\n",
    "    claims_file = r\"C:\\Users\\pooji\\Desktop\\fever_claims_full.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(claims_file, 'r') as f:\n",
    "            all_claims = json.load(f)\n",
    "        \n",
    "        print(f\"\\n‚úì Loaded {len(all_claims)} claims\")\n",
    "        \n",
    "        # Select diverse claims for testing\n",
    "        supports_claims = [c for c in all_claims if c['label'] == 'SUPPORTS'][:7]\n",
    "        refutes_claims = [c for c in all_claims if c['label'] == 'REFUTES'][:7]\n",
    "        nei_claims = [c for c in all_claims if c['label'] == 'NOT ENOUGH INFO'][:6]\n",
    "        \n",
    "        test_claims = supports_claims + refutes_claims + nei_claims\n",
    "        \n",
    "        print(f\"   Selected {len(test_claims)} diverse claims for testing\")\n",
    "        print(f\"   ‚Ä¢ SUPPORTS: {len(supports_claims)} claims\")\n",
    "        print(f\"   ‚Ä¢ REFUTES: {len(refutes_claims)} claims\")\n",
    "        print(f\"   ‚Ä¢ NOT ENOUGH INFO: {len(nei_claims)} claims\")\n",
    "        \n",
    "        # Initialize detector (assumes HallucinationDetector is already defined)\n",
    "        print(\"\\n‚è≥ Initializing detector...\")\n",
    "        detector = HallucinationDetector()\n",
    "        \n",
    "        # Initialize tester\n",
    "        print(\"‚è≥ Initializing adversarial tester...\")\n",
    "        tester = AdversarialTester(detector)\n",
    "        \n",
    "        # Run adversarial tests\n",
    "        print(\"\\n‚è≥ Starting adversarial testing...\")\n",
    "        print(\"   This will generate ~60-80 adversarial examples\")\n",
    "        print(\"   Estimated time: 5-10 minutes\")\n",
    "        print(\"   (Each claim is tested with detect() - may take a while)\\n\")\n",
    "        \n",
    "        adv_results = tester.run_adversarial_test(test_claims, num_claims=20)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ ADVERSARIAL TESTING COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nüìÅ Generated files:\")\n",
    "        print(\"   1. adversarial_test_results.json\")\n",
    "        print(\"   2. adversarial_results.png\")\n",
    "        print(\"\\nüéì Use these to show robustness in your presentation!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Claims file not found: {claims_file}\")\n",
    "        print(\"   Make sure the path is correct!\")\n",
    "    except NameError as e:\n",
    "        print(f\"\\n‚ùå NameError: {e}\")\n",
    "        print(\"\\nüí° Make sure HallucinationDetector class is defined!\")\n",
    "        print(\"   Run the cell that defines your detector first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99457a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ YOUR RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Accuracy: 65.00%\n",
      "Total Claims: 100\n",
      "Correct: 65\n",
      "\n",
      "Confusion Matrix:\n",
      "  SUPPORTS: {'SUPPORTS': 29, 'REFUTES': 2, 'NOT ENOUGH INFO': 1}\n",
      "  REFUTES: {'SUPPORTS': 5, 'REFUTES': 33, 'NOT ENOUGH INFO': 0}\n",
      "  NOT ENOUGH INFO: {'SUPPORTS': 14, 'REFUTES': 13, 'NOT ENOUGH INFO': 3}\n"
     ]
    }
   ],
   "source": [
    "# Run this to see your results\n",
    "import json\n",
    "\n",
    "results_file = r\"C:\\Users\\pooji\\Desktop\\complete_8layer_results_15000.json\"\n",
    "\n",
    "with open(results_file, 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ YOUR RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAccuracy: {results['accuracy']:.2%}\")\n",
    "print(f\"Total Claims: {results['total']}\")\n",
    "print(f\"Correct: {results['correct']}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "for actual, row in results['confusion_matrix'].items():\n",
    "    print(f\"  {actual}: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä GENERATING VISUALIZATIONS FOR UPDATE 2\n",
      "======================================================================\n",
      "\n",
      "‚úì Saved: accuracy_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved: confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved: per_class_accuracy.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved: improvement_breakdown.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ ALL VISUALIZATIONS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Generated files:\n",
      "   1. accuracy_comparison.png\n",
      "   2. confusion_matrix.png\n",
      "   3. per_class_accuracy.png\n",
      "   4. improvement_breakdown.png\n",
      "\n",
      "üéì Use these in your Progress Update 2 presentation!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate Visualization Charts for Progress Update 2\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load your results\n",
    "with open(r\"C:\\Users\\pooji\\Desktop\\complete_8layer_results_15000.json\", 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# ============================================\n",
    "# CHART 1: ACCURACY COMPARISON\n",
    "# ============================================\n",
    "\n",
    "def plot_accuracy_comparison():\n",
    "    \"\"\"Compare all 3 systems\"\"\"\n",
    "    \n",
    "    systems = ['Baseline\\n(GPT-4o)', 'RAG\\n(Wikipedia)', '8-Layer\\nSystem']\n",
    "    accuracies = [59.05, 62.75, results['accuracy'] * 100]\n",
    "    colors = ['#ef4444', '#f59e0b', '#10b981']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.bar(systems, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.1f}%',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('System Accuracy Comparison on FEVER Dataset', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r\"C:\\Users\\pooji\\Desktop\\accuracy_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úì Saved: accuracy_comparison.png\")\n",
    "    plt.show()\n",
    "\n",
    "# ============================================\n",
    "# CHART 2: CONFUSION MATRIX HEATMAP\n",
    "# ============================================\n",
    "\n",
    "def plot_confusion_matrix():\n",
    "    \"\"\"Visualize confusion matrix\"\"\"\n",
    "    \n",
    "    labels = ['SUPPORTS', 'REFUTES', 'NOT ENOUGH INFO']\n",
    "    cm = results['confusion_matrix']\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    matrix = np.array([\n",
    "        [cm['SUPPORTS']['SUPPORTS'], cm['SUPPORTS']['REFUTES'], cm['SUPPORTS']['NOT ENOUGH INFO']],\n",
    "        [cm['REFUTES']['SUPPORTS'], cm['REFUTES']['REFUTES'], cm['REFUTES']['NOT ENOUGH INFO']],\n",
    "        [cm['NOT ENOUGH INFO']['SUPPORTS'], cm['NOT ENOUGH INFO']['REFUTES'], cm['NOT ENOUGH INFO']['NOT ENOUGH INFO']]\n",
    "    ])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=labels, yticklabels=labels,\n",
    "                cbar_kws={'label': 'Number of Claims'}, ax=ax)\n",
    "    \n",
    "    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Actual Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Confusion Matrix - 8-Layer System', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r\"C:\\Users\\pooji\\Desktop\\confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úì Saved: confusion_matrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "# ============================================\n",
    "# CHART 3: PER-CLASS ACCURACY\n",
    "# ============================================\n",
    "\n",
    "def plot_per_class_accuracy():\n",
    "    \"\"\"Show accuracy for each label type\"\"\"\n",
    "    \n",
    "    labels = ['SUPPORTS', 'REFUTES', 'NOT ENOUGH INFO']\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    per_class = []\n",
    "    for label in labels:\n",
    "        total = sum(results['confusion_matrix'][label].values())\n",
    "        correct = results['confusion_matrix'][label][label]\n",
    "        accuracy = (correct / total * 100) if total > 0 else 0\n",
    "        per_class.append(accuracy)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.bar(labels, per_class, color=['#3b82f6', '#8b5cf6', '#ec4899'], alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, acc in zip(bars, per_class):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.1f}%',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Per-Class Accuracy', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r\"C:\\Users\\pooji\\Desktop\\per_class_accuracy.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úì Saved: per_class_accuracy.png\")\n",
    "    plt.show()\n",
    "\n",
    "# ============================================\n",
    "# CHART 4: IMPROVEMENT BREAKDOWN\n",
    "# ============================================\n",
    "\n",
    "def plot_improvement_breakdown():\n",
    "    \"\"\"Show improvement over baseline\"\"\"\n",
    "    \n",
    "    baseline = 59.05\n",
    "    rag = 62.75\n",
    "    complete = results['accuracy'] * 100\n",
    "    \n",
    "    improvements = [0, rag - baseline, complete - baseline]\n",
    "    labels = ['Baseline', '+RAG Layer', '+6 Advanced\\nLayers']\n",
    "    colors = ['#94a3b8', '#f59e0b', '#10b981']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.bar(labels, improvements, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Add cumulative labels\n",
    "    cumulative = [baseline, rag, complete]\n",
    "    for bar, imp, cum in zip(bars, improvements, cumulative):\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'+{imp:.1f}%\\n({cum:.1f}% total)',\n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    ax.set_ylabel('Improvement (percentage points)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Incremental Improvement Over Baseline', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r\"C:\\Users\\pooji\\Desktop\\improvement_breakdown.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úì Saved: improvement_breakdown.png\")\n",
    "    plt.show()\n",
    "\n",
    "# ============================================\n",
    "# RUN ALL VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä GENERATING VISUALIZATIONS FOR UPDATE 2\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "plot_accuracy_comparison()\n",
    "plot_confusion_matrix()\n",
    "plot_per_class_accuracy()\n",
    "plot_improvement_breakdown()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ALL VISUALIZATIONS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìÅ Generated files:\")\n",
    "print(\"   1. accuracy_comparison.png\")\n",
    "print(\"   2. confusion_matrix.png\")\n",
    "print(\"   3. per_class_accuracy.png\")\n",
    "print(\"   4. improvement_breakdown.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f203fa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROGRESS UPDATE 2 - RESULTS SUMMARY\n",
      "8-Layer Hallucination Detection System\n",
      "======================================================================\n",
      "\n",
      "Date: 2025-11-11 00:52\n",
      "Dataset: FEVER (1,000 claim subset)\n",
      "\n",
      "1. OVERALL PERFORMANCE\n",
      "----------------------------------------------------------------------\n",
      "Accuracy: 65.00%\n",
      "Correct Predictions: 65/100\n",
      "\n",
      "2. COMPARISON WITH BASELINES\n",
      "----------------------------------------------------------------------\n",
      "Baseline (GPT-4o only):        59.05%\n",
      "RAG (Wikipedia):               62.75%\n",
      "8-Layer System:                65.00%\n",
      "\n",
      "Total Improvement:             +5.9 percentage points\n",
      "\n",
      "3. PER-CLASS PERFORMANCE\n",
      "----------------------------------------------------------------------\n",
      "SUPPORTS             90.6%  (29/32)\n",
      "REFUTES              86.8%  (33/38)\n",
      "NOT ENOUGH INFO      10.0%  (3/30)\n",
      "\n",
      "4. SYSTEM ARCHITECTURE\n",
      "----------------------------------------------------------------------\n",
      "Layer 1: Wikipedia Search (FAISS + BM25)\n",
      "Layer 2: Cross-Encoder Re-ranking\n",
      "Layer 3: Self-Consistency (5 attempts)\n",
      "Layer 4: Semantic Clustering\n",
      "Layer 5: NLI Verification\n",
      "Layer 6: Entropy Calculation\n",
      "Layer 7: Web Search Verification\n",
      "Layer 8: Claim Verification (FEVER)\n",
      "\n",
      "5. KEY FINDINGS\n",
      "----------------------------------------------------------------------\n",
      "‚Ä¢ System achieves 65.0% accuracy on FEVER claims\n",
      "‚Ä¢ Represents 5.9 point improvement over baseline\n",
      "‚Ä¢ Claim verification layer successfully classifies claims vs questions\n",
      "‚Ä¢ Multi-layer approach reduces hallucination risk\n",
      "\n",
      "======================================================================\n",
      "END OF REPORT\n",
      "======================================================================\n",
      "\n",
      "‚úì Report saved to: C:\\Users\\pooji\\Desktop\\progress_update_2_summary.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate Text Summary Report\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Load results\n",
    "with open(r\"C:\\Users\\pooji\\Desktop\\complete_8layer_results_15000.json\", 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Create report\n",
    "report = []\n",
    "report.append(\"=\"*70)\n",
    "report.append(\"PROGRESS UPDATE 2 - RESULTS SUMMARY\")\n",
    "report.append(\"8-Layer Hallucination Detection System\")\n",
    "report.append(\"=\"*70)\n",
    "report.append(f\"\\nDate: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "report.append(f\"Dataset: FEVER (1,000 claim subset)\")\n",
    "report.append(\"\")\n",
    "\n",
    "# Overall Performance\n",
    "report.append(\"1. OVERALL PERFORMANCE\")\n",
    "report.append(\"-\"*70)\n",
    "report.append(f\"Accuracy: {results['accuracy']:.2%}\")\n",
    "report.append(f\"Correct Predictions: {results['correct']}/{results['total']}\")\n",
    "report.append(\"\")\n",
    "\n",
    "# Comparison\n",
    "baseline_acc = 0.5905\n",
    "rag_acc = 0.6275\n",
    "improvement = (results['accuracy'] - baseline_acc) * 100\n",
    "\n",
    "report.append(\"2. COMPARISON WITH BASELINES\")\n",
    "report.append(\"-\"*70)\n",
    "report.append(f\"Baseline (GPT-4o only):        {baseline_acc:.2%}\")\n",
    "report.append(f\"RAG (Wikipedia):               {rag_acc:.2%}\")\n",
    "report.append(f\"8-Layer System:                {results['accuracy']:.2%}\")\n",
    "report.append(f\"\\nTotal Improvement:             +{improvement:.1f} percentage points\")\n",
    "report.append(\"\")\n",
    "\n",
    "# Per-class performance\n",
    "report.append(\"3. PER-CLASS PERFORMANCE\")\n",
    "report.append(\"-\"*70)\n",
    "cm = results['confusion_matrix']\n",
    "for label in ['SUPPORTS', 'REFUTES', 'NOT ENOUGH INFO']:\n",
    "    total = sum(cm[label].values())\n",
    "    correct = cm[label][label]\n",
    "    acc = (correct / total * 100) if total > 0 else 0\n",
    "    report.append(f\"{label:<20} {acc:.1f}%  ({correct}/{total})\")\n",
    "report.append(\"\")\n",
    "\n",
    "# System architecture\n",
    "report.append(\"4. SYSTEM ARCHITECTURE\")\n",
    "report.append(\"-\"*70)\n",
    "report.append(\"Layer 1: Wikipedia Search (FAISS + BM25)\")\n",
    "report.append(\"Layer 2: Cross-Encoder Re-ranking\")\n",
    "report.append(\"Layer 3: Self-Consistency (5 attempts)\")\n",
    "report.append(\"Layer 4: Semantic Clustering\")\n",
    "report.append(\"Layer 5: NLI Verification\")\n",
    "report.append(\"Layer 6: Entropy Calculation\")\n",
    "report.append(\"Layer 7: Web Search Verification\")\n",
    "report.append(\"Layer 8: Claim Verification (FEVER)\")\n",
    "report.append(\"\")\n",
    "\n",
    "# Key findings\n",
    "report.append(\"5. KEY FINDINGS\")\n",
    "report.append(\"-\"*70)\n",
    "report.append(f\"‚Ä¢ System achieves {results['accuracy']:.1%} accuracy on FEVER claims\")\n",
    "report.append(f\"‚Ä¢ Represents {improvement:.1f} point improvement over baseline\")\n",
    "report.append(\"‚Ä¢ Claim verification layer successfully classifies claims vs questions\")\n",
    "report.append(\"‚Ä¢ Multi-layer approach reduces hallucination risk\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\"*70)\n",
    "report.append(\"END OF REPORT\")\n",
    "report.append(\"=\"*70)\n",
    "\n",
    "# Save report\n",
    "report_text = \"\\n\".join(report)\n",
    "\n",
    "output_file = r\"C:\\Users\\pooji\\Desktop\\progress_update_2_summary.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(report_text)\n",
    "print(f\"\\n‚úì Report saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c259cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING COMPLETE BASELINE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "   Claims file: C:\\Users\\pooji\\Desktop\\fever_claims_full.json\n",
      "   Test size: 100 claims\n",
      "   Estimated time: 1-2 hours\n",
      "\n",
      "This will test:\n",
      "   1. GPT-4 Only Baseline\n",
      "   2. NLI Only Baseline\n",
      "   3. Self-Consistency Baseline\n",
      "   4. Your RAG System (reported)\n",
      "   5. Your Full 8-Layer System (reported)\n",
      "======================================================================\n",
      "üéØ COMPLETE BASELINE COMPARISON SUITE\n",
      "======================================================================\n",
      "\n",
      "Loading claims from: C:\\Users\\pooji\\Desktop\\fever_claims_full.json\n",
      "Selected 99 claims (balanced across labels)\n",
      "   SUPPORTS: 33\n",
      "   REFUTES: 33\n",
      "   NOT ENOUGH INFO: 33\n",
      "\n",
      "======================================================================\n",
      "RUNNING BASELINE TESTS\n",
      "======================================================================\n",
      "======================================================================\n",
      "ü§ñ BASELINE 1: GPT-4 ONLY\n",
      "======================================================================\n",
      "\n",
      "Testing on 99 claims...\n",
      "This will take ~5-10 minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:54:01,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:02,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:03,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:03,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:04,447 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:05,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:05,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:06,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:07,098 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:07,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 10/99 claims (Current accuracy: 70.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:54:08,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:09,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:10,181 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:10,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:12,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:12,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:13,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:14,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:15,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:16,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 20/99 claims (Current accuracy: 65.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:54:17,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:17,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:18,560 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:19,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:20,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:21,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:21,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:22,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:23,588 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:24,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 30/99 claims (Current accuracy: 63.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:54:25,458 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:26,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:27,099 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:28,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:28,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:29,210 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:29,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:30,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:30,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:31,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 40/99 claims (Current accuracy: 62.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:54:32,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:32,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:33,640 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:34,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:35,143 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:35,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:36,360 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:37,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:38,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:38,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 50/99 claims (Current accuracy: 64.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:54:39,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:40,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:40,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:41,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:42,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:43,120 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:43,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:44,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:45,213 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:54:45,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 60/99 claims (Current accuracy: 61.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:54:46,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:16,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:22,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:23,264 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:24,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:24,715 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:25,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:26,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:26,809 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:27,394 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 70/99 claims (Current accuracy: 62.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:55:27,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:28,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:29,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:29,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:30,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:31,024 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:31,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:32,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:32,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:33,556 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 80/99 claims (Current accuracy: 57.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:55:34,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:35,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:36,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:36,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:37,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:38,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:38,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:40,266 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:41,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:41,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 90/99 claims (Current accuracy: 52.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:55:42,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:42,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:43,413 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:44,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:44,619 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:45,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:45,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:46,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:55:46,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ GPT-4 Baseline Accuracy: 50.5%\n",
      "\n",
      "======================================================================\n",
      "üß† BASELINE 2: NLI ONLY\n",
      "======================================================================\n",
      "\n",
      "Testing on 99 claims...\n",
      "Loading NLI model...\n",
      "\n",
      "   ‚úì Processed 10/99 claims (Current accuracy: 40.0%)\n",
      "   ‚úì Processed 20/99 claims (Current accuracy: 45.0%)\n",
      "   ‚úì Processed 30/99 claims (Current accuracy: 50.0%)\n",
      "   ‚úì Processed 40/99 claims (Current accuracy: 55.0%)\n",
      "   ‚úì Processed 50/99 claims (Current accuracy: 60.0%)\n",
      "   ‚úì Processed 60/99 claims (Current accuracy: 60.0%)\n",
      "   ‚úì Processed 70/99 claims (Current accuracy: 58.6%)\n",
      "   ‚úì Processed 80/99 claims (Current accuracy: 51.2%)\n",
      "   ‚úì Processed 90/99 claims (Current accuracy: 45.6%)\n",
      "\n",
      "‚úÖ NLI Baseline Accuracy: 42.4%\n",
      "\n",
      "======================================================================\n",
      "üîÑ BASELINE 3: SELF-CONSISTENCY ONLY\n",
      "======================================================================\n",
      "\n",
      "Testing on 99 claims...\n",
      "Generating 5 responses per claim...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:56:15,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:16,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:16,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:17,652 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:18,068 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:18,713 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:19,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:20,082 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:20,481 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:21,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:21,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:22,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:25,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:25,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:26,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:26,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:27,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:28,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:29,475 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:30,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:30,808 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:31,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:32,654 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:33,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:34,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 5/99 claims (Current accuracy: 100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:56:35,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:36,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:36,593 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:37,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:37,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:38,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:38,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:39,481 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:39,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:40,380 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:40,864 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:41,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:41,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:42,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:43,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:43,645 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:44,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:44,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:45,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:45,876 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:46,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:46,958 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:47,604 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:48,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:48,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 10/99 claims (Current accuracy: 80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:56:49,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:50,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:50,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:51,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:52,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:52,670 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:53,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:53,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:54,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:54,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:55,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:55,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:56,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:56,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:57,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:57,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:58,232 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:58,817 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:56:59,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:00,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:00,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:01,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:01,549 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:01,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:02,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 15/99 claims (Current accuracy: 86.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:57:03,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:03,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:04,467 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:05,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:05,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:06,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:06,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:07,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:08,140 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:08,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:09,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:09,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:10,587 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:11,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:11,739 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:12,469 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:12,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:13,509 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:14,121 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:15,000 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:15,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:16,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:17,035 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:17,568 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:18,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 20/99 claims (Current accuracy: 80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:57:18,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:19,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:20,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:20,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:20,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:21,405 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:21,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:22,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:22,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:23,510 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:23,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:24,409 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:24,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:25,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:26,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:26,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:27,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:27,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:28,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:28,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:29,569 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:30,267 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:31,103 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:31,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:32,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 25/99 claims (Current accuracy: 80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:57:33,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:33,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:34,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:34,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:35,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:35,938 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:36,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:37,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:37,490 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:38,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:38,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:39,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:39,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:40,445 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:40,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:41,416 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:42,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:43,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:43,911 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:44,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:45,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:45,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:46,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:46,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:47,572 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 30/99 claims (Current accuracy: 80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:57:48,325 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:48,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:49,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:50,441 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:50,853 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:51,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:52,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:52,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:53,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:53,851 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:54,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:55,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:55,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:57,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:57,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:58,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:59,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:57:59,773 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:00,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:00,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:01,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:02,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:02,725 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:03,192 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:03,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 35/99 claims (Current accuracy: 80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:58:04,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:06,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:06,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:07,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:08,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:08,820 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:09,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:10,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:10,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:11,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:11,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:12,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:13,359 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:13,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:14,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:14,965 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:15,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:16,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:16,753 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:17,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:18,046 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:18,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:19,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:20,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:20,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 40/99 claims (Current accuracy: 77.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:58:21,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:21,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:22,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:22,691 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:23,091 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:23,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:24,161 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:24,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:25,215 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:25,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:26,029 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:26,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:27,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:27,890 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:28,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:29,652 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:30,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:31,196 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:31,733 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:32,516 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:32,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:33,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:34,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:35,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:35,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 45/99 claims (Current accuracy: 77.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:58:36,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:37,136 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:37,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:38,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:38,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:39,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:39,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:40,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:40,863 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:41,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:41,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:42,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:42,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:43,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:43,930 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:44,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:44,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:45,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:45,736 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:46,203 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:47,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:48,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:48,636 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:49,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:50,086 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 50/99 claims (Current accuracy: 78.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:58:50,817 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:51,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:52,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:52,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:53,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:53,609 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:54,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:54,769 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:55,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:55,829 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:56,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:56,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:57,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:58,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:58,966 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:58:59,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:00,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:00,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:01,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:01,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:02,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:03,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:03,990 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:04,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:05,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 55/99 claims (Current accuracy: 74.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:59:05,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:06,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:06,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:07,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:07,887 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:08,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:08,902 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:09,617 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:10,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:10,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:11,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:11,987 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:12,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:13,314 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:14,206 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:14,713 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:15,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:16,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:16,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:17,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:17,629 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:18,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:18,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:19,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:19,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 60/99 claims (Current accuracy: 75.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:59:20,451 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:20,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:21,391 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:21,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:22,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:23,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:24,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:24,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:25,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:25,636 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:26,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:26,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:27,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:28,184 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:28,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:30,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:30,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:31,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:31,960 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:32,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:33,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:34,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:34,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:35,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:35,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 65/99 claims (Current accuracy: 75.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:59:36,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:36,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:37,580 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:38,126 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:38,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:39,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:39,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:40,431 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:40,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:41,356 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:41,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:42,305 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:42,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:44,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:44,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:45,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:46,156 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:46,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:47,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:48,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:48,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:49,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:49,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:50,492 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:51,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 70/99 claims (Current accuracy: 74.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:59:52,129 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:52,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:53,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:53,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:54,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:55,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:55,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:56,946 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:57,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:58,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:58,674 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:59:59,600 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:00,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:00,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:01,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:01,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:02,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:03,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:03,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:04,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:05,219 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:05,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:06,433 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:07,149 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:07,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 75/99 claims (Current accuracy: 69.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:00:08,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:09,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:09,698 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:10,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:11,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:12,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:14,410 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:14,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:15,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:16,901 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:17,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:18,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:19,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:20,039 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:20,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:22,970 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:23,836 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:24,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:25,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:25,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:27,413 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:28,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:28,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:29,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:30,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 80/99 claims (Current accuracy: 65.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:00:31,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:34,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:35,813 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:38,940 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:39,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:40,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:40,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:41,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:41,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:42,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:42,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:43,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:44,198 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:44,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:45,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:46,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:46,706 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:47,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:48,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:48,570 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:49,337 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:49,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:50,566 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:51,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:51,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 85/99 claims (Current accuracy: 61.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:00:51,946 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:55,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:55,816 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:56,384 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:00:59,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:00,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:01,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:01,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:02,384 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:02,896 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:03,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:04,123 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:04,717 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:05,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:05,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:06,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:09,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:10,228 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:14,261 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:15,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:15,857 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:19,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:19,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:20,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:21,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 90/99 claims (Current accuracy: 57.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:01:21,772 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:22,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:23,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:24,051 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:24,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:25,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:25,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:26,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:29,263 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:29,830 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:32,683 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:33,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:33,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:34,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:35,568 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:36,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:37,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:37,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:38,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:39,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:39,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:40,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:42,217 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:42,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:43,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Processed 95/99 claims (Current accuracy: 56.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 01:01:43,917 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:44,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:45,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:46,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:46,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:47,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:48,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:48,912 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:49,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:50,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:52,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:52,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:53,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:54,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:55,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:56,818 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:57,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:01:58,308 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:02:00,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 01:02:01,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Self-Consistency Baseline Accuracy: 54.5%\n",
      "   Average Consistency Score: 98.2%\n",
      "\n",
      "======================================================================\n",
      "üìä ADDING YOUR EXISTING RESULTS\n",
      "======================================================================\n",
      "\n",
      "üìä Creating comparison visualization...\n",
      "   ‚úì Saved: baseline_comparison.png\n",
      "   ‚úì Saved: baseline_progression.png\n",
      "\n",
      "üíæ Saving results...\n",
      "   ‚úì Saved: baseline_comparison_results.json\n",
      "\n",
      "======================================================================\n",
      "üìä BASELINE COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Method                           Accuracy  Improvement\n",
      "----------------------------------------------------------------------\n",
      "NLI Only                            42.4%         0.0pp\n",
      "GPT-4 Only                          50.5%         8.1pp\n",
      "Self-Consistency                    54.5%        12.1pp\n",
      "RAG Only                            59.0%        16.6pp\n",
      "Full 8-Layer System                 64.0%        21.6pp\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üéØ Best Method: Full 8-Layer System\n",
      "   Accuracy: 64.0%\n",
      "   Improvement: +21.6pp\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BASELINE COMPARISON COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Generated Files:\n",
      "   1. baseline_comparison.png - Side-by-side comparison\n",
      "   2. baseline_progression.png - Performance progression\n",
      "   3. baseline_comparison_results.json - Detailed results\n",
      "\n",
      "üéì For Your Presentation:\n",
      "   Use these visualizations to show:\n",
      "   ‚Ä¢ Each component adds measurable value\n",
      "   ‚Ä¢ Your full system outperforms all baselines\n",
      "   ‚Ä¢ Scientific rigor in evaluation methodology\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "COMPLETE BASELINE COMPARISON SUITE\n",
    "Tests all approaches on same data for fair comparison\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# Initialize OpenAI\n",
    "OPENAI_API_KEY = \"\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
    "\n",
    "# ============================================================================\n",
    "# BASELINE 1: GPT-4 ONLY (No Retrieval, No Verification)\n",
    "# ============================================================================\n",
    "\n",
    "def test_gpt4_baseline(claims, num_claims=100):\n",
    "    \"\"\"\n",
    "    Test GPT-4 alone without any retrieval or verification\n",
    "    Expected: ~50-55% accuracy\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"ü§ñ BASELINE 1: GPT-4 ONLY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nTesting on {num_claims} claims...\")\n",
    "    print(\"This will take ~5-10 minutes...\\n\")\n",
    "    \n",
    "    if not client:\n",
    "        print(\"‚ùå OpenAI API key not configured!\")\n",
    "        return None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, claim_data in enumerate(claims[:num_claims]):\n",
    "        claim = claim_data['claim']\n",
    "        actual_label = claim_data['label']\n",
    "        \n",
    "        # Simple prompt to GPT-4\n",
    "        prompt = f\"\"\"Is the following claim true, false, or is there not enough information to determine?\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Answer with ONLY one of these three options:\n",
    "- SUPPORTS (if the claim is true)\n",
    "- REFUTES (if the claim is false)\n",
    "- NOT ENOUGH INFO (if uncertain)\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.3,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            \n",
    "            predicted = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Normalize prediction\n",
    "            if 'SUPPORTS' in predicted.upper():\n",
    "                predicted = 'SUPPORTS'\n",
    "            elif 'REFUTES' in predicted.upper():\n",
    "                predicted = 'REFUTES'\n",
    "            else:\n",
    "                predicted = 'NOT ENOUGH INFO'\n",
    "            \n",
    "            is_correct = (predicted == actual_label)\n",
    "            \n",
    "            results.append({\n",
    "                'claim': claim,\n",
    "                'predicted_label': predicted,\n",
    "                'actual_label': actual_label,\n",
    "                'correct': is_correct\n",
    "            })\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                accuracy_so_far = sum(r['correct'] for r in results) / len(results) * 100\n",
    "                print(f\"   ‚úì Processed {i + 1}/{num_claims} claims (Current accuracy: {accuracy_so_far:.1f}%)\")\n",
    "            \n",
    "            time.sleep(0.2)  # Rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error on claim {i+1}: {e}\")\n",
    "            results.append({\n",
    "                'claim': claim,\n",
    "                'predicted_label': 'NOT ENOUGH INFO',\n",
    "                'actual_label': actual_label,\n",
    "                'correct': False\n",
    "            })\n",
    "    \n",
    "    accuracy = sum(r['correct'] for r in results) / len(results) * 100\n",
    "    \n",
    "    print(f\"\\n‚úÖ GPT-4 Baseline Accuracy: {accuracy:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'method': 'GPT-4 Only',\n",
    "        'accuracy': accuracy,\n",
    "        'results': results,\n",
    "        'num_tested': len(results)\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# BASELINE 2: NLI ONLY\n",
    "# ============================================================================\n",
    "\n",
    "def test_nli_baseline(claims, num_claims=100):\n",
    "    \"\"\"\n",
    "    Test NLI model only for classification\n",
    "    Expected: ~52-56% accuracy\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üß† BASELINE 2: NLI ONLY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nTesting on {num_claims} claims...\")\n",
    "    print(\"Loading NLI model...\\n\")\n",
    "    \n",
    "    # Load NLI model\n",
    "    nli_model_name = \"cross-encoder/nli-deberta-v3-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(nli_model_name)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, claim_data in enumerate(claims[:num_claims]):\n",
    "        claim = claim_data['claim']\n",
    "        actual_label = claim_data['label']\n",
    "        \n",
    "        # Use claim as both premise and hypothesis (self-verification)\n",
    "        # Or use a neutral statement as premise\n",
    "        premise = \"This is a factual claim about the world.\"\n",
    "        \n",
    "        inputs = tokenizer(premise, claim, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Reorder: [contradiction, neutral, entailment] -> [contradiction, neutral, entailment]\n",
    "        # Map to FEVER labels\n",
    "        contradiction_score = probs[0][0].item()\n",
    "        neutral_score = probs[0][1].item()\n",
    "        entailment_score = probs[0][2].item()\n",
    "        \n",
    "        # Classification logic\n",
    "        if entailment_score > 0.6:\n",
    "            predicted = 'SUPPORTS'\n",
    "        elif contradiction_score > 0.6:\n",
    "            predicted = 'REFUTES'\n",
    "        else:\n",
    "            predicted = 'NOT ENOUGH INFO'\n",
    "        \n",
    "        is_correct = (predicted == actual_label)\n",
    "        \n",
    "        results.append({\n",
    "            'claim': claim,\n",
    "            'predicted_label': predicted,\n",
    "            'actual_label': actual_label,\n",
    "            'correct': is_correct\n",
    "        })\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            accuracy_so_far = sum(r['correct'] for r in results) / len(results) * 100\n",
    "            print(f\"   ‚úì Processed {i + 1}/{num_claims} claims (Current accuracy: {accuracy_so_far:.1f}%)\")\n",
    "    \n",
    "    accuracy = sum(r['correct'] for r in results) / len(results) * 100\n",
    "    \n",
    "    print(f\"\\n‚úÖ NLI Baseline Accuracy: {accuracy:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'method': 'NLI Only',\n",
    "        'accuracy': accuracy,\n",
    "        'results': results,\n",
    "        'num_tested': len(results)\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# BASELINE 3: SELF-CONSISTENCY ONLY\n",
    "# ============================================================================\n",
    "\n",
    "def test_self_consistency_baseline(claims, num_claims=100):\n",
    "    \"\"\"\n",
    "    Test self-consistency only (no other verification)\n",
    "    Expected: ~58-62% accuracy\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîÑ BASELINE 3: SELF-CONSISTENCY ONLY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nTesting on {num_claims} claims...\")\n",
    "    print(\"Generating 5 responses per claim...\\n\")\n",
    "    \n",
    "    if not client:\n",
    "        print(\"‚ùå OpenAI API key not configured!\")\n",
    "        return None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, claim_data in enumerate(claims[:num_claims]):\n",
    "        claim = claim_data['claim']\n",
    "        actual_label = claim_data['label']\n",
    "        \n",
    "        # Generate 5 independent responses\n",
    "        predictions = []\n",
    "        \n",
    "        for attempt in range(5):\n",
    "            prompt = f\"\"\"Verify this claim. Answer ONLY: SUPPORTS, REFUTES, or NOT ENOUGH INFO\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Answer:\"\"\"\n",
    "            \n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=0.7,  # Higher temperature for diversity\n",
    "                    max_tokens=50\n",
    "                )\n",
    "                \n",
    "                pred = response.choices[0].message.content.strip()\n",
    "                \n",
    "                # Normalize\n",
    "                if 'SUPPORTS' in pred.upper():\n",
    "                    pred = 'SUPPORTS'\n",
    "                elif 'REFUTES' in pred.upper():\n",
    "                    pred = 'REFUTES'\n",
    "                else:\n",
    "                    pred = 'NOT ENOUGH INFO'\n",
    "                \n",
    "                predictions.append(pred)\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                predictions.append('NOT ENOUGH INFO')\n",
    "        \n",
    "        # Majority vote\n",
    "        vote_counts = Counter(predictions)\n",
    "        predicted = vote_counts.most_common(1)[0][0]\n",
    "        consistency = vote_counts[predicted] / 5.0\n",
    "        \n",
    "        is_correct = (predicted == actual_label)\n",
    "        \n",
    "        results.append({\n",
    "            'claim': claim,\n",
    "            'predicted_label': predicted,\n",
    "            'actual_label': actual_label,\n",
    "            'correct': is_correct,\n",
    "            'consistency': consistency,\n",
    "            'all_predictions': predictions\n",
    "        })\n",
    "        \n",
    "        if (i + 1) % 5 == 0:\n",
    "            accuracy_so_far = sum(r['correct'] for r in results) / len(results) * 100\n",
    "            print(f\"   ‚úì Processed {i + 1}/{num_claims} claims (Current accuracy: {accuracy_so_far:.1f}%)\")\n",
    "    \n",
    "    accuracy = sum(r['correct'] for r in results) / len(results) * 100\n",
    "    avg_consistency = np.mean([r['consistency'] for r in results]) * 100\n",
    "    \n",
    "    print(f\"\\n‚úÖ Self-Consistency Baseline Accuracy: {accuracy:.1f}%\")\n",
    "    print(f\"   Average Consistency Score: {avg_consistency:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'method': 'Self-Consistency Only',\n",
    "        'accuracy': accuracy,\n",
    "        'results': results,\n",
    "        'num_tested': len(results),\n",
    "        'avg_consistency': avg_consistency\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# RUN ALL BASELINES AND COMPARE\n",
    "# ============================================================================\n",
    "\n",
    "def run_complete_baseline_comparison(claims_file, num_claims=100):\n",
    "    \"\"\"\n",
    "    Run all baseline tests and generate comparison\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üéØ COMPLETE BASELINE COMPARISON SUITE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nLoading claims from: {claims_file}\")\n",
    "    \n",
    "    # Load claims\n",
    "    with open(claims_file, 'r') as f:\n",
    "        all_claims = json.load(f)\n",
    "    \n",
    "    # Select diverse sample\n",
    "    supports = [c for c in all_claims if c['label'] == 'SUPPORTS']\n",
    "    refutes = [c for c in all_claims if c['label'] == 'REFUTES']\n",
    "    nei = [c for c in all_claims if c['label'] == 'NOT ENOUGH INFO']\n",
    "    \n",
    "    # Balanced sample\n",
    "    num_per_class = num_claims // 3\n",
    "    test_claims = (\n",
    "        supports[:num_per_class] + \n",
    "        refutes[:num_per_class] + \n",
    "        nei[:num_per_class]\n",
    "    )\n",
    "    \n",
    "    print(f\"Selected {len(test_claims)} claims (balanced across labels)\")\n",
    "    print(f\"   SUPPORTS: {num_per_class}\")\n",
    "    print(f\"   REFUTES: {num_per_class}\")\n",
    "    print(f\"   NOT ENOUGH INFO: {num_per_class}\")\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    # Run baselines\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RUNNING BASELINE TESTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Baseline 1: GPT-4 Only\n",
    "    gpt4_results = test_gpt4_baseline(test_claims, num_claims=len(test_claims))\n",
    "    if gpt4_results:\n",
    "        all_results['GPT-4 Only'] = gpt4_results\n",
    "    \n",
    "    # Baseline 2: NLI Only\n",
    "    nli_results = test_nli_baseline(test_claims, num_claims=len(test_claims))\n",
    "    if nli_results:\n",
    "        all_results['NLI Only'] = nli_results\n",
    "    \n",
    "    # Baseline 3: Self-Consistency Only\n",
    "    selfcons_results = test_self_consistency_baseline(test_claims, num_claims=len(test_claims))\n",
    "    if selfcons_results:\n",
    "        all_results['Self-Consistency'] = selfcons_results\n",
    "    \n",
    "    # Add your existing results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä ADDING YOUR EXISTING RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    all_results['RAG Only'] = {\n",
    "        'method': 'RAG Only',\n",
    "        'accuracy': 59.0,  # Your reported number\n",
    "        'num_tested': num_claims\n",
    "    }\n",
    "    \n",
    "    all_results['Full 8-Layer System'] = {\n",
    "        'method': 'Full 8-Layer System',\n",
    "        'accuracy': 64.0,  # Your reported number\n",
    "        'num_tested': num_claims\n",
    "    }\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    create_baseline_comparison_plot(all_results)\n",
    "    \n",
    "    # Save results\n",
    "    save_baseline_results(all_results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def create_baseline_comparison_plot(all_results):\n",
    "    \"\"\"\n",
    "    Create professional comparison visualization\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Creating comparison visualization...\")\n",
    "    \n",
    "    methods = list(all_results.keys())\n",
    "    accuracies = [all_results[m]['accuracy'] for m in methods]\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    sorted_data = sorted(zip(methods, accuracies), key=lambda x: x[1])\n",
    "    methods, accuracies = zip(*sorted_data)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Bar chart\n",
    "    colors = ['#ef4444', '#f59e0b', '#10b981', '#3b82f6', '#8b5cf6']\n",
    "    bars = ax1.barh(methods, accuracies, color=colors[:len(methods)], alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    ax1.set_xlabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "    ax1.set_title('Baseline Comparison', fontsize=15, fontweight='bold')\n",
    "    ax1.set_xlim(0, 100)\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        width = bar.get_width()\n",
    "        ax1.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
    "                f'{acc:.1f}%', ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Improvement cascade\n",
    "    baseline_acc = accuracies[0]\n",
    "    improvements = [acc - baseline_acc for acc in accuracies]\n",
    "    \n",
    "    ax2.barh(methods, improvements, color=colors[:len(methods)], alpha=0.8, edgecolor='black')\n",
    "    ax2.set_xlabel('Improvement over Baseline (pp)', fontsize=13, fontweight='bold')\n",
    "    ax2.set_title('Incremental Improvements', fontsize=15, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    ax2.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (method, imp) in enumerate(zip(methods, improvements)):\n",
    "        ax2.text(imp + 0.3 if imp >= 0 else imp - 0.3, i, \n",
    "                f'+{imp:.1f}pp' if imp >= 0 else f'{imp:.1f}pp',\n",
    "                ha='left' if imp >= 0 else 'right', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('baseline_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"   ‚úì Saved: baseline_comparison.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Create progression plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    x_pos = np.arange(len(methods))\n",
    "    bars = ax.bar(x_pos, accuracies, color=colors[:len(methods)], alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('System Performance Progression', fontsize=16, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(methods, rotation=15, ha='right', fontsize=11)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    # Add improvement arrows\n",
    "    for i in range(len(methods)-1):\n",
    "        ax.annotate('', xy=(x_pos[i+1], accuracies[i+1]), \n",
    "                   xytext=(x_pos[i]+0.3, accuracies[i]),\n",
    "                   arrowprops=dict(arrowstyle='->', lw=2, color='gray', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('baseline_progression.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"   ‚úì Saved: baseline_progression.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_baseline_results(all_results):\n",
    "    \"\"\"\n",
    "    Save results to JSON\n",
    "    \"\"\"\n",
    "    print(\"\\nüíæ Saving results...\")\n",
    "    \n",
    "    # Prepare for JSON serialization\n",
    "    results_to_save = {}\n",
    "    for method, data in all_results.items():\n",
    "        results_to_save[method] = {\n",
    "            'accuracy': float(data['accuracy']),\n",
    "            'num_tested': int(data.get('num_tested', 0))\n",
    "        }\n",
    "    \n",
    "    with open('baseline_comparison_results.json', 'w') as f:\n",
    "        json.dump(results_to_save, f, indent=2)\n",
    "    \n",
    "    print(\"   ‚úì Saved: baseline_comparison_results.json\")\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä BASELINE COMPARISON SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Method':<30s} {'Accuracy':>10s} {'Improvement':>12s}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    baseline_acc = min(data['accuracy'] for data in all_results.values())\n",
    "    \n",
    "    for method, data in sorted(all_results.items(), key=lambda x: x[1]['accuracy']):\n",
    "        acc = data['accuracy']\n",
    "        improvement = acc - baseline_acc\n",
    "        print(f\"{method:<30s} {acc:>9.1f}% {improvement:>11.1f}pp\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(f\"\\nüéØ Best Method: {max(all_results.items(), key=lambda x: x[1]['accuracy'])[0]}\")\n",
    "    print(f\"   Accuracy: {max(data['accuracy'] for data in all_results.values()):.1f}%\")\n",
    "    print(f\"   Improvement: +{max(data['accuracy'] for data in all_results.values()) - baseline_acc:.1f}pp\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Configuration\n",
    "    claims_file = r\"C:\\Users\\pooji\\Desktop\\fever_claims_full.json\"\n",
    "    num_claims = 100  \n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ STARTING COMPLETE BASELINE COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\"   Claims file: {claims_file}\")\n",
    "    print(f\"   Test size: {num_claims} claims\")\n",
    "    print(f\"   Estimated time: 1-2 hours\")\n",
    "    print(f\"\\nThis will test:\")\n",
    "    print(f\"   1. GPT-4 Only Baseline\")\n",
    "    print(f\"   2. NLI Only Baseline\")\n",
    "    print(f\"   3. Self-Consistency Baseline\")\n",
    "    print(f\"   4. Your RAG System (reported)\")\n",
    "    print(f\"   5. Your Full 8-Layer System (reported)\")\n",
    "    \n",
    "    input(\"\\nPress Enter to start (or Ctrl+C to cancel)...\")\n",
    "    \n",
    "    try:\n",
    "        results = run_complete_baseline_comparison(claims_file, num_claims)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ BASELINE COMPARISON COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nüìÅ Generated Files:\")\n",
    "        print(\"   1. baseline_comparison.png - Side-by-side comparison\")\n",
    "        print(\"   2. baseline_progression.png - Performance progression\")\n",
    "        print(\"   3. baseline_comparison_results.json - Detailed results\")\n",
    "        \n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå File not found: {claims_file}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
